{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model\n",
    "\n",
    "The aim of the notebook is demo end to end pipeline for Ads prediction in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! ./setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tensorflow/docs\n",
      "  Cloning https://github.com/tensorflow/docs to /private/var/folders/f_/8flgl5n57_dfmnnjzy_w41wm0000gn/T/pip-req-build-zj9ti1z3\n",
      "  Running command git clone -q https://github.com/tensorflow/docs /private/var/folders/f_/8flgl5n57_dfmnnjzy_w41wm0000gn/T/pip-req-build-zj9ti1z3\n",
      "Requirement already satisfied (use --upgrade to upgrade): tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9- from git+https://github.com/tensorflow/docs in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages\n",
      "Requirement already satisfied: astor in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages (from tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9-) (0.8.1)\n",
      "Requirement already satisfied: absl-py in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages (from tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9-) (0.9.0)\n",
      "Requirement already satisfied: six in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages (from tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9-) (1.14.0)\n",
      "Requirement already satisfied: pathlib2 in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages (from tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9-) (2.3.5)\n",
      "Requirement already satisfied: pyyaml in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages (from tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9-) (5.3.1)\n",
      "Building wheels for collected packages: tensorflow-docs\n",
      "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0d92131b8cc983025d3b423255b1afb09683fbed9_-py3-none-any.whl size=98705 sha256=d918741b95d78f55b52fe18e571b925ccd6d05d6ccdf8419855f9a383f158d86\n",
      "  Stored in directory: /private/var/folders/f_/8flgl5n57_dfmnnjzy_w41wm0000gn/T/pip-ephem-wheel-cache-h1t38brr/wheels/cc/c4/d8/5341e93b6376c5c929c49469fce21155eb69cef1a4da4ce32c\n",
      "Successfully built tensorflow-docs\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q git+https://github.com/tensorflow/docs --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tensorflow, 2.1.0 on Python interpreter, sys.version_info(major=3, minor=6, micro=1, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from typing import Dict, Any, Union, List\n",
    "from functools import partial\n",
    "import re\n",
    "import string\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from math import ceil\n",
    "from collections import namedtuple\n",
    "\n",
    "print(f\"Using Tensorflow, {tf.__version__} on Python interpreter, {sys.version_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using random seed, 1588379143\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = int(time.time())\n",
    "\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"Using random seed, {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Dataset credits:\n",
    "```\n",
    "@inproceedings{roffo2016personality,\n",
    "  title={Personality in computational advertising: A benchmark},\n",
    "  author={Roffo, Giorgio and Vinciarelli, Alessandro},\n",
    "  booktitle={4 th Workshop on Emotions and Personality in Personalized Systems (EMPIRE) 2016},\n",
    "  pages={18},\n",
    "  year={2016}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"../../dataset/\")\n",
    "BATCH_SIZE = 4096 # bigger the batch, faster the training but bigger the RAM needed\n",
    "TARGET_COL = \"Rating\"\n",
    "\n",
    "# data files path are relative DATA_FOLDER\n",
    "users_ads_rating_csv = DATA_FOLDER/\"users-ads-without-gcp-ratings_OHE_MLB.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'CapZipCode',\n",
       " 'FaveSports',\n",
       " 'Gender_F',\n",
       " 'Gender_M',\n",
       " 'ad_num_faces',\n",
       " 'ad_isAdvertising',\n",
       " 'ad_isBrand',\n",
       " 'ad_isElectronic device',\n",
       " 'ad_isElectronics',\n",
       " 'ad_isFashion accessory',\n",
       " 'ad_isFictional character',\n",
       " 'ad_isFont',\n",
       " 'ad_isFurniture',\n",
       " 'ad_isGadget',\n",
       " 'ad_isGames',\n",
       " 'ad_isGraphic design',\n",
       " 'ad_isGraphics',\n",
       " 'ad_isJewellery',\n",
       " 'ad_isLine',\n",
       " 'ad_isLogo',\n",
       " 'ad_isMagenta',\n",
       " 'ad_isMaterial property',\n",
       " 'ad_isMultimedia',\n",
       " 'ad_isProduct',\n",
       " 'ad_isRectangle',\n",
       " 'ad_isSkin',\n",
       " 'ad_isTechnology',\n",
       " 'ad_isText',\n",
       " 'ad_isVehicle',\n",
       " 'ad_isYellow',\n",
       " 'ad_isAdult_UNLIKELY',\n",
       " 'ad_isAdult_VERY_UNLIKELY',\n",
       " 'ad_isSpoof_POSSIBLE',\n",
       " 'ad_isSpoof_UNLIKELY',\n",
       " 'ad_isSpoof_VERY_UNLIKELY',\n",
       " 'ad_isMedical_POSSIBLE',\n",
       " 'ad_isMedical_UNLIKELY',\n",
       " 'ad_isMedical_VERY_UNLIKELY',\n",
       " 'ad_isViolence_VERY_UNLIKELY',\n",
       " 'ad_isRacy_POSSIBLE',\n",
       " 'ad_isRacy_UNLIKELY',\n",
       " 'ad_isRacy_VERY_LIKELY',\n",
       " 'ad_isRacy_VERY_UNLIKELY',\n",
       " 'Homecountry_Canada',\n",
       " 'Homecountry_CzechRepublic',\n",
       " 'Homecountry_GreatBritain',\n",
       " 'Homecountry_India',\n",
       " 'Homecountry_Italy',\n",
       " 'Homecountry_Phillipines',\n",
       " 'Homecountry_Romania',\n",
       " 'Homecountry_SaudiArabia',\n",
       " 'Homecountry_Singapore',\n",
       " 'Homecountry_Slovenia',\n",
       " 'Homecountry_UnitedKingdom',\n",
       " 'Homecountry_UnitedStatesofAmerica',\n",
       " 'Rating']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_ID = \"UserId\"\n",
    "AD_ID = \"AdId\"\n",
    "AGE = \"Age\"\n",
    "ZIP_CODE = \"CapZipCode\"\n",
    "COUNTRIES_VISITED = \"Countriesvisited\"\n",
    "FAVE_SPORTS = \"FaveSports\"\n",
    "GENDER = \"Gender\"\n",
    "HOME_COUNTRY = \"Homecountry\"\n",
    "HOME_TOWN = \"Hometown\"\n",
    "INCOME = \"Income\"\n",
    "LAST_NAME = \"LastName\"\n",
    "MOST_LISTENED_MUSICS = \"Mostlistenedmusics\"\n",
    "MOST_READ_BOOKS = \"Mostreadbooks\"\n",
    "MOST_VISITED_WEBSITES = \"Mostvisitedwebsites\"\n",
    "MOST_WATCHED_MOVIES = \"Mostwatchedmovies\"\n",
    "MOST_WATCHED_TV_PROGRAMMES = \"Mostwatchedtvprogrammes\"\n",
    "NAME = \"Name\"\n",
    "PAYPAL = \"Paypal\"\n",
    "TIMEPASS = \"Timepass\"\n",
    "TYPE_OF_JOB = \"TypeofJob\"\n",
    "WEEKLY_WORKING_HOURS = \"Weeklyworkinghours\"\n",
    "FAVE1 = \"fave1\"\n",
    "FAVE10 = \"fave10\"\n",
    "FAVE2 = \"fave2\"\n",
    "FAVE3 = \"fave3\"\n",
    "FAVE4 = \"fave4\"\n",
    "FAVE5 = \"fave5\"\n",
    "FAVE6 = \"fave6\"\n",
    "FAVE7 = \"fave7\"\n",
    "FAVE8 = \"fave8\"\n",
    "FAVE9 = \"fave9\"\n",
    "UNFAVE1 = \"unfave1\"\n",
    "UNFAVE2 = \"unfave2\"\n",
    "UNFAVE3 = \"unfave3\"\n",
    "UNFAVE4 = \"unfave4\"\n",
    "UNFAVE5 = \"unfave5\"\n",
    "UNFAVE6 = \"unfave6\"\n",
    "ADFILEPATH = \"AdFilePath\"\n",
    "GENDER_F = \"Gender_F\"\n",
    "GENDER_M = \"Gender_M\"\n",
    "# HomeCountry = 12 Columns\n",
    "HOMECOUNTRY_CANADA = \"Homecountry_Canada\"\n",
    "HOMECOUNTRY_CZECHREPUBLIC = \"Homecountry_CzechRepublic\"\n",
    "HOMECOUNTRY_GREATBRITAIN = \"Homecountry_GreatBritain\"\n",
    "HOMECOUNTRY_INDIA = \"Homecountry_India\"\n",
    "HOMECOUNTRY_ITALY = \"Homecountry_Italy\"\n",
    "HOMECOUNTRY_PHILLIPINES = \"Homecountry_Phillipines\"\n",
    "HOMECOUNTRY_ROMANIA = \"Homecountry_Romania\"\n",
    "HOMECOUNTRY_SAUDIARABIA = \"Homecountry_SaudiArabia\"\n",
    "HOMECOUNTRY_SINGAPORE = \"Homecountry_Singapore\"\n",
    "HOMECOUNTRY_SLOVENIA = \"Homecountry_Slovenia\"\n",
    "HOMECOUNTRY_UNITEDKINGDOM = \"Homecountry_UnitedKingdom\"\n",
    "HOMECOUNTRY_UNITEDSTATESOFAMERICA = \"Homecountry_UnitedStatesofAmerica\"\n",
    "RATING = \"Rating\"\n",
    "AD_NUM_FACES = \"ad_num_faces\"\n",
    "AD_LABEL_FEATURE_1 = 'ad_isAdvertising'\n",
    "AD_LABEL_FEATURE_2 = 'ad_isBrand'\n",
    "AD_LABEL_FEATURE_3 = 'ad_isElectronic device'\n",
    "AD_LABEL_FEATURE_4 = 'ad_isElectronics'\n",
    "AD_LABEL_FEATURE_5 = 'ad_isFashion accessory'\n",
    "AD_LABEL_FEATURE_6 = 'ad_isFictional character'\n",
    "AD_LABEL_FEATURE_7 = 'ad_isFont'\n",
    "AD_LABEL_FEATURE_8 = 'ad_isFurniture'\n",
    "AD_LABEL_FEATURE_9 = 'ad_isGadget'\n",
    "AD_LABEL_FEATURE_10 = 'ad_isGames'\n",
    "AD_LABEL_FEATURE_11 = 'ad_isGraphic design'\n",
    "AD_LABEL_FEATURE_12 = 'ad_isGraphics'\n",
    "AD_LABEL_FEATURE_13 = 'ad_isJewellery'\n",
    "AD_LABEL_FEATURE_14 = 'ad_isLine'\n",
    "AD_LABEL_FEATURE_15 = 'ad_isLogo'\n",
    "AD_LABEL_FEATURE_16 = 'ad_isMagenta'\n",
    "AD_LABEL_FEATURE_17 = 'ad_isMaterial property'\n",
    "AD_LABEL_FEATURE_18 = 'ad_isMultimedia'\n",
    "AD_LABEL_FEATURE_19 = 'ad_isProduct'\n",
    "AD_LABEL_FEATURE_20 = 'ad_isRectangle'\n",
    "AD_LABEL_FEATURE_21 = 'ad_isSkin'\n",
    "AD_LABEL_FEATURE_22 = 'ad_isTechnology'\n",
    "AD_LABEL_FEATURE_23 = 'ad_isText'\n",
    "AD_LABEL_FEATURE_24 = 'ad_isVehicle'\n",
    "AD_LABEL_FEATURE_25 = 'ad_isYellow'\n",
    "AD_SAFESEARCH_FEATURE_1 = 'ad_isAdult_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_2 ='ad_isAdult_VERY_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_3 ='ad_isSpoof_POSSIBLE'\n",
    "AD_SAFESEARCH_FEATURE_4 ='ad_isSpoof_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_5 ='ad_isSpoof_VERY_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_6 ='ad_isMedical_POSSIBLE'\n",
    "AD_SAFESEARCH_FEATURE_7 ='ad_isMedical_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_8 ='ad_isMedical_VERY_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_9 ='ad_isViolence_VERY_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_10 ='ad_isRacy_POSSIBLE'\n",
    "AD_SAFESEARCH_FEATURE_11 ='ad_isRacy_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_12 ='ad_isRacy_VERY_LIKELY'\n",
    "AD_SAFESEARCH_FEATURE_13 ='ad_isRacy_VERY_UNLIKELY'\n",
    "\n",
    "# Read all columns as strings to avoid any errors\n",
    "COL_DEFAULTS = {\n",
    "    USER_ID: \"**\",\n",
    "    AD_ID: \"**\",\n",
    "    AGE: \"**\",\n",
    "    ZIP_CODE: \"**\",\n",
    "    COUNTRIES_VISITED: \"**\",\n",
    "    FAVE_SPORTS: \"**\",\n",
    "    GENDER: \"**\",\n",
    "    HOME_COUNTRY: \"**\",\n",
    "    HOME_TOWN: \"**\",\n",
    "    INCOME: \"**\",\n",
    "    LAST_NAME: \"**\",\n",
    "    MOST_LISTENED_MUSICS: \"**\",\n",
    "    MOST_READ_BOOKS: \"**\",\n",
    "    MOST_VISITED_WEBSITES: \"**\",\n",
    "    MOST_WATCHED_MOVIES: \"**\",\n",
    "    MOST_WATCHED_TV_PROGRAMMES: \"**\",\n",
    "    NAME: \"**\",\n",
    "    PAYPAL: \"**\",\n",
    "    TIMEPASS: \"**\",\n",
    "    TYPE_OF_JOB: \"**\",\n",
    "    WEEKLY_WORKING_HOURS: \"**\",\n",
    "    FAVE1: \"**\",\n",
    "    FAVE10: \"**\",\n",
    "    FAVE2: \"**\",\n",
    "    FAVE3: \"**\",\n",
    "    FAVE4: \"**\",\n",
    "    FAVE5: \"**\",\n",
    "    FAVE6: \"**\",\n",
    "    FAVE7: \"**\",\n",
    "    FAVE8: \"**\",\n",
    "    FAVE9: \"**\",\n",
    "    UNFAVE1: \"**\",\n",
    "    UNFAVE2: \"**\",\n",
    "    UNFAVE3: \"**\",\n",
    "    UNFAVE4: \"**\",\n",
    "    UNFAVE5: \"**\",\n",
    "    UNFAVE6: \"**\",\n",
    "    ADFILEPATH: \"**\",\n",
    "    GENDER_F: \"**\",\n",
    "    GENDER_M: \"**\",\n",
    "    HOMECOUNTRY_CANADA: \"**\",\n",
    "    HOMECOUNTRY_CZECHREPUBLIC: \"**\",\n",
    "    HOMECOUNTRY_GREATBRITAIN: \"**\",\n",
    "    HOMECOUNTRY_INDIA: \"**\",\n",
    "    HOMECOUNTRY_ITALY: \"**\",\n",
    "    HOMECOUNTRY_PHILLIPINES: \"**\",\n",
    "    HOMECOUNTRY_ROMANIA: \"**\",\n",
    "    HOMECOUNTRY_SAUDIARABIA: \"**\",\n",
    "    HOMECOUNTRY_SINGAPORE: \"**\",\n",
    "    HOMECOUNTRY_SLOVENIA: \"**\",\n",
    "    HOMECOUNTRY_UNITEDKINGDOM: \"**\",\n",
    "    HOMECOUNTRY_UNITEDSTATESOFAMERICA: \"**\",\n",
    "    RATING: \"**\",\n",
    "    AD_NUM_FACES: \"**\"\n",
    "}\n",
    "\n",
    "# SELECTED_COLS = [AGE, ZIP_CODE, FAVE_SPORTS, GENDER, HOME_COUNTRY, HOME_TOWN, INCOME, MOST_LISTENED_MUSICS, MOST_READ_BOOKS, \n",
    "#                  MOST_VISITED_WEBSITES, MOST_WATCHED_MOVIES, MOST_WATCHED_TV_PROGRAMMES, TIMEPASS, TYPE_OF_JOB, WEEKLY_WORKING_HOURS, \n",
    "#                  FAVE1, FAVE2, FAVE3, FAVE4, FAVE5, FAVE6, FAVE7, FAVE8, FAVE9, FAVE10, UNFAVE1, UNFAVE2, UNFAVE3, UNFAVE4, UNFAVE5, \n",
    "#                  UNFAVE6, RATING]\n",
    "\n",
    "AD_FACE_COLS = [AD_NUM_FACES]\n",
    "AD_LABEL_COLS = [AD_LABEL_FEATURE_1,AD_LABEL_FEATURE_2,AD_LABEL_FEATURE_3,AD_LABEL_FEATURE_4,AD_LABEL_FEATURE_5,\n",
    "                AD_LABEL_FEATURE_6,AD_LABEL_FEATURE_7,AD_LABEL_FEATURE_8,AD_LABEL_FEATURE_9,AD_LABEL_FEATURE_10,\n",
    "                AD_LABEL_FEATURE_11,AD_LABEL_FEATURE_12,AD_LABEL_FEATURE_13,AD_LABEL_FEATURE_14,AD_LABEL_FEATURE_15,\n",
    "                AD_LABEL_FEATURE_16,AD_LABEL_FEATURE_17,AD_LABEL_FEATURE_18,AD_LABEL_FEATURE_19,AD_LABEL_FEATURE_20,\n",
    "                AD_LABEL_FEATURE_21,AD_LABEL_FEATURE_22,AD_LABEL_FEATURE_23,AD_LABEL_FEATURE_24,AD_LABEL_FEATURE_25]\n",
    "AD_OBJECT_COLS = []\n",
    "AD_SAFE_SEARCH_COLS = [AD_SAFESEARCH_FEATURE_1,AD_SAFESEARCH_FEATURE_2,AD_SAFESEARCH_FEATURE_3,AD_SAFESEARCH_FEATURE_4,\n",
    "                      AD_SAFESEARCH_FEATURE_5,AD_SAFESEARCH_FEATURE_6,AD_SAFESEARCH_FEATURE_7,AD_SAFESEARCH_FEATURE_8,\n",
    "                      AD_SAFESEARCH_FEATURE_9,AD_SAFESEARCH_FEATURE_10,AD_SAFESEARCH_FEATURE_11,AD_SAFESEARCH_FEATURE_12,AD_SAFESEARCH_FEATURE_13]\n",
    "\n",
    "\n",
    "SELECTED_AD_COLS = AD_FACE_COLS  + AD_LABEL_COLS + AD_OBJECT_COLS + AD_SAFE_SEARCH_COLS\n",
    "\n",
    "SELECTED_HOMECOUNTRY_COLS = [HOMECOUNTRY_CANADA, HOMECOUNTRY_CZECHREPUBLIC, HOMECOUNTRY_GREATBRITAIN,\n",
    "                             HOMECOUNTRY_INDIA, HOMECOUNTRY_ITALY, HOMECOUNTRY_PHILLIPINES, HOMECOUNTRY_ROMANIA,\n",
    "                             HOMECOUNTRY_SAUDIARABIA, HOMECOUNTRY_SINGAPORE, HOMECOUNTRY_SLOVENIA,\n",
    "                             HOMECOUNTRY_UNITEDKINGDOM, HOMECOUNTRY_UNITEDSTATESOFAMERICA]\n",
    "\n",
    "SELECTED_INP_COLS = [AGE, ZIP_CODE, FAVE_SPORTS, GENDER_F, GENDER_M] + SELECTED_AD_COLS + SELECTED_HOMECOUNTRY_COLS\n",
    "SELECTED_COLS = SELECTED_INP_COLS + [TARGET_COL]\n",
    "\n",
    "SELECTED_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ad_dataset_pd():\n",
    "    return pd.read_csv(users_ads_rating_csv, usecols=SELECTED_COLS, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>CapZipCode</th>\n",
       "      <th>FaveSports</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>Homecountry_Canada</th>\n",
       "      <th>Homecountry_CzechRepublic</th>\n",
       "      <th>Homecountry_GreatBritain</th>\n",
       "      <th>Homecountry_India</th>\n",
       "      <th>...</th>\n",
       "      <th>ad_isSpoof_UNLIKELY</th>\n",
       "      <th>ad_isSpoof_VERY_UNLIKELY</th>\n",
       "      <th>ad_isMedical_POSSIBLE</th>\n",
       "      <th>ad_isMedical_UNLIKELY</th>\n",
       "      <th>ad_isMedical_VERY_UNLIKELY</th>\n",
       "      <th>ad_isViolence_VERY_UNLIKELY</th>\n",
       "      <th>ad_isRacy_POSSIBLE</th>\n",
       "      <th>ad_isRacy_UNLIKELY</th>\n",
       "      <th>ad_isRacy_VERY_LIKELY</th>\n",
       "      <th>ad_isRacy_VERY_UNLIKELY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34306</th>\n",
       "      <td>21</td>\n",
       "      <td>L5M 7X7</td>\n",
       "      <td>Indoor sports</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16097</th>\n",
       "      <td>21</td>\n",
       "      <td>E82 2J4</td>\n",
       "      <td>Individual sports‎ (Tennis, Archery, ...), Tea...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7056</th>\n",
       "      <td>33</td>\n",
       "      <td>60660</td>\n",
       "      <td>Equestrian sports‎</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td>19</td>\n",
       "      <td>N2K4C2</td>\n",
       "      <td>Team sports (Footbal, Baseball, Rugby, ...) , ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>24</td>\n",
       "      <td>NW1 1EU</td>\n",
       "      <td>Individual sports‎ (Tennis, Archery, ...)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6405</th>\n",
       "      <td>27</td>\n",
       "      <td>90650</td>\n",
       "      <td>Team sports (Footbal, Baseball, Rugby, ...)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18518</th>\n",
       "      <td>48</td>\n",
       "      <td>t6c 3e8</td>\n",
       "      <td>Indoor sports, Precision sports‎ (Golf, Bowlin...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32941</th>\n",
       "      <td>52</td>\n",
       "      <td>7095</td>\n",
       "      <td>Individual sports‎ (Tennis, Archery, ...), Tea...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5894</th>\n",
       "      <td>22</td>\n",
       "      <td>11415</td>\n",
       "      <td>Individual sports‎ (Tennis, Archery, ...), Tea...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16825</th>\n",
       "      <td>25</td>\n",
       "      <td>CH44 4BW</td>\n",
       "      <td>I do not like Sports</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age CapZipCode                                         FaveSports  \\\n",
       "34306  21    L5M 7X7                                      Indoor sports   \n",
       "16097  21    E82 2J4  Individual sports‎ (Tennis, Archery, ...), Tea...   \n",
       "7056   33      60660                                 Equestrian sports‎   \n",
       "7982   19     N2K4C2  Team sports (Footbal, Baseball, Rugby, ...) , ...   \n",
       "1182   24    NW1 1EU          Individual sports‎ (Tennis, Archery, ...)   \n",
       "6405   27      90650       Team sports (Footbal, Baseball, Rugby, ...)    \n",
       "18518  48    t6c 3e8  Indoor sports, Precision sports‎ (Golf, Bowlin...   \n",
       "32941  52       7095  Individual sports‎ (Tennis, Archery, ...), Tea...   \n",
       "5894   22      11415  Individual sports‎ (Tennis, Archery, ...), Tea...   \n",
       "16825  25   CH44 4BW                               I do not like Sports   \n",
       "\n",
       "      Rating Gender_F Gender_M Homecountry_Canada Homecountry_CzechRepublic  \\\n",
       "34306    1.0        1        0                  1                         0   \n",
       "16097    2.0        1        0                  1                         0   \n",
       "7056     2.0        1        0                  0                         0   \n",
       "7982     1.0        0        1                  1                         0   \n",
       "1182     4.0        1        0                  0                         0   \n",
       "6405     1.0        1        0                  0                         0   \n",
       "18518    2.0        0        1                  1                         0   \n",
       "32941    4.0        1        0                  0                         0   \n",
       "5894     1.0        0        1                  0                         0   \n",
       "16825    1.0        0        1                  0                         0   \n",
       "\n",
       "      Homecountry_GreatBritain Homecountry_India  ... ad_isSpoof_UNLIKELY  \\\n",
       "34306                        0                 0  ...                   0   \n",
       "16097                        0                 0  ...                   0   \n",
       "7056                         0                 0  ...                   0   \n",
       "7982                         0                 0  ...                   0   \n",
       "1182                         1                 0  ...                   0   \n",
       "6405                         0                 0  ...                   0   \n",
       "18518                        0                 0  ...                   1   \n",
       "32941                        0                 0  ...                   1   \n",
       "5894                         0                 0  ...                   0   \n",
       "16825                        0                 0  ...                   0   \n",
       "\n",
       "      ad_isSpoof_VERY_UNLIKELY ad_isMedical_POSSIBLE ad_isMedical_UNLIKELY  \\\n",
       "34306                        1                     0                     1   \n",
       "16097                        1                     0                     1   \n",
       "7056                         1                     0                     0   \n",
       "7982                         1                     0                     1   \n",
       "1182                         0                     0                     0   \n",
       "6405                         1                     0                     1   \n",
       "18518                        0                     0                     1   \n",
       "32941                        0                     0                     1   \n",
       "5894                         1                     0                     0   \n",
       "16825                        1                     0                     0   \n",
       "\n",
       "      ad_isMedical_VERY_UNLIKELY ad_isViolence_VERY_UNLIKELY  \\\n",
       "34306                          0                           1   \n",
       "16097                          0                           1   \n",
       "7056                           1                           1   \n",
       "7982                           0                           1   \n",
       "1182                           1                           1   \n",
       "6405                           0                           1   \n",
       "18518                          0                           1   \n",
       "32941                          0                           1   \n",
       "5894                           1                           1   \n",
       "16825                          1                           1   \n",
       "\n",
       "      ad_isRacy_POSSIBLE ad_isRacy_UNLIKELY ad_isRacy_VERY_LIKELY  \\\n",
       "34306                  0                  0                     0   \n",
       "16097                  0                  0                     0   \n",
       "7056                   0                  0                     0   \n",
       "7982                   0                  0                     0   \n",
       "1182                   0                  0                     0   \n",
       "6405                   0                  0                     0   \n",
       "18518                  0                  0                     0   \n",
       "32941                  0                  0                     0   \n",
       "5894                   0                  0                     0   \n",
       "16825                  0                  0                     0   \n",
       "\n",
       "      ad_isRacy_VERY_UNLIKELY  \n",
       "34306                       1  \n",
       "16097                       1  \n",
       "7056                        1  \n",
       "7982                        1  \n",
       "1182                        1  \n",
       "6405                        1  \n",
       "18518                       1  \n",
       "32941                       1  \n",
       "5894                        1  \n",
       "16825                       1  \n",
       "\n",
       "[10 rows x 57 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_dataset_pd().sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_project(d:Dict, cols:List[str]) -> Dict:\n",
    "    return {k:v for k, v in d.items() if k in cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexerForVocab:\n",
    "    def __init__(self, vocab_list:List[str], oov_index:int=0):\n",
    "        \"\"\"\n",
    "        Creates a string indexer for the vocabulary with out of vocabulary (oov) indexing\n",
    "        \"\"\"\n",
    "        self._vocab_map = {v:i+1 for i, v in enumerate(vocab_list)}\n",
    "        self._oov = oov_index\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"Map for {len(self)} keys with 1 OOV key\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._vocab_map) + 1\n",
    "        \n",
    "    def index_of(self, item:str):\n",
    "        \"\"\"\n",
    "        Index of item in the vocabulary\n",
    "        \"\"\"\n",
    "        return self._vocab_map.get(item, self._oov)\n",
    "    \n",
    "    def index_of_mux(self, items:List[str]):\n",
    "        return [self.index_of(i) for i in items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age\n",
    "\n",
    "Convert to a number and remove any outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained from Tensorflow Data Validation APIs data-exploration/tensorflow-data-validation.ipynb\n",
    "\n",
    "MEAN_AGE, STD_AGE, MEDIAN_AGE, MAX_AGE = 31.74, 12.07, 29, 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_age(age_str:tf.string, default_age=MEDIAN_AGE) -> int:\n",
    "    \"\"\"Typecast age to an integer and update outliers with the default\"\"\"\n",
    "    try:\n",
    "        age = int(age_str)\n",
    "        if age < 0 or age > MAX_AGE:\n",
    "            raise ValueError(f\"{age} is not a valid age\")\n",
    "    except:\n",
    "        age = default_age\n",
    "    normalized_age = (age - MEAN_AGE) / STD_AGE\n",
    "    return normalized_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5128417564208783,\n",
       " -0.22700911350455663,\n",
       " -0.22700911350455663,\n",
       " -0.22700911350455663,\n",
       " -0.22700911350455663)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_age(\"50\"), fix_age(\"50.5\"), fix_age(\"-10\"), fix_age(\"bad_age_10\"), fix_age(\"300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip Code\n",
    "\n",
    "Prepare zip-code column for one-hot encoding each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_ZIP_CODE, FIRST_K_ZIP_DIGITS = \"00000\", 2\n",
    "\n",
    "zip_code_indexer = IndexerForVocab(string.digits + string.ascii_lowercase + string.ascii_uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_zip_code_tensor(zip_code:tf.string, n_digits, indexer) -> List[str]:\n",
    "    \"\"\"Extracts the the first n_digits as a list\"\"\"\n",
    "    zip_digits = []\n",
    "    try:\n",
    "        if isinstance(zip_code, tf.Tensor):\n",
    "            zip_code = zip_code.numpy()[0].decode('ascii', errors=\"ignore\") # very ineffecient way\n",
    "        zip_digits = list(zip_code.strip()[:n_digits])\n",
    "    except:\n",
    "        zip_digits = list(DEFAULT_ZIP_CODE[:n_digits])\n",
    "    return tf.concat( [\n",
    "        tf.one_hot(\n",
    "            indexer.index_of(d), len(indexer)\n",
    "        ) for d in zip_digits\n",
    "    ], 0 )\n",
    "\n",
    "def fix_zip_code(zip_code:str, n_digits, indexer) -> List[str]:\n",
    "    \"\"\"Extracts the the first n_digits as a list\"\"\"\n",
    "    zip_digits = []\n",
    "    try:\n",
    "        zip_digits = list(zip_code.strip()[:n_digits])\n",
    "    except:\n",
    "        zip_digits = list(DEFAULT_ZIP_CODE[:n_digits])\n",
    "    return np.ravel(np.eye(len(indexer))[indexer.index_of_mux(zip_digits)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_zip_code_indexer = IndexerForVocab(string.digits)\n",
    "\n",
    "(fix_zip_code(\"43556\", 10, test_zip_code_indexer),\n",
    "fix_zip_code(\"43556\", 2, test_zip_code_indexer),\n",
    "fix_zip_code(\"43556\", 4, test_zip_code_indexer),\n",
    "fix_zip_code(None, 3, test_zip_code_indexer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Favorite Sports\n",
    "\n",
    "Two approaches,\n",
    "1. Consider the first `K` sports mentioned by each user and one-hot encode each separately\n",
    "2. Multi label binarize all the sports as there are only 15 unique sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=None, sparse_output=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FAV_SPORTS_UNKNOWN = \"UNK_SPORT\"\n",
    "ALL_FAV_SPORTS = ['Olympic sports', 'Winter sports', 'Nothing', 'I do not like Sports', 'Equestrian sports', 'Skating sports', 'Precision sports', 'Hunting sports', 'Motor sports', 'Team sports', 'Individual sports', 'Other', 'Water sports', 'Indoor sports', 'Endurance sports']\n",
    "\n",
    "fav_sports_binarizer = MultiLabelBinarizer()\n",
    "fav_sports_binarizer.fit([ALL_FAV_SPORTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fav_sports_multi_select_str_to_list(sports_str:Union[str, tf.Tensor]) -> List[str]:\n",
    "    # remove commas that dont separate different user selections\n",
    "    # example, commas inside paranthesis of \"Individual sports (Tennis, Archery, ...)\" dont make new sports\n",
    "    if isinstance(sports_str, tf.Tensor):\n",
    "        sports_str = sports_str.numpy()[0].decode('ascii', errors=\"ignore\")\n",
    "    else:\n",
    "        sports_str = sports_str.encode(\"ascii\", errors=\"ignore\").decode(\"ascii\") # remove non-ascii chars\n",
    "    sports = re.sub(r\"\\s*\\(.*,.*\\)\\s*\", \"\", sports_str)\n",
    "    return re.split(r\"\\s*,\\s*\", sports)\n",
    "\n",
    "def fix_fav_sports_mlb(sports_str:str) -> List[int]:\n",
    "    sports = fav_sports_multi_select_str_to_list(sports_str)\n",
    "    return fav_sports_binarizer.transform([sports])[0]\n",
    "\n",
    "def fix_fav_sports_firstk(sports_str:str, first_k:int, pad_constant:int) -> List[str]:\n",
    "    sports = fav_sports_multi_select_str_to_list(sports_str)\n",
    "    right_pad_width = first_k - len(sports_enc)\n",
    "    result = [sports + [pad_constant] * right_pad_width][:first_k]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    fix_fav_sports_mlb(\"Individual sports (Tennis, Archery, ...), Indoor sports, Endurance sports, Skating sports\"),\n",
    "    fix_fav_sports_mlb(\"Skating sports\"),\n",
    "    fix_fav_sports_mlb(\"Individual sports (Tennis, Archery, ...)\"),\n",
    "    fix_fav_sports_mlb(\"Indoor sports, Endurance sports, Skating sports\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATINGS_CARDINALITY = 5 # not zero based indexing i.e. ratings range from 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_pd(rating_str:str):\n",
    "    return np.eye(RATINGS_CARDINALITY, dtype=int)[int(float(rating_str)) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pd_X(df:pd.DataFrame, inp_cols:List[str]):\n",
    "    \"\"\"Original dataframe will be modified\"\"\"\n",
    "    df[AGE] = df[AGE].apply(lambda age: [fix_age(age)])\n",
    "    df[ZIP_CODE] = df[ZIP_CODE].apply(lambda zc: fix_zip_code(zc, n_digits=2, indexer=zip_code_indexer))\n",
    "    df[FAVE_SPORTS] = df[FAVE_SPORTS].apply(fix_fav_sports_mlb)\n",
    "    df[GENDER_F] = df[GENDER_F].apply(lambda gender_f: [int(gender_f)])\n",
    "    df[GENDER_M] = df[GENDER_M].apply(lambda gender_m: [int(gender_m)])\n",
    "    df[AD_NUM_FACES] = df[AD_NUM_FACES].apply(lambda ad_num_faces: [int(ad_num_faces)])\n",
    "    \n",
    "    df[AD_LABEL_FEATURE_1] = df[AD_LABEL_FEATURE_1].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_2] = df[AD_LABEL_FEATURE_2].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_3] = df[AD_LABEL_FEATURE_3].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_4] = df[AD_LABEL_FEATURE_4].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_5] = df[AD_LABEL_FEATURE_5].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_6] = df[AD_LABEL_FEATURE_6].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_7] = df[AD_LABEL_FEATURE_7].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_8] = df[AD_LABEL_FEATURE_8].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_9] = df[AD_LABEL_FEATURE_9].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_10] = df[AD_LABEL_FEATURE_10].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_11] = df[AD_LABEL_FEATURE_11].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_12] = df[AD_LABEL_FEATURE_12].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_13] = df[AD_LABEL_FEATURE_13].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_14] = df[AD_LABEL_FEATURE_14].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_15] = df[AD_LABEL_FEATURE_15].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_16] = df[AD_LABEL_FEATURE_16].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_17] = df[AD_LABEL_FEATURE_17].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_18] = df[AD_LABEL_FEATURE_18].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_19] = df[AD_LABEL_FEATURE_19].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_20] = df[AD_LABEL_FEATURE_20].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_21] = df[AD_LABEL_FEATURE_21].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_22] = df[AD_LABEL_FEATURE_22].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_23] = df[AD_LABEL_FEATURE_23].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_24] = df[AD_LABEL_FEATURE_24].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_25] = df[AD_LABEL_FEATURE_25].apply(lambda f: [int(f)])\n",
    "    \n",
    "    df[AD_SAFESEARCH_FEATURE_1] = df[AD_SAFESEARCH_FEATURE_1].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_2] = df[AD_SAFESEARCH_FEATURE_2].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_3] = df[AD_SAFESEARCH_FEATURE_3].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_4] = df[AD_SAFESEARCH_FEATURE_4].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_5] = df[AD_SAFESEARCH_FEATURE_5].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_6] = df[AD_SAFESEARCH_FEATURE_6].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_7] = df[AD_SAFESEARCH_FEATURE_7].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_8] = df[AD_SAFESEARCH_FEATURE_8].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_9] = df[AD_SAFESEARCH_FEATURE_9].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_10] = df[AD_SAFESEARCH_FEATURE_10].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_11] = df[AD_SAFESEARCH_FEATURE_11].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_12] = df[AD_SAFESEARCH_FEATURE_12].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_13] = df[AD_SAFESEARCH_FEATURE_13].apply(lambda f: [int(f)])\n",
    "            \n",
    "    df[HOMECOUNTRY_CANADA] = df[HOMECOUNTRY_CANADA].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_CZECHREPUBLIC] = df[HOMECOUNTRY_CZECHREPUBLIC].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_GREATBRITAIN] = df[HOMECOUNTRY_GREATBRITAIN].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_INDIA] = df[HOMECOUNTRY_INDIA].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_ITALY] = df[HOMECOUNTRY_ITALY].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_PHILLIPINES] = df[HOMECOUNTRY_PHILLIPINES].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_ROMANIA] = df[HOMECOUNTRY_ROMANIA].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_SAUDIARABIA] = df[HOMECOUNTRY_SAUDIARABIA].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_SINGAPORE] = df[HOMECOUNTRY_SINGAPORE].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_SLOVENIA] = df[HOMECOUNTRY_SLOVENIA].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_UNITEDKINGDOM] = df[HOMECOUNTRY_UNITEDKINGDOM].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_UNITEDSTATESOFAMERICA] = df[HOMECOUNTRY_UNITEDSTATESOFAMERICA].apply(lambda f: [int(f)])\n",
    "    \n",
    "    df[\"X\"] = df[inp_cols].apply(np.concatenate, axis=1)\n",
    "    # TODO: vectorize, else inefficient to sequentially loop over all example\n",
    "    X = np.array([x for x in df[\"X\"]])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pd_y(df:pd.DataFrame, target_col:str):\n",
    "    \"\"\"Original dataframe will be modified\"\"\"\n",
    "    df[\"y\"] = df[target_col].apply(create_target_pd)\n",
    "    # TODO: vectorize, else inefficient to sequentially loop over all example\n",
    "    y = np.array([y for y in df[\"y\"]])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_pd(inp_cols:List[str]=SELECTED_INP_COLS, target_col:str=TARGET_COL, fraction:float=1) -> pd.DataFrame:\n",
    "    \"\"\"Prepare the dataset for training on a fraction of all input data\"\"\"\n",
    "    df = ad_dataset_pd().sample(frac=fraction)\n",
    "    return transform_pd_X(df, inp_cols), transform_pd_y(df, target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tensorboard\n",
    "\n",
    "Monitor training and other stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Start tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 77956), started 6:36:47 ago. (Use '!kill 77956' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-aa2e498f48cd5e44\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-aa2e498f48cd5e44\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir logs (started 6:36:47 ago; pid 77956)\n"
     ]
    }
   ],
   "source": [
    "notebook.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Create a model and train using high level APIs like `tf.keras` and `tf.estimator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 690 ms, total: 1min 6s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train_dataset = input_fn_train(BATCH_SIZE)\n",
    "X, y = create_dataset_pd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.metrics.SensitivityAtSpecificity(name=\"ss\")  # For false positive rate\n",
    "\n",
    "keras_model_metrics = [\n",
    "    \"accuracy\",\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc')\n",
    "]\n",
    "train_histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T CHANGE THE EPOCHS VALUE\n",
    "BATCH_SIZE = 4096\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging tensorboard data at logs/20200502-004149\n"
     ]
    }
   ],
   "source": [
    "logdir = Path(\"logs\")/datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    logdir, \n",
    "    histogram_freq=max(1, ceil(EPOCHS / 20)), # to control the amount of logging\n",
    "#     embeddings_freq=epochs,\n",
    ")\n",
    "print(f\"Logging tensorboard data at {logdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                3920      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 4,025\n",
      "Trainable params: 4,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(20, input_shape=(X.shape[1],), activation=tf.keras.layers.LeakyReLU()),\n",
    "    tf.keras.layers.Dense(RATINGS_CARDINALITY , activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(\n",
    "        learning_rate=0.003,\n",
    "        clipvalue=0.5\n",
    "    ), \n",
    "#     optimizer=tf.keras.optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True), \n",
    "#     optimizer=tf.keras.optimizers.RMSprop(lr),\n",
    "#     loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=keras_model_metrics\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, accuracy:0.4198,  auc:0.6641,  fn:28722.0000,  fp:67.0000,  loss:1.5080,  precision:0.5379,  recall:0.0027,  tn:115133.0000,  tp:78.0000,  val_accuracy:0.5646,  val_auc:0.7276,  val_fn:6600.0000,  val_fp:418.0000,  val_loss:1.3449,  val_precision:0.5894,  val_recall:0.0833,  val_tn:28382.0000,  val_tp:600.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.6224,  auc:0.8696,  fn:14109.0000,  fp:5441.0000,  loss:1.0069,  precision:0.7297,  recall:0.5101,  tn:109759.0000,  tp:14691.0000,  val_accuracy:0.6250,  val_auc:0.8674,  val_fn:3572.0000,  val_fp:1314.0000,  val_loss:1.0136,  val_precision:0.7341,  val_recall:0.5039,  val_tn:27486.0000,  val_tp:3628.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.6281,  auc:0.8750,  fn:14437.0000,  fp:4877.0000,  loss:0.9862,  precision:0.7465,  recall:0.4987,  tn:110323.0000,  tp:14363.0000,  val_accuracy:0.6228,  val_auc:0.8704,  val_fn:3501.0000,  val_fp:1333.0000,  val_loss:1.0029,  val_precision:0.7351,  val_recall:0.5138,  val_tn:27467.0000,  val_tp:3699.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.6297,  auc:0.8781,  fn:13995.0000,  fp:5230.0000,  loss:0.9743,  precision:0.7390,  recall:0.5141,  tn:109970.0000,  tp:14805.0000,  val_accuracy:0.6276,  val_auc:0.8707,  val_fn:3661.0000,  val_fp:1214.0000,  val_loss:1.0005,  val_precision:0.7446,  val_recall:0.4915,  val_tn:27586.0000,  val_tp:3539.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.6335,  auc:0.8796,  fn:14386.0000,  fp:4729.0000,  loss:0.9686,  precision:0.7530,  recall:0.5005,  tn:110471.0000,  tp:14414.0000,  val_accuracy:0.6254,  val_auc:0.8715,  val_fn:3484.0000,  val_fp:1377.0000,  val_loss:0.9994,  val_precision:0.7296,  val_recall:0.5161,  val_tn:27423.0000,  val_tp:3716.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.6342,  auc:0.8813,  fn:14112.0000,  fp:4902.0000,  loss:0.9613,  precision:0.7498,  recall:0.5100,  tn:110298.0000,  tp:14688.0000,  val_accuracy:0.6283,  val_auc:0.8725,  val_fn:3474.0000,  val_fp:1377.0000,  val_loss:0.9965,  val_precision:0.7302,  val_recall:0.5175,  val_tn:27423.0000,  val_tp:3726.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.6352,  auc:0.8825,  fn:14064.0000,  fp:4852.0000,  loss:0.9565,  precision:0.7523,  recall:0.5117,  tn:110348.0000,  tp:14736.0000,  val_accuracy:0.6265,  val_auc:0.8730,  val_fn:3468.0000,  val_fp:1373.0000,  val_loss:0.9945,  val_precision:0.7310,  val_recall:0.5183,  val_tn:27427.0000,  val_tp:3732.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.6373,  auc:0.8832,  fn:14209.0000,  fp:4662.0000,  loss:0.9544,  precision:0.7579,  recall:0.5066,  tn:110538.0000,  tp:14591.0000,  val_accuracy:0.6269,  val_auc:0.8727,  val_fn:3489.0000,  val_fp:1342.0000,  val_loss:0.9945,  val_precision:0.7344,  val_recall:0.5154,  val_tn:27458.0000,  val_tp:3711.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.6402,  auc:0.8845,  fn:13984.0000,  fp:4866.0000,  loss:0.9487,  precision:0.7528,  recall:0.5144,  tn:110334.0000,  tp:14816.0000,  val_accuracy:0.6243,  val_auc:0.8722,  val_fn:3615.0000,  val_fp:1242.0000,  val_loss:0.9953,  val_precision:0.7427,  val_recall:0.4979,  val_tn:27558.0000,  val_tp:3585.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.6398,  auc:0.8851,  fn:13917.0000,  fp:4808.0000,  loss:0.9459,  precision:0.7558,  recall:0.5168,  tn:110392.0000,  tp:14883.0000,  val_accuracy:0.6240,  val_auc:0.8735,  val_fn:3465.0000,  val_fp:1376.0000,  val_loss:0.9939,  val_precision:0.7308,  val_recall:0.5188,  val_tn:27424.0000,  val_tp:3735.0000,  \n",
      "....................................................................................................CPU times: user 13min 29s, sys: 1min 53s, total: 15min 23s\n",
      "Wall time: 3min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_histories.append(model.fit(\n",
    "    X, y,\n",
    "    BATCH_SIZE,\n",
    "    epochs=EPOCHS, \n",
    "    callbacks=[tensorboard_callback, tfdocs.modeling.EpochDots()],\n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_tp</th>\n",
       "      <th>val_fp</th>\n",
       "      <th>val_tn</th>\n",
       "      <th>val_fn</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.944639</td>\n",
       "      <td>0.639722</td>\n",
       "      <td>14817.0</td>\n",
       "      <td>4824.0</td>\n",
       "      <td>110376.0</td>\n",
       "      <td>13983.0</td>\n",
       "      <td>0.754391</td>\n",
       "      <td>0.514479</td>\n",
       "      <td>0.885396</td>\n",
       "      <td>0.995335</td>\n",
       "      <td>0.621528</td>\n",
       "      <td>3638.0</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>27529.0</td>\n",
       "      <td>3562.0</td>\n",
       "      <td>0.741088</td>\n",
       "      <td>0.505278</td>\n",
       "      <td>0.872454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy       tp      fp        tn       fn  precision  \\\n",
       "999  0.944639  0.639722  14817.0  4824.0  110376.0  13983.0   0.754391   \n",
       "\n",
       "       recall       auc  val_loss  val_accuracy  val_tp  val_fp   val_tn  \\\n",
       "999  0.514479  0.885396  0.995335      0.621528  3638.0  1271.0  27529.0   \n",
       "\n",
       "     val_fn  val_precision  val_recall   val_auc  \n",
       "999  3562.0       0.741088    0.505278  0.872454  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(train_histories[-1].history) # pick the latest training history\n",
    "\n",
    "metrics_df.tail(1) # pick the last epoch's metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tip:` You can copy the final metrics row from above and paste it using `Shift + Cmd + V` in our [sheet](https://docs.google.com/spreadsheets/d/1v-nYiDA3elM1UP9stkB42MK0bTbuLxYJE7qAYDP8FHw/edit#gid=925421130) to accurately place all values in the respective columns\n",
    "\n",
    "**IMPORTANT**: Please don't forget to update git version ID column after you check-in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Metrics with p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n",
    "\n",
    "Save the model for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /export/apps/python/3.6.1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: logs/20200502-004149/keras_saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save((logdir/\"keras_saved_model\").as_posix(), save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Gender_F'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gender_F'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-fd508781cf61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m })\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_pd_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSELECTED_INP_COLS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpredicted_rating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-2f8a9d0f9e47>\u001b[0m in \u001b[0;36mtransform_pd_X\u001b[0;34m(df, inp_cols)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mZIP_CODE\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mZIP_CODE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mzc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfix_zip_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_digits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzip_code_indexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFAVE_SPORTS\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFAVE_SPORTS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfix_fav_sports_mlb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGENDER_F\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGENDER_F\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgender_f\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGENDER_M\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGENDER_M\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgender_m\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAD_NUM_FACES\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAD_NUM_FACES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mad_num_faces\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mad_num_faces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gender_F'"
     ]
    }
   ],
   "source": [
    "PredictionReport = namedtuple(\"PredictionReport\", \"probabilities predicted_rating confidence\")\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    AGE: [\"45\"],\n",
    "    ZIP_CODE: [\"94086\"],\n",
    "    FAVE_SPORTS: [\"I do not like Sports\"]\n",
    "})\n",
    "\n",
    "probabilities = model.predict(transform_pd_X(test_df, SELECTED_INP_COLS))\n",
    "predicted_rating, confidence = np.argmax(probabilities), np.max(probabilities)\n",
    "\n",
    "PredictionReport(probabilities, predicted_rating, confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Rough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Featurize using Feature Columns\n",
    "\n",
    "Create feature columns like one-hot, embeddings, bucketing from raw features created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EXAMPLE_BATCH = next(iter(input_fn_train(3)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EXAMPLE_BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_feature_column(feature_column):\n",
    "    feature_layer = tf.keras.layers.DenseFeatures(feature_column)\n",
    "    return feature_layer(EXAMPLE_BATCH).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "age_fc = tf.feature_column.numeric_column(AGE, normalizer_fn=lambda x: (x - MEAN_AGE) / STD_AGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "zip_fcs = [\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            f\"{ZIP_CODE}{i}\", vocabulary_list=list(string.digits), \n",
    "            num_oov_buckets=1)\n",
    "    )\n",
    "    for i in range(FIRST_K_ZIP_DIGITS)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EXAMPLE_BATCH[AGE], test_feature_column(age_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "{k: v for k, v in EXAMPLE_BATCH.items() if k.startswith(ZIP_CODE)}, test_feature_column(zip_fcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.keras.layers.concatenate(age_fc, zip_fcs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "221.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
