{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model\n",
    "\n",
    "The aim of the notebook is demo end to end pipeline for Ads prediction in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! ./setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tensorflow/docs\n",
      "  Cloning https://github.com/tensorflow/docs to /private/var/folders/f_/8flgl5n57_dfmnnjzy_w41wm0000gn/T/pip-req-build-zj9ti1z3\n",
      "  Running command git clone -q https://github.com/tensorflow/docs /private/var/folders/f_/8flgl5n57_dfmnnjzy_w41wm0000gn/T/pip-req-build-zj9ti1z3\n",
      "Requirement already satisfied (use --upgrade to upgrade): tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9- from git+https://github.com/tensorflow/docs in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages\n",
      "Requirement already satisfied: astor in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages (from tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9-) (0.8.1)\n",
      "Requirement already satisfied: absl-py in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages (from tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9-) (0.9.0)\n",
      "Requirement already satisfied: six in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages (from tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9-) (1.14.0)\n",
      "Requirement already satisfied: pathlib2 in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages (from tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9-) (2.3.5)\n",
      "Requirement already satisfied: pyyaml in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages (from tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9-) (5.3.1)\n",
      "Building wheels for collected packages: tensorflow-docs\n",
      "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0d92131b8cc983025d3b423255b1afb09683fbed9_-py3-none-any.whl size=98705 sha256=d918741b95d78f55b52fe18e571b925ccd6d05d6ccdf8419855f9a383f158d86\n",
      "  Stored in directory: /private/var/folders/f_/8flgl5n57_dfmnnjzy_w41wm0000gn/T/pip-ephem-wheel-cache-h1t38brr/wheels/cc/c4/d8/5341e93b6376c5c929c49469fce21155eb69cef1a4da4ce32c\n",
      "Successfully built tensorflow-docs\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q git+https://github.com/tensorflow/docs --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tensorflow, 2.1.0 on Python interpreter, sys.version_info(major=3, minor=6, micro=1, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from typing import Dict, Any, Union, List\n",
    "from functools import partial\n",
    "import re\n",
    "import string\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from math import ceil\n",
    "from collections import namedtuple\n",
    "\n",
    "print(f\"Using Tensorflow, {tf.__version__} on Python interpreter, {sys.version_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using random seed, 1588385897\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = int(time.time())\n",
    "\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"Using random seed, {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Dataset credits:\n",
    "```\n",
    "@inproceedings{roffo2016personality,\n",
    "  title={Personality in computational advertising: A benchmark},\n",
    "  author={Roffo, Giorgio and Vinciarelli, Alessandro},\n",
    "  booktitle={4 th Workshop on Emotions and Personality in Personalized Systems (EMPIRE) 2016},\n",
    "  pages={18},\n",
    "  year={2016}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"../../dataset/\")\n",
    "BATCH_SIZE = 4096 # bigger the batch, faster the training but bigger the RAM needed\n",
    "TARGET_COL = \"Rating\"\n",
    "\n",
    "# data files path are relative DATA_FOLDER\n",
    "users_ads_rating_csv = DATA_FOLDER/\"users-ads-without-gcp-ratings_OHE_MLB.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'CapZipCode',\n",
       " 'FaveSports',\n",
       " 'Gender_F',\n",
       " 'Gender_M',\n",
       " 'ad_num_faces',\n",
       " 'ad_isAdvertising',\n",
       " 'ad_isBrand',\n",
       " 'ad_isElectronic device',\n",
       " 'ad_isElectronics',\n",
       " 'ad_isFashion accessory',\n",
       " 'ad_isFictional character',\n",
       " 'ad_isFont',\n",
       " 'ad_isFurniture',\n",
       " 'ad_isGadget',\n",
       " 'ad_isGames',\n",
       " 'ad_isGraphic design',\n",
       " 'ad_isGraphics',\n",
       " 'ad_isJewellery',\n",
       " 'ad_isLine',\n",
       " 'ad_isLogo',\n",
       " 'ad_isMagenta',\n",
       " 'ad_isMaterial property',\n",
       " 'ad_isMultimedia',\n",
       " 'ad_isProduct',\n",
       " 'ad_isRectangle',\n",
       " 'ad_isSkin',\n",
       " 'ad_isTechnology',\n",
       " 'ad_isText',\n",
       " 'ad_isVehicle',\n",
       " 'ad_isYellow',\n",
       " 'ad_isAdult_UNLIKELY',\n",
       " 'ad_isAdult_VERY_UNLIKELY',\n",
       " 'ad_isSpoof_POSSIBLE',\n",
       " 'ad_isSpoof_UNLIKELY',\n",
       " 'ad_isSpoof_VERY_UNLIKELY',\n",
       " 'ad_isMedical_POSSIBLE',\n",
       " 'ad_isMedical_UNLIKELY',\n",
       " 'ad_isMedical_VERY_UNLIKELY',\n",
       " 'ad_isViolence_VERY_UNLIKELY',\n",
       " 'ad_isRacy_POSSIBLE',\n",
       " 'ad_isRacy_UNLIKELY',\n",
       " 'ad_isRacy_VERY_LIKELY',\n",
       " 'ad_isRacy_VERY_UNLIKELY',\n",
       " 'Homecountry_Canada',\n",
       " 'Homecountry_CzechRepublic',\n",
       " 'Homecountry_GreatBritain',\n",
       " 'Homecountry_India',\n",
       " 'Homecountry_Italy',\n",
       " 'Homecountry_Phillipines',\n",
       " 'Homecountry_Romania',\n",
       " 'Homecountry_SaudiArabia',\n",
       " 'Homecountry_Singapore',\n",
       " 'Homecountry_Slovenia',\n",
       " 'Homecountry_UnitedKingdom',\n",
       " 'Homecountry_UnitedStatesofAmerica',\n",
       " 'Income_0',\n",
       " 'Income_1',\n",
       " 'Income_2',\n",
       " 'Income_3',\n",
       " 'AlternativeMusic',\n",
       " 'AsianPopJPoporKpop',\n",
       " 'Blues',\n",
       " 'ClassicalMusic',\n",
       " 'CountryMusic',\n",
       " 'DanceMusic',\n",
       " 'EasyListening',\n",
       " 'ElectronicMusic',\n",
       " 'EuropeanMusicFolkPop',\n",
       " 'HipHopRap',\n",
       " 'IndiePop',\n",
       " 'InspirationalinclGospel',\n",
       " 'Jazz',\n",
       " 'LatinMusic',\n",
       " 'NewAge',\n",
       " 'Opera',\n",
       " 'PopPopularmusic',\n",
       " 'RampBSoul',\n",
       " 'Reggae',\n",
       " 'Rock',\n",
       " 'SingerSongwriterincFolk',\n",
       " 'WorldMusicBeats',\n",
       " 'Rating']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_ID = \"UserId\"\n",
    "AD_ID = \"AdId\"\n",
    "AGE = \"Age\"\n",
    "ZIP_CODE = \"CapZipCode\"\n",
    "COUNTRIES_VISITED = \"Countriesvisited\"\n",
    "FAVE_SPORTS = \"FaveSports\"\n",
    "GENDER = \"Gender\"\n",
    "HOME_COUNTRY = \"Homecountry\"\n",
    "HOME_TOWN = \"Hometown\"\n",
    "INCOME = \"Income\"\n",
    "LAST_NAME = \"LastName\"\n",
    "MOST_LISTENED_MUSICS = \"Mostlistenedmusics\"\n",
    "MOST_READ_BOOKS = \"Mostreadbooks\"\n",
    "MOST_VISITED_WEBSITES = \"Mostvisitedwebsites\"\n",
    "MOST_WATCHED_MOVIES = \"Mostwatchedmovies\"\n",
    "MOST_WATCHED_TV_PROGRAMMES = \"Mostwatchedtvprogrammes\"\n",
    "NAME = \"Name\"\n",
    "PAYPAL = \"Paypal\"\n",
    "TIMEPASS = \"Timepass\"\n",
    "TYPE_OF_JOB = \"TypeofJob\"\n",
    "WEEKLY_WORKING_HOURS = \"Weeklyworkinghours\"\n",
    "FAVE1 = \"fave1\"\n",
    "FAVE10 = \"fave10\"\n",
    "FAVE2 = \"fave2\"\n",
    "FAVE3 = \"fave3\"\n",
    "FAVE4 = \"fave4\"\n",
    "FAVE5 = \"fave5\"\n",
    "FAVE6 = \"fave6\"\n",
    "FAVE7 = \"fave7\"\n",
    "FAVE8 = \"fave8\"\n",
    "FAVE9 = \"fave9\"\n",
    "UNFAVE1 = \"unfave1\"\n",
    "UNFAVE2 = \"unfave2\"\n",
    "UNFAVE3 = \"unfave3\"\n",
    "UNFAVE4 = \"unfave4\"\n",
    "UNFAVE5 = \"unfave5\"\n",
    "UNFAVE6 = \"unfave6\"\n",
    "ADFILEPATH = \"AdFilePath\"\n",
    "GENDER_F = \"Gender_F\"\n",
    "GENDER_M = \"Gender_M\"\n",
    "# HomeCountry = 12 Columns\n",
    "HOMECOUNTRY_CANADA = \"Homecountry_Canada\"\n",
    "HOMECOUNTRY_CZECHREPUBLIC = \"Homecountry_CzechRepublic\"\n",
    "HOMECOUNTRY_GREATBRITAIN = \"Homecountry_GreatBritain\"\n",
    "HOMECOUNTRY_INDIA = \"Homecountry_India\"\n",
    "HOMECOUNTRY_ITALY = \"Homecountry_Italy\"\n",
    "HOMECOUNTRY_PHILLIPINES = \"Homecountry_Phillipines\"\n",
    "HOMECOUNTRY_ROMANIA = \"Homecountry_Romania\"\n",
    "HOMECOUNTRY_SAUDIARABIA = \"Homecountry_SaudiArabia\"\n",
    "HOMECOUNTRY_SINGAPORE = \"Homecountry_Singapore\"\n",
    "HOMECOUNTRY_SLOVENIA = \"Homecountry_Slovenia\"\n",
    "HOMECOUNTRY_UNITEDKINGDOM = \"Homecountry_UnitedKingdom\"\n",
    "HOMECOUNTRY_UNITEDSTATESOFAMERICA = \"Homecountry_UnitedStatesofAmerica\"\n",
    "# Income = 4 Columns\n",
    "INCOME_0 = \"Income_0\"\n",
    "INCOME_1 = \"Income_1\"\n",
    "INCOME_2 = \"Income_2\"\n",
    "INCOME_3 = \"Income_3\"\n",
    "# Mostlistenedmusics\n",
    "MOSTLISTENEDMUSICS_1 = \"AlternativeMusic\"\n",
    "MOSTLISTENEDMUSICS_2 = \"AsianPopJPoporKpop\"\n",
    "MOSTLISTENEDMUSICS_3 = \"Blues\"\n",
    "MOSTLISTENEDMUSICS_4 = \"ClassicalMusic\"\n",
    "MOSTLISTENEDMUSICS_5 = \"CountryMusic\"\n",
    "MOSTLISTENEDMUSICS_6 = \"DanceMusic\"\n",
    "MOSTLISTENEDMUSICS_7 = \"EasyListening\"\n",
    "MOSTLISTENEDMUSICS_8 = \"ElectronicMusic\"\n",
    "MOSTLISTENEDMUSICS_9 = \"EuropeanMusicFolkPop\"\n",
    "MOSTLISTENEDMUSICS_10 = \"HipHopRap\"\n",
    "MOSTLISTENEDMUSICS_11 = \"IndiePop\"\n",
    "MOSTLISTENEDMUSICS_12 = \"InspirationalinclGospel\"\n",
    "MOSTLISTENEDMUSICS_13 = \"Jazz\"\n",
    "MOSTLISTENEDMUSICS_14 = \"LatinMusic\"\n",
    "MOSTLISTENEDMUSICS_15 = \"NewAge\"\n",
    "MOSTLISTENEDMUSICS_16 = \"Opera\"\n",
    "MOSTLISTENEDMUSICS_17 = \"PopPopularmusic\"\n",
    "MOSTLISTENEDMUSICS_18 = \"RampBSoul\"\n",
    "MOSTLISTENEDMUSICS_19 = \"Reggae\"\n",
    "MOSTLISTENEDMUSICS_20 = \"Rock\"\n",
    "MOSTLISTENEDMUSICS_21 = \"SingerSongwriterincFolk\"\n",
    "MOSTLISTENEDMUSICS_22 = \"WorldMusicBeats\"\n",
    "RATING = \"Rating\"\n",
    "AD_NUM_FACES = \"ad_num_faces\"\n",
    "AD_LABEL_FEATURE_1 = 'ad_isAdvertising'\n",
    "AD_LABEL_FEATURE_2 = 'ad_isBrand'\n",
    "AD_LABEL_FEATURE_3 = 'ad_isElectronic device'\n",
    "AD_LABEL_FEATURE_4 = 'ad_isElectronics'\n",
    "AD_LABEL_FEATURE_5 = 'ad_isFashion accessory'\n",
    "AD_LABEL_FEATURE_6 = 'ad_isFictional character'\n",
    "AD_LABEL_FEATURE_7 = 'ad_isFont'\n",
    "AD_LABEL_FEATURE_8 = 'ad_isFurniture'\n",
    "AD_LABEL_FEATURE_9 = 'ad_isGadget'\n",
    "AD_LABEL_FEATURE_10 = 'ad_isGames'\n",
    "AD_LABEL_FEATURE_11 = 'ad_isGraphic design'\n",
    "AD_LABEL_FEATURE_12 = 'ad_isGraphics'\n",
    "AD_LABEL_FEATURE_13 = 'ad_isJewellery'\n",
    "AD_LABEL_FEATURE_14 = 'ad_isLine'\n",
    "AD_LABEL_FEATURE_15 = 'ad_isLogo'\n",
    "AD_LABEL_FEATURE_16 = 'ad_isMagenta'\n",
    "AD_LABEL_FEATURE_17 = 'ad_isMaterial property'\n",
    "AD_LABEL_FEATURE_18 = 'ad_isMultimedia'\n",
    "AD_LABEL_FEATURE_19 = 'ad_isProduct'\n",
    "AD_LABEL_FEATURE_20 = 'ad_isRectangle'\n",
    "AD_LABEL_FEATURE_21 = 'ad_isSkin'\n",
    "AD_LABEL_FEATURE_22 = 'ad_isTechnology'\n",
    "AD_LABEL_FEATURE_23 = 'ad_isText'\n",
    "AD_LABEL_FEATURE_24 = 'ad_isVehicle'\n",
    "AD_LABEL_FEATURE_25 = 'ad_isYellow'\n",
    "AD_SAFESEARCH_FEATURE_1 = 'ad_isAdult_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_2 ='ad_isAdult_VERY_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_3 ='ad_isSpoof_POSSIBLE'\n",
    "AD_SAFESEARCH_FEATURE_4 ='ad_isSpoof_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_5 ='ad_isSpoof_VERY_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_6 ='ad_isMedical_POSSIBLE'\n",
    "AD_SAFESEARCH_FEATURE_7 ='ad_isMedical_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_8 ='ad_isMedical_VERY_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_9 ='ad_isViolence_VERY_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_10 ='ad_isRacy_POSSIBLE'\n",
    "AD_SAFESEARCH_FEATURE_11 ='ad_isRacy_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_12 ='ad_isRacy_VERY_LIKELY'\n",
    "AD_SAFESEARCH_FEATURE_13 ='ad_isRacy_VERY_UNLIKELY'\n",
    "\n",
    "# Read all columns as strings to avoid any errors\n",
    "COL_DEFAULTS = {\n",
    "    USER_ID: \"**\",\n",
    "    AD_ID: \"**\",\n",
    "    AGE: \"**\",\n",
    "    ZIP_CODE: \"**\",\n",
    "    COUNTRIES_VISITED: \"**\",\n",
    "    FAVE_SPORTS: \"**\",\n",
    "    GENDER: \"**\",\n",
    "    HOME_COUNTRY: \"**\",\n",
    "    HOME_TOWN: \"**\",\n",
    "    INCOME: \"**\",\n",
    "    LAST_NAME: \"**\",\n",
    "    MOST_LISTENED_MUSICS: \"**\",\n",
    "    MOST_READ_BOOKS: \"**\",\n",
    "    MOST_VISITED_WEBSITES: \"**\",\n",
    "    MOST_WATCHED_MOVIES: \"**\",\n",
    "    MOST_WATCHED_TV_PROGRAMMES: \"**\",\n",
    "    NAME: \"**\",\n",
    "    PAYPAL: \"**\",\n",
    "    TIMEPASS: \"**\",\n",
    "    TYPE_OF_JOB: \"**\",\n",
    "    WEEKLY_WORKING_HOURS: \"**\",\n",
    "    FAVE1: \"**\",\n",
    "    FAVE10: \"**\",\n",
    "    FAVE2: \"**\",\n",
    "    FAVE3: \"**\",\n",
    "    FAVE4: \"**\",\n",
    "    FAVE5: \"**\",\n",
    "    FAVE6: \"**\",\n",
    "    FAVE7: \"**\",\n",
    "    FAVE8: \"**\",\n",
    "    FAVE9: \"**\",\n",
    "    UNFAVE1: \"**\",\n",
    "    UNFAVE2: \"**\",\n",
    "    UNFAVE3: \"**\",\n",
    "    UNFAVE4: \"**\",\n",
    "    UNFAVE5: \"**\",\n",
    "    UNFAVE6: \"**\",\n",
    "    ADFILEPATH: \"**\",\n",
    "    GENDER_F: \"**\",\n",
    "    GENDER_M: \"**\",\n",
    "    HOMECOUNTRY_CANADA: \"**\",\n",
    "    HOMECOUNTRY_CZECHREPUBLIC: \"**\",\n",
    "    HOMECOUNTRY_GREATBRITAIN: \"**\",\n",
    "    HOMECOUNTRY_INDIA: \"**\",\n",
    "    HOMECOUNTRY_ITALY: \"**\",\n",
    "    HOMECOUNTRY_PHILLIPINES: \"**\",\n",
    "    HOMECOUNTRY_ROMANIA: \"**\",\n",
    "    HOMECOUNTRY_SAUDIARABIA: \"**\",\n",
    "    HOMECOUNTRY_SINGAPORE: \"**\",\n",
    "    HOMECOUNTRY_SLOVENIA: \"**\",\n",
    "    HOMECOUNTRY_UNITEDKINGDOM: \"**\",\n",
    "    HOMECOUNTRY_UNITEDSTATESOFAMERICA: \"**\",\n",
    "    INCOME_0: \"**\",\n",
    "    INCOME_1: \"**\",\n",
    "    INCOME_2: \"**\",\n",
    "    INCOME_3: \"**\",\n",
    "    MOSTLISTENEDMUSICS_1: \"**\",\n",
    "    MOSTLISTENEDMUSICS_2: \"**\",\n",
    "    MOSTLISTENEDMUSICS_3: \"**\",\n",
    "    MOSTLISTENEDMUSICS_4: \"**\",\n",
    "    MOSTLISTENEDMUSICS_5: \"**\",\n",
    "    MOSTLISTENEDMUSICS_6: \"**\",\n",
    "    MOSTLISTENEDMUSICS_7: \"**\",\n",
    "    MOSTLISTENEDMUSICS_8: \"**\",\n",
    "    MOSTLISTENEDMUSICS_9: \"**\",\n",
    "    MOSTLISTENEDMUSICS_10: \"**\",\n",
    "    MOSTLISTENEDMUSICS_11: \"**\",\n",
    "    MOSTLISTENEDMUSICS_12: \"**\",\n",
    "    MOSTLISTENEDMUSICS_13: \"**\",\n",
    "    MOSTLISTENEDMUSICS_14: \"**\",\n",
    "    MOSTLISTENEDMUSICS_15: \"**\",\n",
    "    MOSTLISTENEDMUSICS_16: \"**\",\n",
    "    MOSTLISTENEDMUSICS_17: \"**\",\n",
    "    MOSTLISTENEDMUSICS_18: \"**\",\n",
    "    MOSTLISTENEDMUSICS_19: \"**\",\n",
    "    MOSTLISTENEDMUSICS_20: \"**\",\n",
    "    MOSTLISTENEDMUSICS_21: \"**\",\n",
    "    MOSTLISTENEDMUSICS_22: \"**\",\n",
    "    RATING: \"**\",\n",
    "    AD_NUM_FACES: \"**\"\n",
    "}\n",
    "\n",
    "# SELECTED_COLS = [AGE, ZIP_CODE, FAVE_SPORTS, GENDER, HOME_COUNTRY, HOME_TOWN, INCOME, MOST_LISTENED_MUSICS, MOST_READ_BOOKS, \n",
    "#                  MOST_VISITED_WEBSITES, MOST_WATCHED_MOVIES, MOST_WATCHED_TV_PROGRAMMES, TIMEPASS, TYPE_OF_JOB, WEEKLY_WORKING_HOURS, \n",
    "#                  FAVE1, FAVE2, FAVE3, FAVE4, FAVE5, FAVE6, FAVE7, FAVE8, FAVE9, FAVE10, UNFAVE1, UNFAVE2, UNFAVE3, UNFAVE4, UNFAVE5, \n",
    "#                  UNFAVE6, RATING]\n",
    "\n",
    "AD_FACE_COLS = [AD_NUM_FACES]\n",
    "AD_LABEL_COLS = [AD_LABEL_FEATURE_1,AD_LABEL_FEATURE_2,AD_LABEL_FEATURE_3,AD_LABEL_FEATURE_4,AD_LABEL_FEATURE_5,\n",
    "                AD_LABEL_FEATURE_6,AD_LABEL_FEATURE_7,AD_LABEL_FEATURE_8,AD_LABEL_FEATURE_9,AD_LABEL_FEATURE_10,\n",
    "                AD_LABEL_FEATURE_11,AD_LABEL_FEATURE_12,AD_LABEL_FEATURE_13,AD_LABEL_FEATURE_14,AD_LABEL_FEATURE_15,\n",
    "                AD_LABEL_FEATURE_16,AD_LABEL_FEATURE_17,AD_LABEL_FEATURE_18,AD_LABEL_FEATURE_19,AD_LABEL_FEATURE_20,\n",
    "                AD_LABEL_FEATURE_21,AD_LABEL_FEATURE_22,AD_LABEL_FEATURE_23,AD_LABEL_FEATURE_24,AD_LABEL_FEATURE_25]\n",
    "AD_OBJECT_COLS = []\n",
    "AD_SAFE_SEARCH_COLS = [AD_SAFESEARCH_FEATURE_1,AD_SAFESEARCH_FEATURE_2,AD_SAFESEARCH_FEATURE_3,AD_SAFESEARCH_FEATURE_4,\n",
    "                      AD_SAFESEARCH_FEATURE_5,AD_SAFESEARCH_FEATURE_6,AD_SAFESEARCH_FEATURE_7,AD_SAFESEARCH_FEATURE_8,\n",
    "                      AD_SAFESEARCH_FEATURE_9,AD_SAFESEARCH_FEATURE_10,AD_SAFESEARCH_FEATURE_11,AD_SAFESEARCH_FEATURE_12,AD_SAFESEARCH_FEATURE_13]\n",
    "\n",
    "\n",
    "SELECTED_AD_COLS = AD_FACE_COLS  + AD_LABEL_COLS + AD_OBJECT_COLS + AD_SAFE_SEARCH_COLS\n",
    "\n",
    "SELECTED_HOMECOUNTRY_COLS = [HOMECOUNTRY_CANADA, HOMECOUNTRY_CZECHREPUBLIC, HOMECOUNTRY_GREATBRITAIN,\n",
    "                             HOMECOUNTRY_INDIA, HOMECOUNTRY_ITALY, HOMECOUNTRY_PHILLIPINES, HOMECOUNTRY_ROMANIA,\n",
    "                             HOMECOUNTRY_SAUDIARABIA, HOMECOUNTRY_SINGAPORE, HOMECOUNTRY_SLOVENIA,\n",
    "                             HOMECOUNTRY_UNITEDKINGDOM, HOMECOUNTRY_UNITEDSTATESOFAMERICA]\n",
    "\n",
    "SELECTED_INCOME_COLS = [INCOME_0, INCOME_1, INCOME_2, INCOME_3]\n",
    "\n",
    "SELECTED_MOSTLISTENEDMUSICS_COLS = [MOSTLISTENEDMUSICS_1, MOSTLISTENEDMUSICS_2, MOSTLISTENEDMUSICS_3,\n",
    "                                    MOSTLISTENEDMUSICS_4, MOSTLISTENEDMUSICS_5, MOSTLISTENEDMUSICS_6,\n",
    "                                    MOSTLISTENEDMUSICS_7, MOSTLISTENEDMUSICS_8, MOSTLISTENEDMUSICS_9,\n",
    "                                    MOSTLISTENEDMUSICS_10, MOSTLISTENEDMUSICS_11, MOSTLISTENEDMUSICS_12,\n",
    "                                    MOSTLISTENEDMUSICS_13, MOSTLISTENEDMUSICS_14, MOSTLISTENEDMUSICS_15,\n",
    "                                    MOSTLISTENEDMUSICS_16, MOSTLISTENEDMUSICS_17, MOSTLISTENEDMUSICS_18,\n",
    "                                    MOSTLISTENEDMUSICS_19, MOSTLISTENEDMUSICS_20, MOSTLISTENEDMUSICS_21,\n",
    "                                    MOSTLISTENEDMUSICS_22]\n",
    "\n",
    "SELECTED_INP_COLS = [AGE, ZIP_CODE, FAVE_SPORTS, GENDER_F, GENDER_M] +\\\n",
    "                    SELECTED_AD_COLS +\\\n",
    "                    SELECTED_HOMECOUNTRY_COLS +\\\n",
    "                    SELECTED_INCOME_COLS +\\\n",
    "                    SELECTED_MOSTLISTENEDMUSICS_COLS\n",
    "\n",
    "SELECTED_COLS = SELECTED_INP_COLS + [TARGET_COL]\n",
    "\n",
    "SELECTED_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ad_dataset_pd():\n",
    "    return pd.read_csv(users_ads_rating_csv, usecols=SELECTED_COLS, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>CapZipCode</th>\n",
       "      <th>FaveSports</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>Homecountry_Canada</th>\n",
       "      <th>Homecountry_CzechRepublic</th>\n",
       "      <th>Homecountry_GreatBritain</th>\n",
       "      <th>Homecountry_India</th>\n",
       "      <th>...</th>\n",
       "      <th>ad_isSpoof_UNLIKELY</th>\n",
       "      <th>ad_isSpoof_VERY_UNLIKELY</th>\n",
       "      <th>ad_isMedical_POSSIBLE</th>\n",
       "      <th>ad_isMedical_UNLIKELY</th>\n",
       "      <th>ad_isMedical_VERY_UNLIKELY</th>\n",
       "      <th>ad_isViolence_VERY_UNLIKELY</th>\n",
       "      <th>ad_isRacy_POSSIBLE</th>\n",
       "      <th>ad_isRacy_UNLIKELY</th>\n",
       "      <th>ad_isRacy_VERY_LIKELY</th>\n",
       "      <th>ad_isRacy_VERY_UNLIKELY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30230</th>\n",
       "      <td>64</td>\n",
       "      <td>80231</td>\n",
       "      <td>Individual sports‎ (Tennis, Archery, ...), Wat...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13301</th>\n",
       "      <td>49</td>\n",
       "      <td>10456</td>\n",
       "      <td>Individual sports‎ (Tennis, Archery, ...)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30794</th>\n",
       "      <td>28</td>\n",
       "      <td>60018</td>\n",
       "      <td>Endurance sports</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33389</th>\n",
       "      <td>27</td>\n",
       "      <td>60064</td>\n",
       "      <td>Water sports, Winter sports</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33271</th>\n",
       "      <td>56</td>\n",
       "      <td>51031</td>\n",
       "      <td>Olympic sports‎</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25696</th>\n",
       "      <td>37</td>\n",
       "      <td>SS2 5JL</td>\n",
       "      <td>Individual sports‎ (Tennis, Archery, ...)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23879</th>\n",
       "      <td>35</td>\n",
       "      <td>NE61 5RT</td>\n",
       "      <td>Other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20640</th>\n",
       "      <td>30</td>\n",
       "      <td>L4Z3T7</td>\n",
       "      <td>Individual sports‎ (Tennis, Archery, ...)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4406</th>\n",
       "      <td>23</td>\n",
       "      <td>98105</td>\n",
       "      <td>Individual sports‎ (Tennis, Archery, ...), Tea...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16262</th>\n",
       "      <td>43</td>\n",
       "      <td>M6K 0A1</td>\n",
       "      <td>Individual sports‎ (Tennis, Archery, ...), Mot...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age CapZipCode                                         FaveSports  \\\n",
       "30230  64      80231  Individual sports‎ (Tennis, Archery, ...), Wat...   \n",
       "13301  49      10456          Individual sports‎ (Tennis, Archery, ...)   \n",
       "30794  28      60018                                   Endurance sports   \n",
       "33389  27      60064                        Water sports, Winter sports   \n",
       "33271  56      51031                                    Olympic sports‎   \n",
       "25696  37    SS2 5JL          Individual sports‎ (Tennis, Archery, ...)   \n",
       "23879  35   NE61 5RT                                              Other   \n",
       "20640  30     L4Z3T7          Individual sports‎ (Tennis, Archery, ...)   \n",
       "4406   23      98105  Individual sports‎ (Tennis, Archery, ...), Tea...   \n",
       "16262  43    M6K 0A1  Individual sports‎ (Tennis, Archery, ...), Mot...   \n",
       "\n",
       "      Rating Gender_F Gender_M Homecountry_Canada Homecountry_CzechRepublic  \\\n",
       "30230    2.0        0        1                  0                         0   \n",
       "13301    1.0        0        1                  0                         0   \n",
       "30794    4.0        1        0                  0                         0   \n",
       "33389    2.0        1        0                  0                         0   \n",
       "33271    3.0        1        0                  0                         0   \n",
       "25696    3.0        0        1                  0                         0   \n",
       "23879    4.0        1        0                  0                         0   \n",
       "20640    3.0        1        0                  1                         0   \n",
       "4406     2.0        0        1                  0                         0   \n",
       "16262    1.0        1        0                  1                         0   \n",
       "\n",
       "      Homecountry_GreatBritain Homecountry_India  ... ad_isSpoof_UNLIKELY  \\\n",
       "30230                        0                 0  ...                   0   \n",
       "13301                        0                 0  ...                   1   \n",
       "30794                        0                 0  ...                   0   \n",
       "33389                        0                 0  ...                   0   \n",
       "33271                        0                 0  ...                   0   \n",
       "25696                        0                 0  ...                   0   \n",
       "23879                        0                 0  ...                   0   \n",
       "20640                        0                 0  ...                   0   \n",
       "4406                         0                 0  ...                   0   \n",
       "16262                        0                 0  ...                   0   \n",
       "\n",
       "      ad_isSpoof_VERY_UNLIKELY ad_isMedical_POSSIBLE ad_isMedical_UNLIKELY  \\\n",
       "30230                        1                     0                     0   \n",
       "13301                        0                     0                     0   \n",
       "30794                        1                     0                     0   \n",
       "33389                        1                     0                     0   \n",
       "33271                        1                     0                     1   \n",
       "25696                        1                     0                     1   \n",
       "23879                        1                     0                     1   \n",
       "20640                        1                     0                     1   \n",
       "4406                         1                     0                     1   \n",
       "16262                        1                     0                     1   \n",
       "\n",
       "      ad_isMedical_VERY_UNLIKELY ad_isViolence_VERY_UNLIKELY  \\\n",
       "30230                          1                           1   \n",
       "13301                          1                           1   \n",
       "30794                          1                           1   \n",
       "33389                          1                           1   \n",
       "33271                          0                           1   \n",
       "25696                          0                           1   \n",
       "23879                          0                           0   \n",
       "20640                          0                           1   \n",
       "4406                           0                           0   \n",
       "16262                          0                           1   \n",
       "\n",
       "      ad_isRacy_POSSIBLE ad_isRacy_UNLIKELY ad_isRacy_VERY_LIKELY  \\\n",
       "30230                  0                  0                     0   \n",
       "13301                  0                  0                     0   \n",
       "30794                  0                  0                     0   \n",
       "33389                  0                  0                     0   \n",
       "33271                  0                  0                     0   \n",
       "25696                  0                  0                     0   \n",
       "23879                  0                  1                     0   \n",
       "20640                  0                  0                     0   \n",
       "4406                   0                  0                     0   \n",
       "16262                  0                  0                     0   \n",
       "\n",
       "      ad_isRacy_VERY_UNLIKELY  \n",
       "30230                       1  \n",
       "13301                       1  \n",
       "30794                       1  \n",
       "33389                       1  \n",
       "33271                       1  \n",
       "25696                       1  \n",
       "23879                       0  \n",
       "20640                       1  \n",
       "4406                        1  \n",
       "16262                       1  \n",
       "\n",
       "[10 rows x 83 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_dataset_pd().sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_project(d:Dict, cols:List[str]) -> Dict:\n",
    "    return {k:v for k, v in d.items() if k in cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexerForVocab:\n",
    "    def __init__(self, vocab_list:List[str], oov_index:int=0):\n",
    "        \"\"\"\n",
    "        Creates a string indexer for the vocabulary with out of vocabulary (oov) indexing\n",
    "        \"\"\"\n",
    "        self._vocab_map = {v:i+1 for i, v in enumerate(vocab_list)}\n",
    "        self._oov = oov_index\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"Map for {len(self)} keys with 1 OOV key\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._vocab_map) + 1\n",
    "        \n",
    "    def index_of(self, item:str):\n",
    "        \"\"\"\n",
    "        Index of item in the vocabulary\n",
    "        \"\"\"\n",
    "        return self._vocab_map.get(item, self._oov)\n",
    "    \n",
    "    def index_of_mux(self, items:List[str]):\n",
    "        return [self.index_of(i) for i in items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age\n",
    "\n",
    "Convert to a number and remove any outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained from Tensorflow Data Validation APIs data-exploration/tensorflow-data-validation.ipynb\n",
    "\n",
    "MEAN_AGE, STD_AGE, MEDIAN_AGE, MAX_AGE = 31.74, 12.07, 29, 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_age(age_str:tf.string, default_age=MEDIAN_AGE) -> int:\n",
    "    \"\"\"Typecast age to an integer and update outliers with the default\"\"\"\n",
    "    try:\n",
    "        age = int(age_str)\n",
    "        if age < 0 or age > MAX_AGE:\n",
    "            raise ValueError(f\"{age} is not a valid age\")\n",
    "    except:\n",
    "        age = default_age\n",
    "    normalized_age = (age - MEAN_AGE) / STD_AGE\n",
    "    return normalized_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5128417564208783,\n",
       " -0.22700911350455663,\n",
       " -0.22700911350455663,\n",
       " -0.22700911350455663,\n",
       " -0.22700911350455663)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_age(\"50\"), fix_age(\"50.5\"), fix_age(\"-10\"), fix_age(\"bad_age_10\"), fix_age(\"300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip Code\n",
    "\n",
    "Prepare zip-code column for one-hot encoding each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_ZIP_CODE, FIRST_K_ZIP_DIGITS = \"00000\", 2\n",
    "\n",
    "zip_code_indexer = IndexerForVocab(string.digits + string.ascii_lowercase + string.ascii_uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_zip_code_tensor(zip_code:tf.string, n_digits, indexer) -> List[str]:\n",
    "    \"\"\"Extracts the the first n_digits as a list\"\"\"\n",
    "    zip_digits = []\n",
    "    try:\n",
    "        if isinstance(zip_code, tf.Tensor):\n",
    "            zip_code = zip_code.numpy()[0].decode('ascii', errors=\"ignore\") # very ineffecient way\n",
    "        zip_digits = list(zip_code.strip()[:n_digits])\n",
    "    except:\n",
    "        zip_digits = list(DEFAULT_ZIP_CODE[:n_digits])\n",
    "    return tf.concat( [\n",
    "        tf.one_hot(\n",
    "            indexer.index_of(d), len(indexer)\n",
    "        ) for d in zip_digits\n",
    "    ], 0 )\n",
    "\n",
    "def fix_zip_code(zip_code:str, n_digits, indexer) -> List[str]:\n",
    "    \"\"\"Extracts the the first n_digits as a list\"\"\"\n",
    "    zip_digits = []\n",
    "    try:\n",
    "        zip_digits = list(zip_code.strip()[:n_digits])\n",
    "    except:\n",
    "        zip_digits = list(DEFAULT_ZIP_CODE[:n_digits])\n",
    "    return np.ravel(np.eye(len(indexer))[indexer.index_of_mux(zip_digits)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_zip_code_indexer = IndexerForVocab(string.digits)\n",
    "\n",
    "(fix_zip_code(\"43556\", 10, test_zip_code_indexer),\n",
    "fix_zip_code(\"43556\", 2, test_zip_code_indexer),\n",
    "fix_zip_code(\"43556\", 4, test_zip_code_indexer),\n",
    "fix_zip_code(None, 3, test_zip_code_indexer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Favorite Sports\n",
    "\n",
    "Two approaches,\n",
    "1. Consider the first `K` sports mentioned by each user and one-hot encode each separately\n",
    "2. Multi label binarize all the sports as there are only 15 unique sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=None, sparse_output=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FAV_SPORTS_UNKNOWN = \"UNK_SPORT\"\n",
    "ALL_FAV_SPORTS = ['Olympic sports', 'Winter sports', 'Nothing', 'I do not like Sports', 'Equestrian sports', 'Skating sports', 'Precision sports', 'Hunting sports', 'Motor sports', 'Team sports', 'Individual sports', 'Other', 'Water sports', 'Indoor sports', 'Endurance sports']\n",
    "\n",
    "fav_sports_binarizer = MultiLabelBinarizer()\n",
    "fav_sports_binarizer.fit([ALL_FAV_SPORTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fav_sports_multi_select_str_to_list(sports_str:Union[str, tf.Tensor]) -> List[str]:\n",
    "    # remove commas that dont separate different user selections\n",
    "    # example, commas inside paranthesis of \"Individual sports (Tennis, Archery, ...)\" dont make new sports\n",
    "    if isinstance(sports_str, tf.Tensor):\n",
    "        sports_str = sports_str.numpy()[0].decode('ascii', errors=\"ignore\")\n",
    "    else:\n",
    "        sports_str = sports_str.encode(\"ascii\", errors=\"ignore\").decode(\"ascii\") # remove non-ascii chars\n",
    "    sports = re.sub(r\"\\s*\\(.*,.*\\)\\s*\", \"\", sports_str)\n",
    "    return re.split(r\"\\s*,\\s*\", sports)\n",
    "\n",
    "def fix_fav_sports_mlb(sports_str:str) -> List[int]:\n",
    "    sports = fav_sports_multi_select_str_to_list(sports_str)\n",
    "    return fav_sports_binarizer.transform([sports])[0]\n",
    "\n",
    "def fix_fav_sports_firstk(sports_str:str, first_k:int, pad_constant:int) -> List[str]:\n",
    "    sports = fav_sports_multi_select_str_to_list(sports_str)\n",
    "    right_pad_width = first_k - len(sports_enc)\n",
    "    result = [sports + [pad_constant] * right_pad_width][:first_k]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    fix_fav_sports_mlb(\"Individual sports (Tennis, Archery, ...), Indoor sports, Endurance sports, Skating sports\"),\n",
    "    fix_fav_sports_mlb(\"Skating sports\"),\n",
    "    fix_fav_sports_mlb(\"Individual sports (Tennis, Archery, ...)\"),\n",
    "    fix_fav_sports_mlb(\"Indoor sports, Endurance sports, Skating sports\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATINGS_CARDINALITY = 5 # not zero based indexing i.e. ratings range from 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_pd(rating_str:str):\n",
    "    return np.eye(RATINGS_CARDINALITY, dtype=int)[int(float(rating_str)) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pd_X(df:pd.DataFrame, inp_cols:List[str]):\n",
    "    \"\"\"Original dataframe will be modified\"\"\"\n",
    "    df[AGE] = df[AGE].apply(lambda age: [fix_age(age)])\n",
    "    df[ZIP_CODE] = df[ZIP_CODE].apply(lambda zc: fix_zip_code(zc, n_digits=2, indexer=zip_code_indexer))\n",
    "    df[FAVE_SPORTS] = df[FAVE_SPORTS].apply(fix_fav_sports_mlb)\n",
    "    df[GENDER_F] = df[GENDER_F].apply(lambda gender_f: [int(gender_f)])\n",
    "    df[GENDER_M] = df[GENDER_M].apply(lambda gender_m: [int(gender_m)])\n",
    "    df[AD_NUM_FACES] = df[AD_NUM_FACES].apply(lambda ad_num_faces: [int(ad_num_faces)])\n",
    "    \n",
    "    df[AD_LABEL_FEATURE_1] = df[AD_LABEL_FEATURE_1].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_2] = df[AD_LABEL_FEATURE_2].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_3] = df[AD_LABEL_FEATURE_3].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_4] = df[AD_LABEL_FEATURE_4].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_5] = df[AD_LABEL_FEATURE_5].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_6] = df[AD_LABEL_FEATURE_6].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_7] = df[AD_LABEL_FEATURE_7].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_8] = df[AD_LABEL_FEATURE_8].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_9] = df[AD_LABEL_FEATURE_9].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_10] = df[AD_LABEL_FEATURE_10].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_11] = df[AD_LABEL_FEATURE_11].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_12] = df[AD_LABEL_FEATURE_12].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_13] = df[AD_LABEL_FEATURE_13].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_14] = df[AD_LABEL_FEATURE_14].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_15] = df[AD_LABEL_FEATURE_15].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_16] = df[AD_LABEL_FEATURE_16].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_17] = df[AD_LABEL_FEATURE_17].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_18] = df[AD_LABEL_FEATURE_18].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_19] = df[AD_LABEL_FEATURE_19].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_20] = df[AD_LABEL_FEATURE_20].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_21] = df[AD_LABEL_FEATURE_21].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_22] = df[AD_LABEL_FEATURE_22].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_23] = df[AD_LABEL_FEATURE_23].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_24] = df[AD_LABEL_FEATURE_24].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_25] = df[AD_LABEL_FEATURE_25].apply(lambda f: [int(f)])\n",
    "    \n",
    "    df[AD_SAFESEARCH_FEATURE_1] = df[AD_SAFESEARCH_FEATURE_1].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_2] = df[AD_SAFESEARCH_FEATURE_2].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_3] = df[AD_SAFESEARCH_FEATURE_3].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_4] = df[AD_SAFESEARCH_FEATURE_4].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_5] = df[AD_SAFESEARCH_FEATURE_5].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_6] = df[AD_SAFESEARCH_FEATURE_6].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_7] = df[AD_SAFESEARCH_FEATURE_7].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_8] = df[AD_SAFESEARCH_FEATURE_8].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_9] = df[AD_SAFESEARCH_FEATURE_9].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_10] = df[AD_SAFESEARCH_FEATURE_10].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_11] = df[AD_SAFESEARCH_FEATURE_11].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_12] = df[AD_SAFESEARCH_FEATURE_12].apply(lambda f: [int(f)])\n",
    "    df[AD_SAFESEARCH_FEATURE_13] = df[AD_SAFESEARCH_FEATURE_13].apply(lambda f: [int(f)])\n",
    "            \n",
    "    df[HOMECOUNTRY_CANADA] = df[HOMECOUNTRY_CANADA].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_CZECHREPUBLIC] = df[HOMECOUNTRY_CZECHREPUBLIC].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_GREATBRITAIN] = df[HOMECOUNTRY_GREATBRITAIN].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_INDIA] = df[HOMECOUNTRY_INDIA].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_ITALY] = df[HOMECOUNTRY_ITALY].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_PHILLIPINES] = df[HOMECOUNTRY_PHILLIPINES].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_ROMANIA] = df[HOMECOUNTRY_ROMANIA].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_SAUDIARABIA] = df[HOMECOUNTRY_SAUDIARABIA].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_SINGAPORE] = df[HOMECOUNTRY_SINGAPORE].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_SLOVENIA] = df[HOMECOUNTRY_SLOVENIA].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_UNITEDKINGDOM] = df[HOMECOUNTRY_UNITEDKINGDOM].apply(lambda f: [int(f)])\n",
    "    df[HOMECOUNTRY_UNITEDSTATESOFAMERICA] = df[HOMECOUNTRY_UNITEDSTATESOFAMERICA].apply(lambda f: [int(f)])\n",
    "\n",
    "    df[INCOME_0] = df[INCOME_0].apply(lambda f: [int(f)])\n",
    "    df[INCOME_1] = df[INCOME_1].apply(lambda f: [int(f)])\n",
    "    df[INCOME_2] = df[INCOME_2].apply(lambda f: [int(f)])\n",
    "    df[INCOME_3] = df[INCOME_3].apply(lambda f: [int(f)])\n",
    "\n",
    "    df[MOSTLISTENEDMUSICS_1] = df[MOSTLISTENEDMUSICS_1].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_2] = df[MOSTLISTENEDMUSICS_2].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_3] = df[MOSTLISTENEDMUSICS_3].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_4] = df[MOSTLISTENEDMUSICS_4].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_5] = df[MOSTLISTENEDMUSICS_5].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_6] = df[MOSTLISTENEDMUSICS_6].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_7] = df[MOSTLISTENEDMUSICS_7].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_8] = df[MOSTLISTENEDMUSICS_8].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_9] = df[MOSTLISTENEDMUSICS_9].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_10] = df[MOSTLISTENEDMUSICS_10].apply(lambda f: [int(f)])    \n",
    "    df[MOSTLISTENEDMUSICS_11] = df[MOSTLISTENEDMUSICS_11].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_12] = df[MOSTLISTENEDMUSICS_12].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_13] = df[MOSTLISTENEDMUSICS_13].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_14] = df[MOSTLISTENEDMUSICS_14].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_15] = df[MOSTLISTENEDMUSICS_15].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_16] = df[MOSTLISTENEDMUSICS_16].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_17] = df[MOSTLISTENEDMUSICS_17].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_18] = df[MOSTLISTENEDMUSICS_18].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_19] = df[MOSTLISTENEDMUSICS_19].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_20] = df[MOSTLISTENEDMUSICS_20].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_21] = df[MOSTLISTENEDMUSICS_21].apply(lambda f: [int(f)])\n",
    "    df[MOSTLISTENEDMUSICS_22] = df[MOSTLISTENEDMUSICS_22].apply(lambda f: [int(f)])\n",
    "\n",
    "    df[\"X\"] = df[inp_cols].apply(np.concatenate, axis=1)\n",
    "    # TODO: vectorize, else inefficient to sequentially loop over all example\n",
    "    X = np.array([x for x in df[\"X\"]])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pd_y(df:pd.DataFrame, target_col:str):\n",
    "    \"\"\"Original dataframe will be modified\"\"\"\n",
    "    df[\"y\"] = df[target_col].apply(create_target_pd)\n",
    "    # TODO: vectorize, else inefficient to sequentially loop over all example\n",
    "    y = np.array([y for y in df[\"y\"]])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_pd(inp_cols:List[str]=SELECTED_INP_COLS, target_col:str=TARGET_COL, fraction:float=1) -> pd.DataFrame:\n",
    "    \"\"\"Prepare the dataset for training on a fraction of all input data\"\"\"\n",
    "    df = ad_dataset_pd().sample(frac=fraction)\n",
    "    return transform_pd_X(df, inp_cols), transform_pd_y(df, target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tensorboard\n",
    "\n",
    "Monitor training and other stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Start tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 77956), started 6:36:47 ago. (Use '!kill 77956' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-aa2e498f48cd5e44\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-aa2e498f48cd5e44\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir logs (started 6:36:47 ago; pid 77956)\n"
     ]
    }
   ],
   "source": [
    "notebook.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Create a model and train using high level APIs like `tf.keras` and `tf.estimator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 270 ms, total: 1min 31s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train_dataset = input_fn_train(BATCH_SIZE)\n",
    "X, y = create_dataset_pd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.metrics.SensitivityAtSpecificity(name=\"ss\")  # For false positive rate\n",
    "\n",
    "keras_model_metrics = [\n",
    "    \"accuracy\",\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc')\n",
    "]\n",
    "train_histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T CHANGE THE EPOCHS VALUE\n",
    "BATCH_SIZE = 4096\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging tensorboard data at logs/20200502-023932\n"
     ]
    }
   ],
   "source": [
    "logdir = Path(\"logs\")/datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    logdir, \n",
    "    histogram_freq=max(1, ceil(EPOCHS / 20)), # to control the amount of logging\n",
    "#     embeddings_freq=epochs,\n",
    ")\n",
    "print(f\"Logging tensorboard data at {logdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                4440      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 4,545\n",
      "Trainable params: 4,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(20, input_shape=(X.shape[1],), activation=tf.keras.layers.LeakyReLU()),\n",
    "    tf.keras.layers.Dense(RATINGS_CARDINALITY , activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(\n",
    "        learning_rate=0.003,\n",
    "        clipvalue=0.5\n",
    "    ), \n",
    "#     optimizer=tf.keras.optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True), \n",
    "#     optimizer=tf.keras.optimizers.RMSprop(lr),\n",
    "#     loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=keras_model_metrics\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, accuracy:0.4840,  auc:0.7049,  fn:28290.0000,  fp:272.0000,  loss:1.4540,  precision:0.6522,  recall:0.0177,  tn:114928.0000,  tp:510.0000,  val_accuracy:0.5451,  val_auc:0.7391,  val_fn:6001.0000,  val_fp:862.0000,  val_loss:1.3328,  val_precision:0.5818,  val_recall:0.1665,  val_tn:27938.0000,  val_tp:1199.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.6262,  auc:0.8764,  fn:14191.0000,  fp:5164.0000,  loss:0.9813,  precision:0.7388,  recall:0.5073,  tn:110036.0000,  tp:14609.0000,  val_accuracy:0.6147,  val_auc:0.8663,  val_fn:3566.0000,  val_fp:1423.0000,  val_loss:1.0211,  val_precision:0.7186,  val_recall:0.5047,  val_tn:27377.0000,  val_tp:3634.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.6325,  auc:0.8812,  fn:14240.0000,  fp:4806.0000,  loss:0.9623,  precision:0.7518,  recall:0.5056,  tn:110394.0000,  tp:14560.0000,  val_accuracy:0.6176,  val_auc:0.8678,  val_fn:3461.0000,  val_fp:1516.0000,  val_loss:1.0173,  val_precision:0.7115,  val_recall:0.5193,  val_tn:27284.0000,  val_tp:3739.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.6383,  auc:0.8841,  fn:13955.0000,  fp:4928.0000,  loss:0.9498,  precision:0.7508,  recall:0.5155,  tn:110272.0000,  tp:14845.0000,  val_accuracy:0.6149,  val_auc:0.8675,  val_fn:3573.0000,  val_fp:1418.0000,  val_loss:1.0169,  val_precision:0.7189,  val_recall:0.5038,  val_tn:27382.0000,  val_tp:3627.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.6363,  auc:0.8858,  fn:13681.0000,  fp:5103.0000,  loss:0.9431,  precision:0.7477,  recall:0.5250,  tn:110097.0000,  tp:15119.0000,  val_accuracy:0.6156,  val_auc:0.8685,  val_fn:3571.0000,  val_fp:1401.0000,  val_loss:1.0127,  val_precision:0.7215,  val_recall:0.5040,  val_tn:27399.0000,  val_tp:3629.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.6380,  auc:0.8871,  fn:13511.0000,  fp:5187.0000,  loss:0.9380,  precision:0.7467,  recall:0.5309,  tn:110013.0000,  tp:15289.0000,  val_accuracy:0.6154,  val_auc:0.8677,  val_fn:3589.0000,  val_fp:1384.0000,  val_loss:1.0158,  val_precision:0.7229,  val_recall:0.5015,  val_tn:27416.0000,  val_tp:3611.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.6402,  auc:0.8878,  fn:13649.0000,  fp:5022.0000,  loss:0.9347,  precision:0.7511,  recall:0.5261,  tn:110178.0000,  tp:15151.0000,  val_accuracy:0.6167,  val_auc:0.8682,  val_fn:3616.0000,  val_fp:1354.0000,  val_loss:1.0149,  val_precision:0.7258,  val_recall:0.4978,  val_tn:27446.0000,  val_tp:3584.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.6417,  auc:0.8888,  fn:13450.0000,  fp:5079.0000,  loss:0.9302,  precision:0.7514,  recall:0.5330,  tn:110121.0000,  tp:15350.0000,  val_accuracy:0.6129,  val_auc:0.8689,  val_fn:3565.0000,  val_fp:1388.0000,  val_loss:1.0148,  val_precision:0.7237,  val_recall:0.5049,  val_tn:27412.0000,  val_tp:3635.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.6412,  auc:0.8896,  fn:13706.0000,  fp:4922.0000,  loss:0.9270,  precision:0.7541,  recall:0.5241,  tn:110278.0000,  tp:15094.0000,  val_accuracy:0.6129,  val_auc:0.8687,  val_fn:3586.0000,  val_fp:1380.0000,  val_loss:1.0148,  val_precision:0.7237,  val_recall:0.5019,  val_tn:27420.0000,  val_tp:3614.0000,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.6434,  auc:0.8906,  fn:13439.0000,  fp:4944.0000,  loss:0.9233,  precision:0.7565,  recall:0.5334,  tn:110256.0000,  tp:15361.0000,  val_accuracy:0.6154,  val_auc:0.8688,  val_fn:3514.0000,  val_fp:1421.0000,  val_loss:1.0151,  val_precision:0.7218,  val_recall:0.5119,  val_tn:27379.0000,  val_tp:3686.0000,  \n",
      "....................................................................................................CPU times: user 14min 32s, sys: 1min 30s, total: 16min 3s\n",
      "Wall time: 3min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_histories.append(model.fit(\n",
    "    X, y,\n",
    "    BATCH_SIZE,\n",
    "    epochs=EPOCHS, \n",
    "    callbacks=[tensorboard_callback, tfdocs.modeling.EpochDots()],\n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_tp</th>\n",
       "      <th>val_fp</th>\n",
       "      <th>val_tn</th>\n",
       "      <th>val_fn</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.92049</td>\n",
       "      <td>0.643576</td>\n",
       "      <td>15154.0</td>\n",
       "      <td>4754.0</td>\n",
       "      <td>110446.0</td>\n",
       "      <td>13646.0</td>\n",
       "      <td>0.761202</td>\n",
       "      <td>0.526181</td>\n",
       "      <td>0.891134</td>\n",
       "      <td>1.018866</td>\n",
       "      <td>0.60875</td>\n",
       "      <td>3622.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>27380.0</td>\n",
       "      <td>3578.0</td>\n",
       "      <td>0.718366</td>\n",
       "      <td>0.503056</td>\n",
       "      <td>0.868021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy       tp      fp        tn       fn  precision  \\\n",
       "999  0.92049  0.643576  15154.0  4754.0  110446.0  13646.0   0.761202   \n",
       "\n",
       "       recall       auc  val_loss  val_accuracy  val_tp  val_fp   val_tn  \\\n",
       "999  0.526181  0.891134  1.018866       0.60875  3622.0  1420.0  27380.0   \n",
       "\n",
       "     val_fn  val_precision  val_recall   val_auc  \n",
       "999  3578.0       0.718366    0.503056  0.868021  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(train_histories[-1].history) # pick the latest training history\n",
    "\n",
    "metrics_df.tail(1) # pick the last epoch's metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tip:` You can copy the final metrics row from above and paste it using `Shift + Cmd + V` in our [sheet](https://docs.google.com/spreadsheets/d/1v-nYiDA3elM1UP9stkB42MK0bTbuLxYJE7qAYDP8FHw/edit#gid=925421130) to accurately place all values in the respective columns\n",
    "\n",
    "**IMPORTANT**: Please don't forget to update git version ID column after you check-in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Metrics with p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n",
    "\n",
    "Save the model for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /export/apps/python/3.6.1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: logs/20200502-023932/keras_saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save((logdir/\"keras_saved_model\").as_posix(), save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Gender_F'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gender_F'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-fd508781cf61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m })\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_pd_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSELECTED_INP_COLS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpredicted_rating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-2f8a9d0f9e47>\u001b[0m in \u001b[0;36mtransform_pd_X\u001b[0;34m(df, inp_cols)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mZIP_CODE\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mZIP_CODE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mzc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfix_zip_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_digits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzip_code_indexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFAVE_SPORTS\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFAVE_SPORTS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfix_fav_sports_mlb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGENDER_F\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGENDER_F\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgender_f\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGENDER_M\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGENDER_M\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgender_m\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAD_NUM_FACES\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAD_NUM_FACES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mad_num_faces\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mad_num_faces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gender_F'"
     ]
    }
   ],
   "source": [
    "PredictionReport = namedtuple(\"PredictionReport\", \"probabilities predicted_rating confidence\")\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    AGE: [\"45\"],\n",
    "    ZIP_CODE: [\"94086\"],\n",
    "    FAVE_SPORTS: [\"I do not like Sports\"]\n",
    "})\n",
    "\n",
    "probabilities = model.predict(transform_pd_X(test_df, SELECTED_INP_COLS))\n",
    "predicted_rating, confidence = np.argmax(probabilities), np.max(probabilities)\n",
    "\n",
    "PredictionReport(probabilities, predicted_rating, confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Rough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Featurize using Feature Columns\n",
    "\n",
    "Create feature columns like one-hot, embeddings, bucketing from raw features created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EXAMPLE_BATCH = next(iter(input_fn_train(3)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EXAMPLE_BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_feature_column(feature_column):\n",
    "    feature_layer = tf.keras.layers.DenseFeatures(feature_column)\n",
    "    return feature_layer(EXAMPLE_BATCH).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "age_fc = tf.feature_column.numeric_column(AGE, normalizer_fn=lambda x: (x - MEAN_AGE) / STD_AGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "zip_fcs = [\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            f\"{ZIP_CODE}{i}\", vocabulary_list=list(string.digits), \n",
    "            num_oov_buckets=1)\n",
    "    )\n",
    "    for i in range(FIRST_K_ZIP_DIGITS)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EXAMPLE_BATCH[AGE], test_feature_column(age_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "{k: v for k, v in EXAMPLE_BATCH.items() if k.startswith(ZIP_CODE)}, test_feature_column(zip_fcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.keras.layers.concatenate(age_fc, zip_fcs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "221.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
