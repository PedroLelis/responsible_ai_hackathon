{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model\n",
    "\n",
    "The aim of the notebook is demo end to end pipeline for Ads prediction in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! ./setup.sh # uncomment if you wish to install any new packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from typing import Dict, Any, Union, List, Tuple\n",
    "from functools import partial\n",
    "import re\n",
    "import string\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from math import ceil\n",
    "from collections import namedtuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "import chakin\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import zipfile\n",
    "import sqlite3\n",
    "import logging\n",
    "from tempfile import TemporaryDirectory\n",
    "from fastprogress import progress_bar\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.datasets import BinaryLabelDataset  # To handle the data\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from EmbeddingFactory import EmbeddingFactory\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(f\"Using Tensorflow, {tf.__version__} on Python interpreter, {sys.version_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = int(time.time())\n",
    "\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"Using random seed, {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset credits:\n",
    "```\n",
    "@inproceedings{roffo2016personality,\n",
    "  title={Personality in computational advertising: A benchmark},\n",
    "  author={Roffo, Giorgio and Vinciarelli, Alessandro},\n",
    "  booktitle={4 th Workshop on Emotions and Personality in Personalized Systems (EMPIRE) 2016},\n",
    "  pages={18},\n",
    "  year={2016}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"../../dataset/\")\n",
    "BATCH_SIZE = 4096 # bigger the batch, faster the training but bigger the RAM needed\n",
    "TARGET_COL = \"Rating\"\n",
    "\n",
    "# data files path are relative DATA_FOLDER\n",
    "users_ads_rating_csv = DATA_FOLDER/\"users-ads-without-gcp-ratings_OHE_MLB_FAV_UNFAV_Merged.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Declare columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "USER_ID = \"UserId\"\n",
    "AD_ID = \"AdId\"\n",
    "AGE = \"Age\"\n",
    "ZIP_CODE = \"CapZipCode\"\n",
    "COUNTRIES_VISITED = \"Countriesvisited\"\n",
    "FAVE_SPORTS = \"FaveSports\"\n",
    "GENDER = \"Gender\"\n",
    "HOME_COUNTRY = \"Homecountry\"\n",
    "HOME_TOWN = \"Hometown\"\n",
    "INCOME = \"Income\"\n",
    "LAST_NAME = \"LastName\"\n",
    "MOST_LISTENED_MUSICS = \"Mostlistenedmusics\"\n",
    "MOST_READ_BOOKS = \"Mostreadbooks\"\n",
    "MOST_VISITED_WEBSITES = \"Mostvisitedwebsites\"\n",
    "MOST_WATCHED_MOVIES = \"Mostwatchedmovies\"\n",
    "MOST_WATCHED_TV_PROGRAMMES = \"Mostwatchedtvprogrammes\"\n",
    "NAME = \"Name\"\n",
    "PAYPAL = \"Paypal\"\n",
    "TIMEPASS = \"Timepass\"\n",
    "TYPE_OF_JOB = \"TypeofJob\"\n",
    "WEEKLY_WORKING_HOURS = \"Weeklyworkinghours\"\n",
    "ADFILEPATH = \"AdFilePath\"\n",
    "GENDER_F = \"Gender_F\"\n",
    "GENDER_M = \"Gender_M\"\n",
    "# HomeCountry = 12 Columns\n",
    "HOMECOUNTRY_CANADA = \"Homecountry_Canada\"\n",
    "HOMECOUNTRY_CZECHREPUBLIC = \"Homecountry_CzechRepublic\"\n",
    "HOMECOUNTRY_GREATBRITAIN = \"Homecountry_GreatBritain\"\n",
    "HOMECOUNTRY_INDIA = \"Homecountry_India\"\n",
    "HOMECOUNTRY_ITALY = \"Homecountry_Italy\"\n",
    "HOMECOUNTRY_PHILLIPINES = \"Homecountry_Phillipines\"\n",
    "HOMECOUNTRY_ROMANIA = \"Homecountry_Romania\"\n",
    "HOMECOUNTRY_SAUDIARABIA = \"Homecountry_SaudiArabia\"\n",
    "HOMECOUNTRY_SINGAPORE = \"Homecountry_Singapore\"\n",
    "HOMECOUNTRY_SLOVENIA = \"Homecountry_Slovenia\"\n",
    "HOMECOUNTRY_UNITEDKINGDOM = \"Homecountry_UnitedKingdom\"\n",
    "HOMECOUNTRY_UNITEDSTATESOFAMERICA = \"Homecountry_UnitedStatesofAmerica\"\n",
    "# Income = 4 Columns\n",
    "INCOME_0 = \"Income_0\"\n",
    "INCOME_1 = \"Income_1\"\n",
    "INCOME_2 = \"Income_2\"\n",
    "INCOME_3 = \"Income_3\"\n",
    "# Mostlistenedmusics = 22 Columns\n",
    "MOSTLISTENEDMUSICS_1 = \"AlternativeMusic\"\n",
    "MOSTLISTENEDMUSICS_2 = \"AsianPopJPoporKpop\"\n",
    "MOSTLISTENEDMUSICS_3 = \"Blues\"\n",
    "MOSTLISTENEDMUSICS_4 = \"ClassicalMusic\"\n",
    "MOSTLISTENEDMUSICS_5 = \"CountryMusic\"\n",
    "MOSTLISTENEDMUSICS_6 = \"DanceMusic\"\n",
    "MOSTLISTENEDMUSICS_7 = \"EasyListening\"\n",
    "MOSTLISTENEDMUSICS_8 = \"ElectronicMusic\"\n",
    "MOSTLISTENEDMUSICS_9 = \"EuropeanMusicFolkPop\"\n",
    "MOSTLISTENEDMUSICS_10 = \"HipHopRap\"\n",
    "MOSTLISTENEDMUSICS_11 = \"IndiePop\"\n",
    "MOSTLISTENEDMUSICS_12 = \"InspirationalinclGospel\"\n",
    "MOSTLISTENEDMUSICS_13 = \"Jazz\"\n",
    "MOSTLISTENEDMUSICS_14 = \"LatinMusic\"\n",
    "MOSTLISTENEDMUSICS_15 = \"NewAge\"\n",
    "MOSTLISTENEDMUSICS_16 = \"Opera\"\n",
    "MOSTLISTENEDMUSICS_17 = \"PopPopularmusic\"\n",
    "MOSTLISTENEDMUSICS_18 = \"RampBSoul\"\n",
    "MOSTLISTENEDMUSICS_19 = \"Reggae\"\n",
    "MOSTLISTENEDMUSICS_20 = \"Rock\"\n",
    "MOSTLISTENEDMUSICS_21 = \"SingerSongwriterincFolk\"\n",
    "MOSTLISTENEDMUSICS_22 = \"WorldMusicBeats\"\n",
    "# Mostreadbooks = 31 Columns\n",
    "MOSTREADBOOKS_1 = \"ActionandAdventure\"\n",
    "MOSTREADBOOKS_2 = \"Anthologies\"\n",
    "MOSTREADBOOKS_3 = \"Art\"\n",
    "MOSTREADBOOKS_4 = \"Autobiographies\"\n",
    "MOSTREADBOOKS_5 = \"Biographies\"\n",
    "MOSTREADBOOKS_6 = \"Childrens\"\n",
    "MOSTREADBOOKS_7 = \"Childrensliterature\"\n",
    "MOSTREADBOOKS_8 = \"Comics\"\n",
    "MOSTREADBOOKS_9 = \"Cookbooks\"\n",
    "MOSTREADBOOKS_10 = \"Diaries\"\n",
    "MOSTREADBOOKS_11 = \"Drama\"\n",
    "MOSTREADBOOKS_12 = \"Encyclopedias\"\n",
    "MOSTREADBOOKS_13 = \"Eroticfiction\"\n",
    "MOSTREADBOOKS_14 = \"Fantasy\"\n",
    "MOSTREADBOOKS_15 = \"Guide\"\n",
    "MOSTREADBOOKS_16 = \"History\"\n",
    "MOSTREADBOOKS_17 = \"Horror\"\n",
    "MOSTREADBOOKS_18 = \"Journals\"\n",
    "MOSTREADBOOKS_19 = \"Math\"\n",
    "MOSTREADBOOKS_20 = \"Mystery\"\n",
    "MOSTREADBOOKS_21 = \"Poetry\"\n",
    "MOSTREADBOOKS_22 = \"Prayerbooks\"\n",
    "MOSTREADBOOKS_23 = \"Religious\"\n",
    "MOSTREADBOOKS_24 = \"Romance\"\n",
    "MOSTREADBOOKS_25 = \"Satire\"\n",
    "MOSTREADBOOKS_26 = \"Science\"\n",
    "MOSTREADBOOKS_27 = \"Sciencefiction\"\n",
    "MOSTREADBOOKS_28 = \"Selfhelp\"\n",
    "MOSTREADBOOKS_29 = \"Series\"\n",
    "MOSTREADBOOKS_30 = \"Travel\"\n",
    "MOSTREADBOOKS_31 = \"Trilogies\"\n",
    "# Mostwatchedmovies = 21 Columns\n",
    "MOSTWATCHEDMOVIES_1 = \"Mostwatchedmovies_Action\"\n",
    "MOSTWATCHEDMOVIES_2 = \"Mostwatchedmovies_Adventure\"\n",
    "MOSTWATCHEDMOVIES_3 = \"Mostwatchedmovies_Animation\"\n",
    "MOSTWATCHEDMOVIES_4 = \"Mostwatchedmovies_Biography\"\n",
    "MOSTWATCHEDMOVIES_5 = \"Mostwatchedmovies_Comedy\"\n",
    "MOSTWATCHEDMOVIES_6 = \"Mostwatchedmovies_CrimeandGangster\"\n",
    "MOSTWATCHEDMOVIES_7 = \"Mostwatchedmovies_Documentary\"\n",
    "MOSTWATCHEDMOVIES_8 = \"Mostwatchedmovies_Drama\"\n",
    "MOSTWATCHEDMOVIES_9 = \"Mostwatchedmovies_EpicHistorical\"\n",
    "MOSTWATCHEDMOVIES_10 = \"Mostwatchedmovies_Erotic\"\n",
    "MOSTWATCHEDMOVIES_11 = \"Mostwatchedmovies_Family\"\n",
    "MOSTWATCHEDMOVIES_12 = \"Mostwatchedmovies_Fantasy\"\n",
    "MOSTWATCHEDMOVIES_13 = \"Mostwatchedmovies_Horror\"\n",
    "MOSTWATCHEDMOVIES_14 = \"Mostwatchedmovies_Musical\"\n",
    "MOSTWATCHEDMOVIES_15 = \"Mostwatchedmovies_Mystery\"\n",
    "MOSTWATCHEDMOVIES_16 = \"Mostwatchedmovies_Romance\"\n",
    "MOSTWATCHEDMOVIES_17 = \"Mostwatchedmovies_SciFi\"\n",
    "MOSTWATCHEDMOVIES_18 = \"Mostwatchedmovies_Sport\"\n",
    "MOSTWATCHEDMOVIES_19 = \"Mostwatchedmovies_Thriller\"\n",
    "MOSTWATCHEDMOVIES_20 = \"Mostwatchedmovies_War\"\n",
    "MOSTWATCHEDMOVIES_21 = \"Mostwatchedmovies_Western\"\n",
    "# Mostwatchedtvprogrammes = 11 Columns\n",
    "MOSTWATCHEDTVPROGRAMMES_1 = \"Mostwatchedtvprogrammes_Childrens\"\n",
    "MOSTWATCHEDTVPROGRAMMES_2 = \"Mostwatchedtvprogrammes_Comedy\"\n",
    "MOSTWATCHEDTVPROGRAMMES_3 = \"Mostwatchedtvprogrammes_Drama\"\n",
    "MOSTWATCHEDTVPROGRAMMES_4 = \"Mostwatchedtvprogrammes_EntertainmentVarietyShows\"\n",
    "MOSTWATCHEDTVPROGRAMMES_5 = \"Mostwatchedtvprogrammes_Factual\"\n",
    "MOSTWATCHEDTVPROGRAMMES_6 = \"Mostwatchedtvprogrammes_Learning\"\n",
    "MOSTWATCHEDTVPROGRAMMES_7 = \"Mostwatchedtvprogrammes_Music\"\n",
    "MOSTWATCHEDTVPROGRAMMES_8 = \"Mostwatchedtvprogrammes_News\"\n",
    "MOSTWATCHEDTVPROGRAMMES_9 = \"Mostwatchedtvprogrammes_ReligionampEthics\"\n",
    "MOSTWATCHEDTVPROGRAMMES_10 = \"Mostwatchedtvprogrammes_Sport\"\n",
    "MOSTWATCHEDTVPROGRAMMES_11 = \"Mostwatchedtvprogrammes_Weather\"\n",
    "\n",
    "RATING = \"Rating\"\n",
    "AD_NUM_FACES = \"ad_num_faces\"\n",
    "AD_LABEL_FEATURE_1 = 'ad_isAdvertising'\n",
    "AD_LABEL_FEATURE_2 = 'ad_isBrand'\n",
    "AD_LABEL_FEATURE_3 = 'ad_isElectronicdevice'\n",
    "AD_LABEL_FEATURE_4 = 'ad_isElectronics'\n",
    "AD_LABEL_FEATURE_5 = 'ad_isFashionaccessory'\n",
    "AD_LABEL_FEATURE_6 = 'ad_isFictionalcharacter'\n",
    "AD_LABEL_FEATURE_7 = 'ad_isFont'\n",
    "AD_LABEL_FEATURE_8 = 'ad_isFurniture'\n",
    "AD_LABEL_FEATURE_9 = 'ad_isGadget'\n",
    "AD_LABEL_FEATURE_10 = 'ad_isGames'\n",
    "AD_LABEL_FEATURE_11 = 'ad_isGraphicdesign'\n",
    "AD_LABEL_FEATURE_12 = 'ad_isGraphics'\n",
    "AD_LABEL_FEATURE_13 = 'ad_isJewellery'\n",
    "AD_LABEL_FEATURE_14 = 'ad_isLine'\n",
    "AD_LABEL_FEATURE_15 = 'ad_isLogo'\n",
    "AD_LABEL_FEATURE_16 = 'ad_isMagenta'\n",
    "AD_LABEL_FEATURE_17 = 'ad_isMaterialproperty'\n",
    "AD_LABEL_FEATURE_18 = 'ad_isMultimedia'\n",
    "AD_LABEL_FEATURE_19 = 'ad_isProduct'\n",
    "AD_LABEL_FEATURE_20 = 'ad_isRectangle'\n",
    "AD_LABEL_FEATURE_21 = 'ad_isSkin'\n",
    "AD_LABEL_FEATURE_22 = 'ad_isTechnology'\n",
    "AD_LABEL_FEATURE_23 = 'ad_isText'\n",
    "AD_LABEL_FEATURE_24 = 'ad_isVehicle'\n",
    "AD_LABEL_FEATURE_25 = 'ad_isYellow'\n",
    "AD_SAFESEARCH_FEATURE_1 = 'ad_isAdult_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_2 ='ad_isAdult_VERY_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_3 ='ad_isSpoof_POSSIBLE'\n",
    "AD_SAFESEARCH_FEATURE_4 ='ad_isSpoof_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_5 ='ad_isSpoof_VERY_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_6 ='ad_isMedical_POSSIBLE'\n",
    "AD_SAFESEARCH_FEATURE_7 ='ad_isMedical_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_8 ='ad_isMedical_VERY_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_9 ='ad_isViolence_VERY_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_10 ='ad_isRacy_POSSIBLE'\n",
    "AD_SAFESEARCH_FEATURE_11 ='ad_isRacy_UNLIKELY'\n",
    "AD_SAFESEARCH_FEATURE_12 ='ad_isRacy_VERY_LIKELY'\n",
    "AD_SAFESEARCH_FEATURE_13 ='ad_isRacy_VERY_UNLIKELY'\n",
    "AD_OBJECT_FEATURE_1 = 'ad_isAnimal'\n",
    "AD_OBJECT_FEATURE_2 ='ad_isBelt'\n",
    "AD_OBJECT_FEATURE_3 ='ad_isBottle'\n",
    "AD_OBJECT_FEATURE_4 ='ad_isBox'\n",
    "AD_OBJECT_FEATURE_5 ='ad_isCameralens'\n",
    "AD_OBJECT_FEATURE_6 ='ad_isChair'\n",
    "AD_OBJECT_FEATURE_7 ='ad_isClothing'\n",
    "AD_OBJECT_FEATURE_8 ='ad_isEarrings'\n",
    "AD_OBJECT_FEATURE_9 ='ad_isFood'\n",
    "AD_OBJECT_FEATURE_10 ='ad_isHat'\n",
    "AD_OBJECT_FEATURE_11 ='ad_isLuggagebags'\n",
    "AD_OBJECT_FEATURE_12 ='ad_isMobilephone'\n",
    "AD_OBJECT_FEATURE_13 ='ad_isNecklace'\n",
    "AD_OBJECT_FEATURE_14 ='ad_isPackagedgoods'\n",
    "AD_OBJECT_FEATURE_15 ='ad_isPants'\n",
    "AD_OBJECT_FEATURE_16 ='ad_isPen'\n",
    "AD_OBJECT_FEATURE_17 ='ad_isPerson'\n",
    "AD_OBJECT_FEATURE_18 ='ad_isPillow'\n",
    "AD_OBJECT_FEATURE_19 ='ad_isPoster'\n",
    "AD_OBJECT_FEATURE_20 ='ad_isShoe'\n",
    "AD_OBJECT_FEATURE_21 ='ad_isTop'\n",
    "AD_OBJECT_FEATURE_22 ='ad_isToy'\n",
    "AD_OBJECT_FEATURE_23 ='ad_isWatch'\n",
    "AD_OBJECT_FEATURE_24  ='ad_isWheel'\n",
    "FAV = 'fav'\n",
    "UNFAV = 'unfav'\n",
    "\n",
    "\n",
    "# Read all columns as strings to avoid any errors\n",
    "COL_DEFAULTS = {\n",
    "    USER_ID: \"**\",\n",
    "    AD_ID: \"**\",\n",
    "    AGE: \"**\",\n",
    "    ZIP_CODE: \"**\",\n",
    "    COUNTRIES_VISITED: \"**\",\n",
    "    FAVE_SPORTS: \"**\",\n",
    "    GENDER: \"**\",\n",
    "    HOME_COUNTRY: \"**\",\n",
    "    HOME_TOWN: \"**\",\n",
    "    INCOME: \"**\",\n",
    "    LAST_NAME: \"**\",\n",
    "    MOST_LISTENED_MUSICS: \"**\",\n",
    "    MOST_READ_BOOKS: \"**\",\n",
    "    MOST_VISITED_WEBSITES: \"**\",\n",
    "    MOST_WATCHED_MOVIES: \"**\",\n",
    "    MOST_WATCHED_TV_PROGRAMMES: \"**\",\n",
    "    NAME: \"**\",\n",
    "    PAYPAL: \"**\",\n",
    "    TIMEPASS: \"**\",\n",
    "    TYPE_OF_JOB: \"**\",\n",
    "    WEEKLY_WORKING_HOURS: \"**\",\n",
    "    ADFILEPATH: \"**\",\n",
    "    GENDER_F: \"**\",\n",
    "    GENDER_M: \"**\",\n",
    "    HOMECOUNTRY_CANADA: \"**\",\n",
    "    HOMECOUNTRY_CZECHREPUBLIC: \"**\",\n",
    "    HOMECOUNTRY_GREATBRITAIN: \"**\",\n",
    "    HOMECOUNTRY_INDIA: \"**\",\n",
    "    HOMECOUNTRY_ITALY: \"**\",\n",
    "    HOMECOUNTRY_PHILLIPINES: \"**\",\n",
    "    HOMECOUNTRY_ROMANIA: \"**\",\n",
    "    HOMECOUNTRY_SAUDIARABIA: \"**\",\n",
    "    HOMECOUNTRY_SINGAPORE: \"**\",\n",
    "    HOMECOUNTRY_SLOVENIA: \"**\",\n",
    "    HOMECOUNTRY_UNITEDKINGDOM: \"**\",\n",
    "    HOMECOUNTRY_UNITEDSTATESOFAMERICA: \"**\",\n",
    "    INCOME_0: \"**\",\n",
    "    INCOME_1: \"**\",\n",
    "    INCOME_2: \"**\",\n",
    "    INCOME_3: \"**\",\n",
    "    MOSTLISTENEDMUSICS_1: \"**\",\n",
    "    MOSTLISTENEDMUSICS_2: \"**\",\n",
    "    MOSTLISTENEDMUSICS_3: \"**\",\n",
    "    MOSTLISTENEDMUSICS_4: \"**\",\n",
    "    MOSTLISTENEDMUSICS_5: \"**\",\n",
    "    MOSTLISTENEDMUSICS_6: \"**\",\n",
    "    MOSTLISTENEDMUSICS_7: \"**\",\n",
    "    MOSTLISTENEDMUSICS_8: \"**\",\n",
    "    MOSTLISTENEDMUSICS_9: \"**\",\n",
    "    MOSTLISTENEDMUSICS_10: \"**\",\n",
    "    MOSTLISTENEDMUSICS_11: \"**\",\n",
    "    MOSTLISTENEDMUSICS_12: \"**\",\n",
    "    MOSTLISTENEDMUSICS_13: \"**\",\n",
    "    MOSTLISTENEDMUSICS_14: \"**\",\n",
    "    MOSTLISTENEDMUSICS_15: \"**\",\n",
    "    MOSTLISTENEDMUSICS_16: \"**\",\n",
    "    MOSTLISTENEDMUSICS_17: \"**\",\n",
    "    MOSTLISTENEDMUSICS_18: \"**\",\n",
    "    MOSTLISTENEDMUSICS_19: \"**\",\n",
    "    MOSTLISTENEDMUSICS_20: \"**\",\n",
    "    MOSTLISTENEDMUSICS_21: \"**\",\n",
    "    MOSTLISTENEDMUSICS_22: \"**\",\n",
    "    MOSTREADBOOKS_1: \"**\",\n",
    "    MOSTREADBOOKS_2: \"**\",\n",
    "    MOSTREADBOOKS_3: \"**\",\n",
    "    MOSTREADBOOKS_4: \"**\",\n",
    "    MOSTREADBOOKS_5: \"**\",\n",
    "    MOSTREADBOOKS_6: \"**\",\n",
    "    MOSTREADBOOKS_7: \"**\",\n",
    "    MOSTREADBOOKS_8: \"**\",\n",
    "    MOSTREADBOOKS_9: \"**\",\n",
    "    MOSTREADBOOKS_10: \"**\",\n",
    "    MOSTREADBOOKS_11: \"**\",\n",
    "    MOSTREADBOOKS_12: \"**\",\n",
    "    MOSTREADBOOKS_13: \"**\",\n",
    "    MOSTREADBOOKS_14: \"**\",\n",
    "    MOSTREADBOOKS_15: \"**\",\n",
    "    MOSTREADBOOKS_16: \"**\",\n",
    "    MOSTREADBOOKS_17: \"**\",\n",
    "    MOSTREADBOOKS_18: \"**\",\n",
    "    MOSTREADBOOKS_19: \"**\",\n",
    "    MOSTREADBOOKS_20: \"**\",\n",
    "    MOSTREADBOOKS_21: \"**\",\n",
    "    MOSTREADBOOKS_22: \"**\",\n",
    "    MOSTREADBOOKS_23: \"**\",\n",
    "    MOSTREADBOOKS_24: \"**\",\n",
    "    MOSTREADBOOKS_25: \"**\",\n",
    "    MOSTREADBOOKS_26: \"**\",\n",
    "    MOSTREADBOOKS_27: \"**\",\n",
    "    MOSTREADBOOKS_28: \"**\",\n",
    "    MOSTREADBOOKS_29: \"**\",\n",
    "    MOSTREADBOOKS_30: \"**\",\n",
    "    MOSTREADBOOKS_31: \"**\",\n",
    "    MOSTWATCHEDMOVIES_1: \"**\",\n",
    "    MOSTWATCHEDMOVIES_2: \"**\",\n",
    "    MOSTWATCHEDMOVIES_3: \"**\",\n",
    "    MOSTWATCHEDMOVIES_4: \"**\",\n",
    "    MOSTWATCHEDMOVIES_5: \"**\",\n",
    "    MOSTWATCHEDMOVIES_6: \"**\",\n",
    "    MOSTWATCHEDMOVIES_7: \"**\",\n",
    "    MOSTWATCHEDMOVIES_8: \"**\",\n",
    "    MOSTWATCHEDMOVIES_9: \"**\",\n",
    "    MOSTWATCHEDMOVIES_10: \"**\",\n",
    "    MOSTWATCHEDMOVIES_11: \"**\",\n",
    "    MOSTWATCHEDMOVIES_12: \"**\",\n",
    "    MOSTWATCHEDMOVIES_13: \"**\",\n",
    "    MOSTWATCHEDMOVIES_14: \"**\",\n",
    "    MOSTWATCHEDMOVIES_15: \"**\",\n",
    "    MOSTWATCHEDMOVIES_16: \"**\",\n",
    "    MOSTWATCHEDMOVIES_17: \"**\",\n",
    "    MOSTWATCHEDMOVIES_18: \"**\",\n",
    "    MOSTWATCHEDMOVIES_19: \"**\",\n",
    "    MOSTWATCHEDMOVIES_20: \"**\",\n",
    "    MOSTWATCHEDMOVIES_21: \"**\",\n",
    "    MOSTWATCHEDTVPROGRAMMES_1: \"**\",\n",
    "    MOSTWATCHEDTVPROGRAMMES_2: \"**\",\n",
    "    MOSTWATCHEDTVPROGRAMMES_3: \"**\",\n",
    "    MOSTWATCHEDTVPROGRAMMES_4: \"**\",\n",
    "    MOSTWATCHEDTVPROGRAMMES_5: \"**\",\n",
    "    MOSTWATCHEDTVPROGRAMMES_6: \"**\",\n",
    "    MOSTWATCHEDTVPROGRAMMES_7: \"**\",\n",
    "    MOSTWATCHEDTVPROGRAMMES_8: \"**\",\n",
    "    MOSTWATCHEDTVPROGRAMMES_9: \"**\",\n",
    "    MOSTWATCHEDTVPROGRAMMES_10: \"**\",\n",
    "    MOSTWATCHEDTVPROGRAMMES_11: \"**\",    \n",
    "    RATING: \"**\",\n",
    "    AD_NUM_FACES: \"**\",\n",
    "    FAV: \"**\",\n",
    "    UNFAV: \"**\"\n",
    "}\n",
    "\n",
    "\n",
    "AD_FACE_COLS = [AD_NUM_FACES]\n",
    "AD_LABEL_COLS = [AD_LABEL_FEATURE_1,AD_LABEL_FEATURE_2,AD_LABEL_FEATURE_3,AD_LABEL_FEATURE_4,AD_LABEL_FEATURE_5,\n",
    "                AD_LABEL_FEATURE_6,AD_LABEL_FEATURE_7,AD_LABEL_FEATURE_8,AD_LABEL_FEATURE_9,AD_LABEL_FEATURE_10,\n",
    "                AD_LABEL_FEATURE_11,AD_LABEL_FEATURE_12,AD_LABEL_FEATURE_13,AD_LABEL_FEATURE_14,AD_LABEL_FEATURE_15,\n",
    "                AD_LABEL_FEATURE_16,AD_LABEL_FEATURE_17,AD_LABEL_FEATURE_18,AD_LABEL_FEATURE_19,AD_LABEL_FEATURE_20,\n",
    "                AD_LABEL_FEATURE_21,AD_LABEL_FEATURE_22,AD_LABEL_FEATURE_23,AD_LABEL_FEATURE_24,AD_LABEL_FEATURE_25]\n",
    "\n",
    "AD_OBJECT_COLS = [AD_OBJECT_FEATURE_1,AD_OBJECT_FEATURE_2,AD_OBJECT_FEATURE_3,AD_OBJECT_FEATURE_4,AD_OBJECT_FEATURE_5,\n",
    "                AD_OBJECT_FEATURE_6,AD_OBJECT_FEATURE_7,AD_OBJECT_FEATURE_8,AD_OBJECT_FEATURE_9,AD_OBJECT_FEATURE_10,\n",
    "                AD_OBJECT_FEATURE_11,AD_OBJECT_FEATURE_12,AD_OBJECT_FEATURE_13,AD_OBJECT_FEATURE_14,AD_OBJECT_FEATURE_15,\n",
    "                AD_OBJECT_FEATURE_16,AD_OBJECT_FEATURE_17,AD_OBJECT_FEATURE_18,AD_OBJECT_FEATURE_19,AD_OBJECT_FEATURE_20,\n",
    "                AD_OBJECT_FEATURE_21,AD_OBJECT_FEATURE_22,AD_OBJECT_FEATURE_23,AD_OBJECT_FEATURE_24]\n",
    "\n",
    "\n",
    "AD_SAFE_SEARCH_COLS = [AD_SAFESEARCH_FEATURE_1,AD_SAFESEARCH_FEATURE_2,AD_SAFESEARCH_FEATURE_3,AD_SAFESEARCH_FEATURE_4,\n",
    "                      AD_SAFESEARCH_FEATURE_5,AD_SAFESEARCH_FEATURE_6,AD_SAFESEARCH_FEATURE_7,AD_SAFESEARCH_FEATURE_8,\n",
    "                      AD_SAFESEARCH_FEATURE_9,AD_SAFESEARCH_FEATURE_10,AD_SAFESEARCH_FEATURE_11,AD_SAFESEARCH_FEATURE_12,AD_SAFESEARCH_FEATURE_13]\n",
    "\n",
    "\n",
    "SELECTED_AD_COLS = AD_FACE_COLS  + AD_LABEL_COLS + AD_OBJECT_COLS + AD_SAFE_SEARCH_COLS\n",
    "\n",
    "SELECTED_HOMECOUNTRY_COLS = [HOMECOUNTRY_CANADA, HOMECOUNTRY_CZECHREPUBLIC, HOMECOUNTRY_GREATBRITAIN,\n",
    "                             HOMECOUNTRY_INDIA, HOMECOUNTRY_ITALY, HOMECOUNTRY_PHILLIPINES, HOMECOUNTRY_ROMANIA,\n",
    "                             HOMECOUNTRY_SAUDIARABIA, HOMECOUNTRY_SINGAPORE, HOMECOUNTRY_SLOVENIA,\n",
    "                             HOMECOUNTRY_UNITEDKINGDOM, HOMECOUNTRY_UNITEDSTATESOFAMERICA]\n",
    "\n",
    "SELECTED_INCOME_COLS = [INCOME_0, INCOME_1, INCOME_2, INCOME_3]\n",
    "\n",
    "SELECTED_MOSTLISTENEDMUSICS_COLS = [MOSTLISTENEDMUSICS_1, MOSTLISTENEDMUSICS_2, MOSTLISTENEDMUSICS_3,\n",
    "                                    MOSTLISTENEDMUSICS_4, MOSTLISTENEDMUSICS_5, MOSTLISTENEDMUSICS_6,\n",
    "                                    MOSTLISTENEDMUSICS_7, MOSTLISTENEDMUSICS_8, MOSTLISTENEDMUSICS_9,\n",
    "                                    MOSTLISTENEDMUSICS_10, MOSTLISTENEDMUSICS_11, MOSTLISTENEDMUSICS_12,\n",
    "                                    MOSTLISTENEDMUSICS_13, MOSTLISTENEDMUSICS_14, MOSTLISTENEDMUSICS_15,\n",
    "                                    MOSTLISTENEDMUSICS_16, MOSTLISTENEDMUSICS_17, MOSTLISTENEDMUSICS_18,\n",
    "                                    MOSTLISTENEDMUSICS_19, MOSTLISTENEDMUSICS_20, MOSTLISTENEDMUSICS_21,\n",
    "                                    MOSTLISTENEDMUSICS_22]\n",
    "\n",
    "SELECTED_MOSTREADBOOKS_COLS = [MOSTREADBOOKS_1, MOSTREADBOOKS_2, MOSTREADBOOKS_3, MOSTREADBOOKS_4,\n",
    "                               MOSTREADBOOKS_5, MOSTREADBOOKS_6, MOSTREADBOOKS_7, MOSTREADBOOKS_8,\n",
    "                               MOSTREADBOOKS_9, MOSTREADBOOKS_10, MOSTREADBOOKS_11, MOSTREADBOOKS_12,\n",
    "                               MOSTREADBOOKS_13, MOSTREADBOOKS_14, MOSTREADBOOKS_15, MOSTREADBOOKS_16,\n",
    "                               MOSTREADBOOKS_17, MOSTREADBOOKS_18, MOSTREADBOOKS_19, MOSTREADBOOKS_20,\n",
    "                               MOSTREADBOOKS_21, MOSTREADBOOKS_22, MOSTREADBOOKS_23, MOSTREADBOOKS_24,\n",
    "                               MOSTREADBOOKS_25, MOSTREADBOOKS_26, MOSTREADBOOKS_27, MOSTREADBOOKS_28,\n",
    "                               MOSTREADBOOKS_29, MOSTREADBOOKS_30, MOSTREADBOOKS_31] \n",
    "\n",
    "SELECTED_MOSTWATCHEDMOVIES_COLS = [MOSTWATCHEDMOVIES_1, MOSTWATCHEDMOVIES_2, MOSTWATCHEDMOVIES_3,\n",
    "                                   MOSTWATCHEDMOVIES_4, MOSTWATCHEDMOVIES_5, MOSTWATCHEDMOVIES_6,\n",
    "                                   MOSTWATCHEDMOVIES_7, MOSTWATCHEDMOVIES_8, MOSTWATCHEDMOVIES_9,\n",
    "                                   MOSTWATCHEDMOVIES_10, MOSTWATCHEDMOVIES_11, MOSTWATCHEDMOVIES_12,\n",
    "                                   MOSTWATCHEDMOVIES_13, MOSTWATCHEDMOVIES_14, MOSTWATCHEDMOVIES_15,\n",
    "                                   MOSTWATCHEDMOVIES_16, MOSTWATCHEDMOVIES_17, MOSTWATCHEDMOVIES_18,\n",
    "                                   MOSTWATCHEDMOVIES_19, MOSTWATCHEDMOVIES_20, MOSTWATCHEDMOVIES_21]\n",
    "\n",
    "SELECTED_MOSTWATCHEDTVPROGRAMMES_COLS = [MOSTWATCHEDTVPROGRAMMES_1, MOSTWATCHEDTVPROGRAMMES_2,\n",
    "                                         MOSTWATCHEDTVPROGRAMMES_3, MOSTWATCHEDTVPROGRAMMES_4,\n",
    "                                         MOSTWATCHEDTVPROGRAMMES_5, MOSTWATCHEDTVPROGRAMMES_6,\n",
    "                                         MOSTWATCHEDTVPROGRAMMES_7, MOSTWATCHEDTVPROGRAMMES_8,\n",
    "                                         MOSTWATCHEDTVPROGRAMMES_9, MOSTWATCHEDTVPROGRAMMES_10,\n",
    "                                         MOSTWATCHEDTVPROGRAMMES_11]\n",
    "                                   \n",
    "SELECTED_INP_COLS = [AGE, ZIP_CODE, FAVE_SPORTS, GENDER_F, GENDER_M] +\\\n",
    "                    SELECTED_AD_COLS +\\\n",
    "                    SELECTED_HOMECOUNTRY_COLS +\\\n",
    "                    SELECTED_INCOME_COLS +\\\n",
    "                    SELECTED_MOSTLISTENEDMUSICS_COLS +\\\n",
    "                    SELECTED_MOSTREADBOOKS_COLS +\\\n",
    "                    SELECTED_MOSTWATCHEDMOVIES_COLS +\\\n",
    "                    SELECTED_MOSTWATCHEDTVPROGRAMMES_COLS\n",
    "\n",
    "EMBED_COLS = [FAV, UNFAV]\n",
    "\n",
    "SELECTED_COLS = SELECTED_INP_COLS + [TARGET_COL]\n",
    "\n",
    "print(SELECTED_COLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness - Preprocess mitigation plan : Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reweigh_biased_cols(bias_cols,df):\n",
    "   \n",
    "    X = df[bias_cols]\n",
    "    y = df[[\"Rating\"]]\n",
    "    \n",
    "    # Assumtion for each column (except AGE) value 1 : privilaged , value 0 : non-privilaged\n",
    "    \n",
    "    priv_cols = []\n",
    "    \n",
    "    for col in bias_cols: \n",
    "        \n",
    "        if(col == 'Age'):\n",
    "            X['Age'] = pd.to_numeric(X['Age'])\n",
    "            bucket_boundaries = [0, 20, 40, 100] # refer pandas.cut() for syntax on binning\n",
    "            X[\"Age_bucket\"] = pd.cut(X[\"Age\"], bins=bucket_boundaries, labels=[\"young\", \"middle-age\", \"old\"])\n",
    "            X['privilaged_age_bucket'] = 0.0\n",
    "            #considering young and old as privilaged group\n",
    "            X.loc[X['Age_bucket'] != \"young\", 'privilaged_age_bucket'] = 1.0 \n",
    "            priv_cols.append('privilaged_age_bucket')  \n",
    "            \n",
    "        else :\n",
    "            X[col] = pd.to_numeric(X[col])\n",
    "            priv_cols.append(col)  \n",
    "    \n",
    "    \n",
    "    y['Rating'] = pd.to_numeric(y['Rating'])\n",
    "    y.loc[y[\"Rating\"] != 1.0, \"Rating\"] = 2.0\n",
    "    y['Rating'] = y['Rating'] - 1.0\n",
    "    \n",
    "    X = X[priv_cols]\n",
    "    \n",
    "    train_pp_bld = BinaryLabelDataset(df=pd.concat((X, y),\n",
    "                                               axis=1),\n",
    "                                  label_names=['Rating'],\n",
    "                                  protected_attribute_names=priv_cols,\n",
    "                                  favorable_label=1.0,\n",
    "                                  unfavorable_label=0.0)\n",
    "    \n",
    "    privileged_dict = {}\n",
    "    unprivileged_dict = {}\n",
    "    for col in priv_cols:\n",
    "        privileged_dict[col] = 1\n",
    "        unprivileged_dict[col] = 0\n",
    "    \n",
    "    privileged_groups = [privileged_dict]\n",
    "    unprivileged_groups = [unprivileged_dict]\n",
    "    \n",
    "    \n",
    "    # Create the metric object\n",
    "    metric_train_bld = BinaryLabelDatasetMetric(train_pp_bld,\n",
    "                                            unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups)\n",
    "    \n",
    "    \n",
    "    rw = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "    train_pp_bld_f = rw.fit_transform(train_pp_bld)\n",
    "    \n",
    "    \n",
    "    #df[\"fairness_privilage_weight\"] = train_pp_bld_f.instance_weights\n",
    "    #df[\"fairness_privilage_weight\"] = df[\"fairness_privilage_weight\"].astype(str)\n",
    "    \n",
    "    return train_pp_bld_f.instance_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ad_dataset_pd(usecols:List[str]=None, **read_csv_kwargs):\n",
    "    \"\"\"\n",
    "    Read from csv files given set of columns into Pandas Dataframe\n",
    "    \"\"\"\n",
    "    return pd.read_csv(users_ads_rating_csv, usecols=usecols, dtype=str, **read_csv_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ad_dataset_pd(SELECTED_COLS).sample(5).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chakin.search(lang='English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_VEC_DIMENSIONS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "embedding_index = EmbeddingFactory(Path(\"./embeddings/\"), \"GloVe.6B.50d\", WORD_VEC_DIMENSIONS, nrows=None, skiprows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_embed_col(s:pd.Series, t:Tokenizer, maxlen:int=None):\n",
    "    \"\"\"Tokenizes each row in s using t and pads them to equal length of maxlen. Computes maxlen if not provided\"\"\"\n",
    "    # integer encode the text data\n",
    "    encoded_col = t.texts_to_sequences(s)\n",
    "\n",
    "    # calculate max len of vector and make length equal by padding with zeros\n",
    "    if maxlen is None:\n",
    "        maxlen = max(len(x) for x in encoded_col) \n",
    "        \n",
    "    return pad_sequences(encoded_col, maxlen=maxlen, padding='post'), maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_data(df:pd.DataFrame) -> Dict:\n",
    "    \"\"\"Compute metadata and embedding matrix for each embedding column in df\"\"\"\n",
    "    \n",
    "    es = defaultdict(dict) # embedding_store\n",
    "    for embed_col in EMBED_COLS:\n",
    "        # Input dataframe and embed_col\n",
    "        t = Tokenizer()\n",
    "        t.fit_on_texts(df[embed_col])\n",
    "        es[embed_col][\"tokenizer\"] = t\n",
    "\n",
    "        # UNK added as tokenizer starts indexing from 1\n",
    "        words = [\"UNK\"] + list(t.word_index.keys()) # in order of tokenizer\n",
    "        es[embed_col][\"vocab_size\"] = len(words)\n",
    "        es[embed_col][\"padded_col\"], es[embed_col][\"maxlen\"] = transform_embed_col(df[embed_col], t)\n",
    "\n",
    "        # create a weight matrix\n",
    "        embeddings = dict.fromkeys(words, \" \".join([\"0\"] * WORD_VEC_DIMENSIONS)) # default embeddings to all words as 0\n",
    "        embeddings.update(dict(embedding_index.fetch_word_vectors(words))) # update for known words\n",
    "        # reorder to match tokenizer's indexing\n",
    "        emb_matrix = pd.DataFrame.from_dict(embeddings, orient=\"index\").loc[words, 0].str.split(\" \", expand=True).to_numpy().astype(np.float16)\n",
    "        es[embed_col][\"embed_matrix\"] = emb_matrix\n",
    "        assert emb_matrix.shape[0] == len(words), f\"For {embed_col}, not all words have embeddings\"\n",
    "        \n",
    "    return es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_embedding_data(ad_dataset_pd(EMBED_COLS).sample(n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dict_project(d:Dict, cols:List[str]) -> Dict:\n",
    "    \"\"\"Returns a new dictionary with only cols keys\"\"\"\n",
    "    return {k:v for k, v in d.items() if k in cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class IndexerForVocab:\n",
    "    def __init__(self, vocab_list:List[str], oov_index:int=0):\n",
    "        \"\"\"\n",
    "        Creates a string indexer for the vocabulary with out of vocabulary (oov) indexing\n",
    "        \"\"\"\n",
    "        self._vocab_map = {v:i+1 for i, v in enumerate(vocab_list)}\n",
    "        self._oov = oov_index\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"Map for {len(self)} keys with 1 OOV key\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._vocab_map) + 1\n",
    "        \n",
    "    def index_of(self, item:str):\n",
    "        \"\"\"\n",
    "        Index of item in the vocabulary\n",
    "        \"\"\"\n",
    "        return self._vocab_map.get(item, self._oov)\n",
    "    \n",
    "    def index_of_mux(self, items:List[str]):\n",
    "        return [self.index_of(i) for i in items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Age\n",
    "\n",
    "Convert to a number and remove any outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Obtained from Tensorflow Data Validation APIs data-exploration/tensorflow-data-validation.ipynb\n",
    "\n",
    "MEAN_AGE, STD_AGE, MEDIAN_AGE, MAX_AGE = 31.74, 12.07, 29, 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fix_age(age_str:tf.string, default_age=MEDIAN_AGE) -> int:\n",
    "    \"\"\"Typecast age to an integer and update outliers with the default\"\"\"\n",
    "    try:\n",
    "        age = int(age_str)\n",
    "        if age < 0 or age > MAX_AGE:\n",
    "            raise ValueError(f\"{age} is not a valid age\")\n",
    "    except:\n",
    "        age = default_age\n",
    "    normalized_age = (age - MEAN_AGE) / STD_AGE\n",
    "    return normalized_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Visual Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fix_age(\"50\"), fix_age(\"50.5\"), fix_age(\"-10\"), fix_age(\"bad_age_10\"), fix_age(\"300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Zip Code\n",
    "\n",
    "Prepare zip-code column for one-hot encoding each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DEFAULT_ZIP_CODE, FIRST_K_ZIP_DIGITS = \"00000\", 2\n",
    "\n",
    "zip_code_indexer = IndexerForVocab(string.digits + string.ascii_lowercase + string.ascii_uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fix_zip_code_tensor(zip_code:tf.string, n_digits, indexer) -> List[str]:\n",
    "    \"\"\"Extracts the the first n_digits as a list\"\"\"\n",
    "    zip_digits = []\n",
    "    try:\n",
    "        if isinstance(zip_code, tf.Tensor):\n",
    "            zip_code = zip_code.numpy()[0].decode('ascii', errors=\"ignore\") # very ineffecient way\n",
    "        zip_digits = list(zip_code.strip()[:n_digits])\n",
    "    except:\n",
    "        zip_digits = list(DEFAULT_ZIP_CODE[:n_digits])\n",
    "    return tf.concat( [\n",
    "        tf.one_hot(\n",
    "            indexer.index_of(d), len(indexer)\n",
    "        ) for d in zip_digits\n",
    "    ], 0 )\n",
    "\n",
    "def fix_zip_code(zip_code:str, n_digits, indexer) -> List[str]:\n",
    "    \"\"\"Extracts the the first n_digits as a list\"\"\"\n",
    "    zip_digits = []\n",
    "    try:\n",
    "        zip_digits = list(zip_code.strip()[:n_digits])\n",
    "    except:\n",
    "        zip_digits = list(DEFAULT_ZIP_CODE[:n_digits])\n",
    "    return np.ravel(np.eye(len(indexer))[indexer.index_of_mux(zip_digits)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Visual Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_zip_code_indexer = IndexerForVocab(string.digits)\n",
    "\n",
    "(fix_zip_code(\"43556\", 10, test_zip_code_indexer),\n",
    "fix_zip_code(\"43556\", 2, test_zip_code_indexer),\n",
    "fix_zip_code(\"43556\", 4, test_zip_code_indexer),\n",
    "fix_zip_code(None, 3, test_zip_code_indexer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Favorite Sports\n",
    "\n",
    "Two approaches,\n",
    "1. Consider the first `K` sports mentioned by each user and one-hot encode each separately\n",
    "2. Multi label binarize all the sports as there are only 15 unique sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FAV_SPORTS_UNKNOWN = \"UNK_SPORT\"\n",
    "ALL_FAV_SPORTS = ['Olympic sports', 'Winter sports', 'Nothing', 'I do not like Sports', 'Equestrian sports', 'Skating sports', 'Precision sports', 'Hunting sports', 'Motor sports', 'Team sports', 'Individual sports', 'Other', 'Water sports', 'Indoor sports', 'Endurance sports']\n",
    "\n",
    "fav_sports_binarizer = MultiLabelBinarizer()\n",
    "fav_sports_binarizer.fit([ALL_FAV_SPORTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fav_sports_multi_select_str_to_list(sports_str:Union[str, tf.Tensor]) -> List[str]:\n",
    "    # remove commas that dont separate different user selections\n",
    "    # example, commas inside paranthesis of \"Individual sports (Tennis, Archery, ...)\" dont make new sports\n",
    "    if isinstance(sports_str, tf.Tensor):\n",
    "        sports_str = sports_str.numpy()[0].decode('ascii', errors=\"ignore\")\n",
    "    else:\n",
    "        sports_str = sports_str.encode(\"ascii\", errors=\"ignore\").decode(\"ascii\") # remove non-ascii chars\n",
    "    sports = re.sub(r\"\\s*\\(.*,.*\\)\\s*\", \"\", sports_str)\n",
    "    return re.split(r\"\\s*,\\s*\", sports)\n",
    "\n",
    "def fix_fav_sports_mlb(sports_str:str) -> List[int]:\n",
    "    sports = fav_sports_multi_select_str_to_list(sports_str)\n",
    "    return fav_sports_binarizer.transform([sports])[0]\n",
    "\n",
    "def fix_fav_sports_firstk(sports_str:str, first_k:int, pad_constant:int) -> List[str]:\n",
    "    sports = fav_sports_multi_select_str_to_list(sports_str)\n",
    "    right_pad_width = first_k - len(sports_enc)\n",
    "    result = [sports + [pad_constant] * right_pad_width][:first_k]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Visual Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    fix_fav_sports_mlb(\"Individual sports (Tennis, Archery, ...), Indoor sports, Endurance sports, Skating sports\"),\n",
    "    fix_fav_sports_mlb(\"Skating sports\"),\n",
    "    fix_fav_sports_mlb(\"Individual sports (Tennis, Archery, ...)\"),\n",
    "    fix_fav_sports_mlb(\"Indoor sports, Endurance sports, Skating sports\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RATINGS_CARDINALITY = 2 # not zero based indexing i.e. ratings range from 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_target_pd(rating_str:str):\n",
    "    return np.eye(RATINGS_CARDINALITY, dtype=int)[int(float(rating_str)) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FRAC = 0.2\n",
    "fairness_reweighing_enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pd_X(df:pd.DataFrame, inp_cols:List[str]):\n",
    "    \"\"\"Original dataframe will be modified\"\"\"\n",
    "    df[AGE] = df[AGE].apply(lambda age: [fix_age(age)])\n",
    "    df[ZIP_CODE] = df[ZIP_CODE].apply(lambda zc: fix_zip_code(zc, n_digits=2, indexer=zip_code_indexer))\n",
    "    df[FAVE_SPORTS] = df[FAVE_SPORTS].apply(fix_fav_sports_mlb)\n",
    "\n",
    "    int_cols = [GENDER_F, GENDER_M, AD_NUM_FACES] +\\\n",
    "               AD_LABEL_COLS +\\\n",
    "               AD_SAFE_SEARCH_COLS +\\\n",
    "               SELECTED_HOMECOUNTRY_COLS +\\\n",
    "               SELECTED_INCOME_COLS +\\\n",
    "               SELECTED_MOSTLISTENEDMUSICS_COLS +\\\n",
    "               SELECTED_MOSTREADBOOKS_COLS +\\\n",
    "               SELECTED_MOSTWATCHEDMOVIES_COLS +\\\n",
    "               SELECTED_MOSTWATCHEDTVPROGRAMMES_COLS +\\\n",
    "               AD_OBJECT_COLS\n",
    "    \n",
    "    df[int_cols] = df[int_cols].applymap(lambda f: [int(f)])\n",
    "    \n",
    "    df[\"X\"] = df[inp_cols].apply(np.concatenate, axis=1)\n",
    "    # TODO: vectorize, else inefficient to sequentially loop over all examples\n",
    "    X = np.array([x for x in df[\"X\"]])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_minority_classes(df, target_col):\n",
    "    \"\"\"Original dataframe is modified\"\"\"\n",
    "    df.loc[df[target_col] != \"1.0\", target_col] = \"2.0\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pd_y(df:pd.DataFrame, target_col:str):\n",
    "    \"\"\"Original dataframe will be modified\"\"\"\n",
    "    if (RATINGS_CARDINALITY == 2) :\n",
    "        df = merge_minority_classes(df, target_col)\n",
    "        \n",
    "    df[\"y\"] = df[target_col].apply(create_target_pd)\n",
    "    # TODO: vectorize, else inefficient to sequentially loop over all examples\n",
    "    y = np.array([y for y in df[\"y\"]])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_pd(inp_cols:List[str]=SELECTED_INP_COLS, target_col:str=TARGET_COL, fraction:float=1, test_frac:float=TEST_FRAC) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, List]:\n",
    "    \"\"\"\n",
    "    Prepare the dataset for training on a fraction of all input data\n",
    "    Columns using embeddings are split seperately and returned in list of tuples called embed_features\n",
    "    \"\"\"\n",
    "    # NOTE: RANDOM_SEED should be same for both splits\n",
    "    # Create (train, test) split of selected columns and target \n",
    "    df = ad_dataset_pd(SELECTED_COLS + EMBED_COLS).sample(frac=fraction)\n",
    "    \n",
    "    if fairness_reweighing_enabled:\n",
    "        bias_cols = ['Gender_F','Age']\n",
    "        sample_weights = reweigh_biased_cols(bias_cols,df)\n",
    "    else:\n",
    "        sample_weights = np.ones(shape=(df.shape[0],))\n",
    "\n",
    "    \n",
    "    X, y = transform_pd_X(df[SELECTED_COLS], inp_cols), transform_pd_y(df[SELECTED_COLS], target_col)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_frac, random_state=RANDOM_SEED)\n",
    "    \n",
    "    # Create (train, test) split for each embedding column\n",
    "    embed_features, embedding_store = {}, create_embedding_data(df)\n",
    "    # TODO: this loop can be vectorized for speed\n",
    "    for embed_col in EMBED_COLS:\n",
    "        X_embed_train, X_embed_test = train_test_split(embedding_store[embed_col][\"padded_col\"], test_size=test_frac, random_state=RANDOM_SEED)\n",
    "        embed_features[embed_col] = {\"train\": X_embed_train, \"test\": X_embed_test}\n",
    "        \n",
    "    sample_weights_train,sample_weights_test = train_test_split(sample_weights, test_size=test_frac, random_state=RANDOM_SEED)\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test, embed_features, embedding_store, sample_weights_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tensorboard\n",
    "\n",
    "Monitor training and other stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Start tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "notebook.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Create a model and train using high level APIs like `tf.keras` and `tf.estimator`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/Z1eVQu9.png\" width=\"600\" height=\"300\">\n",
    "<p style=\"text-align: center;\"><strong>Image Credits:</strong> https://www.kaggle.com/colinmorris/embedding-layers</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_train, X_test, y_train, y_test, embed_features, embedding_store, sample_weights_train = create_dataset_pd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the transformed data for repeatable future experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = X_train, X_test, y_train, y_test, embed_features, embedding_store\n",
    "\n",
    "with open(f\"inp-{RANDOM_SEED}.pickle\", \"wb\") as f:\n",
    "    pickle.dump(inp, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Balance training data classes : Random oversampling , SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_embed_feature_1 = embed_features[FAV][\"train\"]\n",
    "train_embed_feature_2 = embed_features[UNFAV][\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def balance_classes(X_train , y_train , train_embed_feature_1 , train_embed_feature_2 , smote):\n",
    "    \n",
    "    if fairness_reweighing_enabled:\n",
    "        raise ValueError('Dont use class balancing with reweighing enabled (fairness_reweighing_enabled = 1)')\n",
    "        \n",
    "    #concatenate embedding columns to X_train\n",
    "    X_train_cols = X_train.shape[1]\n",
    "    train_embed_feature_1_cols = train_embed_feature_1.shape[1]\n",
    "    train_embed_feature_2_cols = train_embed_feature_2.shape[1]\n",
    "    \n",
    "    #convert OHE target to normal\n",
    "    y_train_normal = [np.where(r==1)[0][0] for r in y_train]\n",
    "    \n",
    "    x_train_concat = np.concatenate((X_train,train_embed_feature_1,train_embed_feature_2),axis=1)\n",
    "    \n",
    "    if(smote):\n",
    "        smote_oversample = SMOTE()\n",
    "        X_t, y_t = smote_oversample.fit_resample(x_train_concat, y_train_normal)\n",
    "    else:\n",
    "        random_oversample = RandomOverSampler()\n",
    "        X_t, y_t = random_oversample.fit_sample(x_train_concat, y_train_normal)\n",
    "    \n",
    "    #regenerate x_train , y_train and embedding columns from X_t\n",
    "    y_train = np.eye(RATINGS_CARDINALITY, dtype=int)[y_t]\n",
    "    X_train = X_t[:,0:X_train_cols]\n",
    "    train_embed_feature_1 = X_t[:, X_train_cols : X_train_cols+train_embed_feature_1_cols]\n",
    "    train_embed_feature_2 = X_t[:, X_train_cols+train_embed_feature_1_cols : X_train_cols+train_embed_feature_1_cols+train_embed_feature_2_cols]\n",
    "    \n",
    "    return X_train, y_train, train_embed_feature_1, train_embed_feature_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not fairness_reweighing_enabled:\n",
    "    X_train, y_train, embed_features[FAV][\"train\"], embed_features[UNFAV][\"train\"] = balance_classes(X_train,y_train,\n",
    "                                                                                  train_embed_feature_1,train_embed_feature_2,\n",
    "                                                                                  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, embed_features[FAV][\"train\"].shape, embed_features[UNFAV][\"train\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Check the number of samples per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(y_train)[0].value_counts(), pd.DataFrame(y_test)[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_metrics = [\n",
    "    \"accuracy\",\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc')\n",
    "]\n",
    "train_histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of train cat & num features \",X_train.shape)\n",
    "print(\"Size of output for train \",y_train.shape)\n",
    "print(\"Size of test cat & num features \",X_test.shape)\n",
    "print(\"Size of output for test \",y_test.shape)\n",
    "print(\"No. of embedded features \",len(embed_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_unknown_word_count(col:str):\n",
    "    unk_embed_vec = np.zeros((embedding_store[col][\"vocab_size\"], WORD_VEC_DIMENSIONS))\n",
    "    num_rows = np.count_nonzero(embedding_store[col][\"embed_matrix\"] == unk_embed_vec, axis=1).sum() / WORD_VEC_DIMENSIONS\n",
    "    logging.warning(f\"Could't find embeddings for {int(num_rows)} words in {col} column\")\n",
    "    \n",
    "log_unknown_word_count(FAV), log_unknown_word_count(UNFAV) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embed_flat_layer(col:str, trainable_embed:bool=False):\n",
    "    col_input = Input(shape=(embedding_store[col]['maxlen'],), name=col)\n",
    "    col_embedded = Embedding(embedding_store[col]['vocab_size'], WORD_VEC_DIMENSIONS, weights=[embedding_store[col]['embed_matrix']],\n",
    "                     input_length = embedding_store[col]['maxlen'], trainable=trainable_embed)(col_input)\n",
    "    col_embedded_flat = Flatten()(col_embedded)\n",
    "    return col_input, col_embedded_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_arch(inp):\n",
    "    out = Dense(20, activation='relu')(inp)\n",
    "    out = Dense(10, activation='relu')(out)\n",
    "    return Dense(RATINGS_CARDINALITY, activation='softmax')(out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_with_embeddings():\n",
    "    # Input layers\n",
    "    selected_cols_input = Input(shape=(X_train.shape[1],), name=\"non_embed_inputs\")\n",
    "    fav_input, fav_embed = create_embed_flat_layer(FAV)\n",
    "    unfav_input, unfav_embed = create_embed_flat_layer(UNFAV)\n",
    "\n",
    "    # Concatenate the layers\n",
    "    concatenated = concatenate([fav_embed, unfav_embed, selected_cols_input]) \n",
    "    out = model_arch(concatenated)\n",
    "\n",
    "    # Create the model\n",
    "    return Model(\n",
    "        inputs = [fav_input, unfav_input, selected_cols_input],\n",
    "        outputs = out,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_without_embeddings():\n",
    "    selected_cols_input = Input(shape=(X_train.shape[1],), name=\"non_embed_inputs\")\n",
    "    out = model_arch(selected_cols_input)\n",
    "\n",
    "    # Create the model\n",
    "    return Model(\n",
    "        inputs = selected_cols_input,\n",
    "        outputs = out,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_data(with_embed:bool=True):\n",
    "    d = {}\n",
    "    if with_embed:\n",
    "        d[\"X_train\"] = [embed_features[FAV][\"train\"], embed_features[UNFAV][\"train\"], X_train]\n",
    "        d[\"y_train\"] = y_train\n",
    "        d[\"val_data\"] = ([embed_features[FAV][\"test\"], embed_features[UNFAV][\"test\"], X_test], y_test)\n",
    "    else:\n",
    "        d[\"X_train\"] = X_train\n",
    "        d[\"y_train\"] = y_train\n",
    "        d[\"val_data\"] = (X_test, y_test)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model_with_embeddings()\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(\n",
    "        learning_rate=0.003,\n",
    "        clipvalue=0.5\n",
    "    ), \n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=keras_model_metrics\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4096\n",
    "EPOCHS = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Track hyperparameters using https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = Path(\"logs\")/f\"{RANDOM_SEED}\" #datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    logdir, \n",
    "    histogram_freq=max(1, ceil(EPOCHS / 20)), # to control the amount of logging\n",
    "#     embeddings_freq=epochs,\n",
    ")\n",
    "print(f\"Logging tensorboard data at {logdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# mfd = model_fit_data(with_embed=True)\n",
    "# train_histories.append(model.fit(\n",
    "#     mfd[\"X_train\"], mfd[\"y_train\"],\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     epochs=3,\n",
    "#     validation_data=mfd[\"val_data\"],\n",
    "#     callbacks=[tfdocs.modeling.EpochDots(), tensorboard_callback], \n",
    "#     verbose=0\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_histories.append(model.fit(\n",
    "    {\n",
    "        FAV: embed_features[FAV][\"train\"],\n",
    "        UNFAV: embed_features[UNFAV][\"train\"],\n",
    "        \"non_embed_inputs\": X_train\n",
    "    }, \n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(\n",
    "        {\n",
    "            FAV: embed_features[FAV][\"test\"],\n",
    "            UNFAV: embed_features[UNFAV][\"test\"],\n",
    "            \"non_embed_inputs\": X_test\n",
    "        },\n",
    "        y_test\n",
    "    ),\n",
    "    callbacks=[tfdocs.modeling.EpochDots(), tensorboard_callback], \n",
    "    verbose=0,\n",
    "    sample_weight=sample_weights_train #from af360 fairness reweighting\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(train_histories[-1].history) # pick the latest training history\n",
    "\n",
    "metrics_df.tail(1) # pick the last epoch's metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tip:` You can copy the final metrics row from above and paste it using `Shift + Cmd + V` in our [sheet](https://docs.google.com/spreadsheets/d/1v-nYiDA3elM1UP9stkB42MK0bTbuLxYJE7qAYDP8FHw/edit#gid=925421130) to accurately place all values in the respective columns\n",
    "\n",
    "**IMPORTANT**: Please don't forget to update git version ID column after you check-in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Model Metrics with p-value\n",
    "\n",
    "TODO: Run multiple times on different samples of `y_test` to compute p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report, precision_score, recall_score, f1_score\n",
    "import sklearn\n",
    "from collections import OrderedDict\n",
    "\n",
    "assert sklearn.__version__.startswith('0.22'), \"Please upgrade scikit-learn (https://scikit-learn.org/stable/install.html)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_prob = model.predict([embed_features[FAV][\"test\"], embed_features[UNFAV][\"test\"], X_test], BATCH_SIZE)\n",
    "y_true = y_test\n",
    "y_pred = (y_prob / np.max(y_prob, axis=1).reshape(-1, 1)).astype(int) # convert probabilities to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(OrderedDict({\n",
    "    \"macro_roc_auc_ovo\": [roc_auc_score(y_test, y_prob, multi_class=\"ovo\", average=\"macro\")],\n",
    "    \"weighted_roc_auc_ovo\": roc_auc_score(y_test, y_prob, multi_class=\"ovo\", average=\"weighted\"),\n",
    "    \"macro_roc_auc_ovr\": roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\"),\n",
    "    \"weighted_roc_auc_ovr\": roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"weighted\"),\n",
    "    \"weighted_precision\": precision_score(y_test, y_pred, average=\"weighted\"),\n",
    "    \"weighted_recall\": recall_score(y_test, y_pred, average=\"weighted\"),\n",
    "    \"weighted_f1\": f1_score(y_test, y_pred, average=\"weighted\")\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Also paste the above numbers to our [sheet](https://docs.google.com/spreadsheets/d/1v-nYiDA3elM1UP9stkB42MK0bTbuLxYJE7qAYDP8FHw/edit#gid=925421130&range=W1:AC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Export\n",
    "\n",
    "Save the model for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.save((logdir/\"keras_saved_model\").as_posix(), save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PREDICTED_RATING, PREDICTION_CONFIDENCE = \"pred_rating\", \"pred_confidence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def predict_on_dataset(df:pd.DataFrame, model:tf.keras.Model, es:Dict, inp_cols_of_interest:List[str]):\n",
    "    \"\"\"\n",
    "    Make predictions on df using the model and return inp_cols_of_interest\n",
    "    IMPORTANT: embedding store, es should be the same as the model was trained on\n",
    "    \"\"\"\n",
    "    X = transform_pd_X(df[SELECTED_COLS], SELECTED_INP_COLS)\n",
    "\n",
    "    embed_features = {}\n",
    "    for col in EMBED_COLS:\n",
    "        embed_features[col], _ = transform_embed_col(df[col], es[col][\"tokenizer\"], es[col][\"maxlen\"])\n",
    "     \n",
    "    predict_proba = model.predict([embed_features[FAV], embed_features[UNFAV], X], batch_size=BATCH_SIZE)  \n",
    "    df[PREDICTED_RATING], df[PREDICTION_CONFIDENCE] = np.argmax(predict_proba, axis=1), np.max(predict_proba, axis=1)\n",
    "    \n",
    "    return df[inp_cols_of_interest + [RATING, PREDICTED_RATING, PREDICTION_CONFIDENCE]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Adhoc Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PredictionReport = namedtuple(\"PredictionReport\", \"probabilities predicted_rating confidence\")\n",
    "\n",
    "# Note: Create a dataframe with all SELECTED_INP_COLS\n",
    "test_df = pd.DataFrame({\n",
    "    AGE: [\"45\"],\n",
    "    ZIP_CODE: [\"94086\"],\n",
    "    FAVE_SPORTS: [\"I do not like Sports\"]\n",
    "})\n",
    "\n",
    "probabilities = model.predict(transform_pd_X(test_df, SELECTED_INP_COLS))\n",
    "predicted_rating, confidence = np.argmax(probabilities), np.max(probabilities)\n",
    "\n",
    "PredictionReport(probabilities, predicted_rating, confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare State - Data & Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore previously saved input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1589009535 # seed used in a historical run of interest for fairness analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"inp-{RANDOM_SEED}.pickle\", \"rb\") as f:\n",
    "    X_train, X_test, y_train, y_test, embed_features, embedding_store = pickle.load(f)\n",
    "    \n",
    "X_train.shape, y_train.shape, embed_features[FAV][\"train\"].shape, embed_features[UNFAV][\"train\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore previously saved model. \n",
    "\n",
    "**Note:** This is not suitable for training in its raw form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f\"logs/{RANDOM_SEED}/keras_saved_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and filter data with raw and transformed columns, basically all columns to test for fairness of the subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_df = ad_dataset_pd() #.sample(n=100)\n",
    "merge_minority_classes(fairness_df, RATING) # modifies original dataframe\n",
    "fairness_df[RATING] = fairness_df[RATING].astype(\"float\")\n",
    "fairness_df[RATING] = fairness_df[RATING] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: Use the same `RANDOM_SEED` used while generating the input data. Care must be taken if you restored a previously generated input data from disk, that was generated on a different `RANDOM_SEED`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fairness_df, val_fairness_df = train_test_split(fairness_df, test_size=TEST_FRAC, random_state=RANDOM_SEED)\n",
    "train_fairness_df.shape, val_fairness_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "res = predict_on_dataset(val_fairness_df, model, embedding_store, [AGE, GENDER, INCOME, HOME_COUNTRY])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Serialize for future reference to skip prediction generation. As the inference data is w.r.t the model, we'll save it in the same folder as the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = f\"logs/{RANDOM_SEED}/inference_data.csv\"\n",
    "\n",
    "res.to_csv(out_path, index=False)\n",
    "print(f\"Saved inference data at {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credits: https://stackoverflow.com/a/50671617/1585523 has good explanations for all metrics and is from where the code has been copied\n",
    "\n",
    "def metrics_from_df(df:pd.DataFrame, confidence_threshold=0):\n",
    "    \"\"\"Drop examples with probability < confidence_threshold from calc\"\"\"\n",
    "    y_true = df[RATING]\n",
    "    y_pred = df[PREDICTED_RATING]\n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    FP = FP.astype(float)\n",
    "    FN = FN.astype(float)\n",
    "    TP = TP.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "    # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "    \n",
    "    return {\n",
    "        \"TPR\": TPR, \"TNR\": TNR, \"PPV\": PPV, \"NPV\": NPV, \"FPR\": FPR, \"FNR\": FNR, \"FDR\": FDR, \"ACC\": ACC\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_for_metric_class(metric_df:pd.DataFrame, metric:str=\"FPR\", rating_class:int=1):\n",
    "    \"\"\"Generates plot for metric and given rating_class from metric_df indexed by dimension of interest\"\"\"\n",
    "    plot_df = metric_df.apply(lambda m: m[\"fairness_metrics_per_class\"][metric][rating_class], axis=1)\n",
    "    plot_df = plot_df.reset_index().rename({0: metric}, axis=1)\n",
    "    return plot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to restart the kernel if the execution is slow as we have all the info for computing fairness metrics of columns you selected above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv(\"logs/1589009535/inference_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.sample(4).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_metrics_df = res.groupby(GENDER).apply(metrics_from_df).to_frame(\"fairness_metrics_per_class\")\n",
    "gender_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_df = plot_for_metric_class(gender_metrics_df)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=GENDER, y=\"FPR\", data=plot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy to clipboard for easy pasting into results sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.to_clipboard(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[AGE] = res[AGE].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(res[AGE], kde=False, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_BUCKET = AGE + \"_bucket\"\n",
    "bucket_boundaries = [0, 20, 40, 100] # refer pandas.cut() for syntax on binning\n",
    "age_labels = [\"young\", \"middle-age\", \"old\"] # refer pandas.cut() for syntax on labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[AGE_BUCKET] = pd.cut(res[AGE], bins=bucket_boundaries, labels=age_labels)\n",
    "res[[AGE, AGE_BUCKET]].sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(res[AGE_BUCKET])\n",
    "res[AGE_BUCKET].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_metrics_df = res.groupby(AGE_BUCKET).apply(metrics_from_df).to_frame(\"fairness_metrics_per_class\")\n",
    "age_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = plot_for_metric_class(age_metrics_df)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=AGE_BUCKET, y=\"FPR\", data=plot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy to clipboard for easy pasting into results sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.to_clipboard(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(res[INCOME])\n",
    "res[INCOME].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_metrics_df = res.groupby(INCOME).apply(metrics_from_df).to_frame(\"fairness_metrics_per_class\")\n",
    "income_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_df = plot_for_metric_class(income_metrics_df)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=INCOME, y=\"FPR\", data=plot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy to clipboard for easy pasting into results sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.to_clipboard(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homecountry Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(res[HOME_COUNTRY])\n",
    "res[HOME_COUNTRY].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homecountry_metrics_df = res.groupby(HOME_COUNTRY).apply(metrics_from_df).to_frame(\"fairness_metrics_per_class\")\n",
    "homecountry_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_df = plot_for_metric_class(homecountry_metrics_df)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=HOME_COUNTRY, y=\"FPR\", data=plot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy to clipboard for easy pasting into results sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdCat 11 (Kitchen & Home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter train & val df for Ads of Category 11 - \"Kitchen & Home\"\n",
    "train_fairness_df_adcat11 = train_fairness_df[train_fairness_df['AdId'].str.startswith(\"A11_\")]\n",
    "val_fairness_df_adcat11 = val_fairness_df[val_fairness_df['AdId'].str.startswith(\"A11_\")]\n",
    "train_fairness_df_adcat11.shape, val_fairness_df_adcat11.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fairness_df_adcat11[GENDER].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fairness_df[GENDER].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "res = predict_on_dataset(val_fairness_df_adcat11, model, embedding_store, [AGE, GENDER, INCOME, HOME_COUNTRY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = f\"logs/{RANDOM_SEED}/inference_data_AdCat11.csv\"\n",
    "\n",
    "res.to_csv(out_path, index=False)\n",
    "print(f\"Saved inference data at {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = pd.read_csv(\"logs/\" + str(RANDOM_SEED) + \"/inference_data.csv\")\n",
    "res = pd.read_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.sample(4).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_metrics_df = res.groupby(GENDER).apply(metrics_from_df).to_frame(\"fairness_metrics_per_class\")\n",
    "gender_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = plot_for_metric_class(gender_metrics_df)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=GENDER, y=\"FPR\", data=plot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy to clipboard for easy pasting into results sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.to_clipboard(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Income Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(res[INCOME])\n",
    "res[INCOME].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_metrics_df = res.groupby(INCOME).apply(metrics_from_df).to_frame(\"fairness_metrics_per_class\")\n",
    "income_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = plot_for_metric_class(income_metrics_df)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=INCOME, y=\"FPR\", data=plot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy to clipboard for easy pasting into results sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.to_clipboard(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdCat 03 (Baby Products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter train & val df for Ads of Category 11 - \"Kitchen & Home\"\n",
    "train_fairness_df_adcat03 = train_fairness_df[train_fairness_df['AdId'].str.startswith(\"A03_\")]\n",
    "val_fairness_df_adcat03 = val_fairness_df[val_fairness_df['AdId'].str.startswith(\"A03_\")]\n",
    "train_fairness_df_adcat03.shape, val_fairness_df_adcat03.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fairness_df_adcat03[GENDER].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fairness_df[GENDER].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "res = predict_on_dataset(val_fairness_df_adcat03, model, embedding_store, [AGE, GENDER, INCOME, HOME_COUNTRY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = f\"logs/{RANDOM_SEED}/inference_data_AdCat03.csv\"\n",
    "\n",
    "res.to_csv(out_path, index=False)\n",
    "print(f\"Saved inference data at {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = pd.read_csv(\"logs/\" + str(RANDOM_SEED) + \"/inference_data.csv\")\n",
    "res = pd.read_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.sample(4).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_metrics_df = res.groupby(GENDER).apply(metrics_from_df).to_frame(\"fairness_metrics_per_class\")\n",
    "gender_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = plot_for_metric_class(gender_metrics_df)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=GENDER, y=\"FPR\", data=plot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy to clipboard for easy pasting into results sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.to_clipboard(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdCat 06 (Consumer Electronics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter train & val df for Ads of Category 11 - \"Kitchen & Home\"\n",
    "train_fairness_df_adcat06 = train_fairness_df[train_fairness_df['AdId'].str.startswith(\"A06_\")]\n",
    "val_fairness_df_adcat06 = val_fairness_df[val_fairness_df['AdId'].str.startswith(\"A06_\")]\n",
    "train_fairness_df_adcat06.shape, val_fairness_df_adcat06.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fairness_df_adcat06[GENDER].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fairness_df[GENDER].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "res = predict_on_dataset(val_fairness_df_adcat06, model, embedding_store, [AGE, GENDER, INCOME, HOME_COUNTRY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = f\"logs/{RANDOM_SEED}/inference_data_AdCat06.csv\"\n",
    "\n",
    "res.to_csv(out_path, index=False)\n",
    "print(f\"Saved inference data at {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = pd.read_csv(\"logs/\" + str(RANDOM_SEED) + \"/inference_data.csv\")\n",
    "res = pd.read_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.sample(4).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_metrics_df = res.groupby(GENDER).apply(metrics_from_df).to_frame(\"fairness_metrics_per_class\")\n",
    "gender_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = plot_for_metric_class(gender_metrics_df)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=GENDER, y=\"FPR\", data=plot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy to clipboard for easy pasting into results sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.to_clipboard(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[AGE] = res[AGE].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(res[AGE], kde=False, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_BUCKET = AGE + \"_bucket\"\n",
    "bucket_boundaries = [0, 20, 40, 100] # refer pandas.cut() for syntax on binning\n",
    "age_labels = [\"young\", \"middle-age\", \"old\"] # refer pandas.cut() for syntax on labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[AGE_BUCKET] = pd.cut(res[AGE], bins=bucket_boundaries, labels=age_labels)\n",
    "res[[AGE, AGE_BUCKET]].sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(res[AGE_BUCKET])\n",
    "res[AGE_BUCKET].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_metrics_df = res.groupby(AGE_BUCKET).apply(metrics_from_df).to_frame(\"fairness_metrics_per_class\")\n",
    "age_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = plot_for_metric_class(age_metrics_df)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=AGE_BUCKET, y=\"FPR\", data=plot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy to clipboard for easy pasting into results sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.to_clipboard(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Income Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(res[INCOME])\n",
    "res[INCOME].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_metrics_df = res.groupby(INCOME).apply(metrics_from_df).to_frame(\"fairness_metrics_per_class\")\n",
    "income_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = plot_for_metric_class(income_metrics_df)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=INCOME, y=\"FPR\", data=plot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy to clipboard for easy pasting into results sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.to_clipboard(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Rough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Featurize using Feature Columns\n",
    "\n",
    "Create feature columns like one-hot, embeddings, bucketing from raw features created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EXAMPLE_BATCH = next(iter(input_fn_train(3)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EXAMPLE_BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_feature_column(feature_column):\n",
    "    feature_layer = tf.keras.layers.DenseFeatures(feature_column)\n",
    "    return feature_layer(EXAMPLE_BATCH).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "age_fc = tf.feature_column.numeric_column(AGE, normalizer_fn=lambda x: (x - MEAN_AGE) / STD_AGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "zip_fcs = [\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            f\"{ZIP_CODE}{i}\", vocabulary_list=list(string.digits), \n",
    "            num_oov_buckets=1)\n",
    "    )\n",
    "    for i in range(FIRST_K_ZIP_DIGITS)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EXAMPLE_BATCH[AGE], test_feature_column(age_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "{k: v for k, v in EXAMPLE_BATCH.items() if k.startswith(ZIP_CODE)}, test_feature_column(zip_fcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.keras.layers.concatenate(age_fc, zip_fcs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Fairness Indicators using TFMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import apache_beam as beam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "import tensorflow_data_validation as tfdv\n",
    "from tensorflow_model_analysis.addons.fairness.post_export_metrics import fairness_indicators\n",
    "from tensorflow_model_analysis.addons.fairness.view import widget_view\n",
    "from fairness_indicators.examples import util\n",
    "\n",
    "from witwidget.notebook.visualization import WitConfigBuilder\n",
    "from witwidget.notebook.visualization import WitWidget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train[:100, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dl():\n",
    "    for i in range(100):\n",
    "        yield OrderedDict({\n",
    "            FAV: embed_features[FAV][\"train\"][i, :],\n",
    "            UNFAV: embed_features[UNFAV][\"train\"][i, :],\n",
    "            \"non_embed_inputs\": X_train[i, :],\n",
    "            RATING: y_train[i, :]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(dl, \n",
    "            (tf.float32, tf.float32, tf.float32, tf.float32),\n",
    "            (tf.TensorShape([40]), tf.TensorShape([34]), tf.TensorShape([308]), tf.TensorShape([2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "NON_EMBED_INPUTS = \"non_embed_inputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(dl, \n",
    "            {FAV: tf.float32, UNFAV: tf.float32, NON_EMBED_INPUTS: tf.float32, RATING: tf.float32},\n",
    "            {FAV: tf.TensorShape([40]), UNFAV: tf.TensorShape([34]), NON_EMBED_INPUTS: tf.TensorShape([308]), RATING: tf.TensorShape([2])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fields_to_save = [FAV, UNFAV, NON_EMBED_INPUTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def serialize_example(*example:List[tf.Tensor]):\n",
    "    \"\"\"\n",
    "    Creates a tf.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "    # Create a dictionary mapping the feature name to the tf.Example-compatible data type.\n",
    "    fields = {field: dtype_feature_map[example[i].dtype](example[i]) for i, field in enumerate(fields_to_save)}\n",
    "\n",
    "    # Create a Features message using tf.train.Example.\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=fields))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "def tf_serialize_example(example:Dict):\n",
    "    tf_string = tf.py_function(\n",
    "        serialize_example,\n",
    "        [example[field] for field in fields_to_save],  # pass these args to the above function.\n",
    "        tf.string)      # the return type is `tf.string`.\n",
    "    return tf.reshape(tf_string, ()) # The result is a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    if len(value.shape) > 0:\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    if len(value.shape) > 0:\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dtype_feature_map = {\n",
    "    tf.dtypes.string: _bytes_feature,\n",
    "    tf.dtypes.float16: _float_feature,\n",
    "    tf.dtypes.float32: _float_feature,\n",
    "    tf.dtypes.float64: _float_feature,\n",
    "    tf.dtypes.int8: _int64_feature,\n",
    "    tf.dtypes.int16: _int64_feature,\n",
    "    tf.dtypes.int32: _int64_feature,\n",
    "    tf.dtypes.int64: _int64_feature\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "analysis_data_folder = Path(\"./analysis_data_with_temporal_as_ints\")\n",
    "analysis_train_data_folder = analysis_data_folder/\"train.tfrecords\"\n",
    "analysis_val_data_folder = analysis_data_folder/\"val.tfrecords\"\n",
    "\n",
    "analysis_data_folder.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from shutil import rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_dataset_part(dataset:tf.data, part:int, save_in_folder:Union[Path, str], overwrite=False):\n",
    "    \"\"\"\n",
    "    Save a sharded dataset to a folder\n",
    "    \"\"\"\n",
    "    print(f\"Working on part-{part} of the file\")\n",
    "    save_in_folder:Path = Path(save_in_folder) # change to Path object if not already\n",
    "    overwrite and rmtree(save_in_folder, ignore_errors=True)\n",
    "    save_in_folder.mkdir(parents=True, exist_ok=True)\n",
    "    writer = tf.data.experimental.TFRecordWriter(f\"{save_in_folder}/part-{part}\")\n",
    "    writer.write(dataset)\n",
    "    \n",
    "save_dataset_part_parallel_fn = partial(save_dataset_part, save_in_folder=analysis_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset_for_save(dataset):\n",
    "    return dataset.\\\n",
    "        unbatch().\\\n",
    "        map(tf_serialize_example, tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d1 = prepare_dataset_for_save(dataset.batch(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_dataset_part(d1, 0, analysis_train_data_folder, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "! ls {logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#@title Fairness Indicators Computation Options\n",
    "tfma_eval_result_path = f'{logdir}/tfma_eval_result'\n",
    "\n",
    "#@markdown Modify the slice_selection for experiments on other identities.\n",
    "slice_selection = 'gender' #@param [\"sexual_orientation\", \"gender\", \"religion\", \"race\", \"disability\"]\n",
    "#@markdown Confidence Intervals can help you make better decisions regarding your data, but as it requires computing multiple resamples, is slower particularly in the colab environment that cannot take advantage of parallelization.\n",
    "compute_confidence_intervals = False #@param {type:\"boolean\"}\n",
    "\n",
    "# # Define slices that you want the evaluation to run on.\n",
    "slice_spec = [\n",
    "    tfma.slicer.SingleSliceSpec(), # Overall slice\n",
    "    tfma.slicer.SingleSliceSpec(columns=[slice_selection]),\n",
    "]\n",
    "\n",
    "# # Add the fairness metrics.\n",
    "add_metrics_callbacks = [\n",
    "  tfma.post_export_metrics.fairness_indicators(\n",
    "      thresholds=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "      labels_key=RATING\n",
    "      )\n",
    "]\n",
    "\n",
    "eval_shared_model = tfma.default_eval_shared_model(\n",
    "    eval_saved_model_path=(logdir/\"keras_saved_model\").as_posix(),\n",
    "    add_metrics_callbacks=add_metrics_callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eval_config = text_format.Parse(\"\"\"\n",
    "  # https://www.tensorflow.org/tfx/model_analysis/setup#model_specs\n",
    "  model_specs {\n",
    "    # This assumes a serving model with a \"serving_default\" signature.\n",
    "    label_key: \"%(label_key)s\"\n",
    "  }\n",
    "  metrics_specs {\n",
    "    metrics { class_name: \"ExampleCount\" }\n",
    "    metrics { class_name: \"WeightedExampleCount\" }\n",
    "    metrics { class_name: \"SparseCategoricalCrossentropy\" }\n",
    "    metrics { class_name: \"SparseCategoricalAccuracy\" }\n",
    "    metrics { class_name: \"Precision\" config: '\"top_k\": 1' }\n",
    "    metrics { class_name: \"Precision\" config: '\"top_k\": 3' }\n",
    "    metrics { class_name: \"Recall\" config: '\"top_k\": 1' }\n",
    "    metrics { class_name: \"Recall\" config: '\"top_k\": 3' }\n",
    "    metrics { class_name: \"AUC\" }\n",
    "  }\n",
    "  # https://www.tensorflow.org/tfx/model_analysis/setup#slicing_specs\n",
    "  slicing_specs {\n",
    "    feature_keys: [\"Age\"]\n",
    "  }\n",
    "\"\"\" % {\"label_key\": RATING}, tfma.EvalConfig())\n",
    "\n",
    "eval_shared_model = tfma.default_eval_shared_model(\n",
    "    eval_saved_model_path=(logdir/\"keras_saved_model\").as_posix(), \n",
    "    eval_config=eval_config, add_metrics_callbacks=add_metrics_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eval_result = tfma.run_model_analysis(eval_shared_model=eval_shared_model,\n",
    "                                          eval_config=eval_config,\n",
    "                                          data_location=(analysis_train_data_folder/\"*\").as_posix(),\n",
    "                                          file_format='tfrecords',\n",
    "#                                           slice_spec=slice_list,\n",
    "#                                           output_path='sample_data',\n",
    "#                                           extractors=None, \n",
    "                                          desired_batch_size=1024,\n",
    "                                          random_seed_for_testing=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "slices = [tfma.slicer.SingleSliceSpec(columns=[AGE])]\n",
    "tfma.view.render_slicing_metrics(eval_result, slicing_spec=slices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "validate_tf_file = \"analysis_data_with_temporal_as_ints/train.tfrecords/part-0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Run the fairness evaluation.\n",
    "with beam.Pipeline() as pipeline:\n",
    "    _ = (\n",
    "      pipeline\n",
    "      | 'ReadData' >> beam.io.ReadFromTFRecord(validate_tf_file)\n",
    "      | 'ExtractEvaluateAndWriteResults' >>\n",
    "       tfma.ExtractEvaluateAndWriteResults(\n",
    "                 eval_shared_model=eval_shared_model,\n",
    "                 slice_spec=slice_spec,\n",
    "                 compute_confidence_intervals=compute_confidence_intervals,\n",
    "                 output_path=tfma_eval_result_path)\n",
    "    )\n",
    "\n",
    "#     eval_result = tfma.load_eval_result(output_path=tfma_eval_result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_target_for_model(d:Dict, target_col:str=RATING) -> Tuple[Dict, np.array]:\n",
    "    target = d.pop(target_col)\n",
    "    return d, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for d in dataset.batch(1).take(2):\n",
    "    pprint(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for d in dataset.map(create_dataset_pd).take(2):\n",
    "    pprint(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for d in dl():\n",
    "    for k in d:\n",
    "        print(k, d[k].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.data.Dataset.from_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        FAV: embed_features[FAV][\"train\"][:num_samples, :],\n",
    "        UNFAV: embed_features[UNFAV][\"train\"][:num_samples, :],\n",
    "        \"non_embed_inputs\": X_train[:num_samples, :],\n",
    "        RATING: y_train[:num_samples, :]\n",
    "    },\n",
    "    index=range(num_samples)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "beam.io.ReadF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eval_shared_model??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfma.ExtractEvaluateAndWriteResults??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Fairness Indicators using IBM's AIF360 Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "@misc{aif360-oct-2018,\n",
    "    title = \"{AI Fairness} 360:  An Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias\",\n",
    "    author = {Rachel K. E. Bellamy and Kuntal Dey and Michael Hind and\n",
    "\tSamuel C. Hoffman and Stephanie Houde and Kalapriya Kannan and\n",
    "\tPranay Lohia and Jacquelyn Martino and Sameep Mehta and\n",
    "\tAleksandra Mojsilovic and Seema Nagar and Karthikeyan Natesan Ramamurthy and\n",
    "\tJohn Richards and Diptikalyan Saha and Prasanna Sattigeri and\n",
    "\tMoninder Singh and Kush R. Varshney and Yunfeng Zhang},\n",
    "    month = oct,\n",
    "    year = {2018},\n",
    "    url = {https://arxiv.org/abs/1810.01943}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ./setup.sh # uncomment if you wish to install any new packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from aif360.datasets import GermanDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from aif360.metrics import DatasetMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import aif360.sklearn.metrics as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "257px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
