{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model\n",
    "\n",
    "The aim of the notebook is demo end to end pipeline for Ads prediction in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! ./setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tensorflow/docs\n",
      "  Cloning https://github.com/tensorflow/docs to /private/var/folders/f_/8flgl5n57_dfmnnjzy_w41wm0000gn/T/pip-req-build-zj9ti1z3\n",
      "  Running command git clone -q https://github.com/tensorflow/docs /private/var/folders/f_/8flgl5n57_dfmnnjzy_w41wm0000gn/T/pip-req-build-zj9ti1z3\n",
      "Requirement already satisfied (use --upgrade to upgrade): tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9- from git+https://github.com/tensorflow/docs in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages\n",
      "Requirement already satisfied: astor in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages (from tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9-) (0.8.1)\n",
      "Requirement already satisfied: absl-py in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages (from tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9-) (0.9.0)\n",
      "Requirement already satisfied: six in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages (from tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9-) (1.14.0)\n",
      "Requirement already satisfied: pathlib2 in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages (from tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9-) (2.3.5)\n",
      "Requirement already satisfied: pyyaml in /Users/praveenkrishna/miniconda3/lib/python3.7/site-packages (from tensorflow-docs===0.0.0d92131b8cc983025d3b423255b1afb09683fbed9-) (5.3.1)\n",
      "Building wheels for collected packages: tensorflow-docs\n",
      "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0d92131b8cc983025d3b423255b1afb09683fbed9_-py3-none-any.whl size=98705 sha256=d918741b95d78f55b52fe18e571b925ccd6d05d6ccdf8419855f9a383f158d86\n",
      "  Stored in directory: /private/var/folders/f_/8flgl5n57_dfmnnjzy_w41wm0000gn/T/pip-ephem-wheel-cache-h1t38brr/wheels/cc/c4/d8/5341e93b6376c5c929c49469fce21155eb69cef1a4da4ce32c\n",
      "Successfully built tensorflow-docs\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q git+https://github.com/tensorflow/docs --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tensorflow, 2.1.0 on Python interpreter, sys.version_info(major=3, minor=7, micro=7, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_docs as tfdocs\n",
    "#import tensorflow_docs.modeling\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from typing import Dict, Any, Union, List\n",
    "from functools import partial\n",
    "import re\n",
    "import string\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from math import ceil\n",
    "from collections import namedtuple\n",
    "\n",
    "print(f\"Using Tensorflow, {tf.__version__} on Python interpreter, {sys.version_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using random seed, 1588311123\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = int(time.time())\n",
    "\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"Using random seed, {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Dataset credits:\n",
    "```\n",
    "@inproceedings{roffo2016personality,\n",
    "  title={Personality in computational advertising: A benchmark},\n",
    "  author={Roffo, Giorgio and Vinciarelli, Alessandro},\n",
    "  booktitle={4 th Workshop on Emotions and Personality in Personalized Systems (EMPIRE) 2016},\n",
    "  pages={18},\n",
    "  year={2016}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"../../dataset/\")\n",
    "BATCH_SIZE = 4096 # bigger the batch, faster the training but bigger the RAM needed\n",
    "TARGET_COL = \"Rating\"\n",
    "\n",
    "# data files path are relative DATA_FOLDER\n",
    "users_ads_rating_csv = DATA_FOLDER/\"users-ads-without-gcp-ratings_OHE_MLB.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'CapZipCode',\n",
       " 'FaveSports',\n",
       " 'Gender_F',\n",
       " 'Gender_M',\n",
       " 'ad_num_faces',\n",
       " 'ad_isAdvertising',\n",
       " 'ad_isBrand',\n",
       " 'ad_isElectronic device',\n",
       " 'ad_isElectronics',\n",
       " 'ad_isFashion accessory',\n",
       " 'ad_isFictional character',\n",
       " 'ad_isFont',\n",
       " 'ad_isFurniture',\n",
       " 'ad_isGadget',\n",
       " 'ad_isGames',\n",
       " 'ad_isGraphic design',\n",
       " 'ad_isGraphics',\n",
       " 'ad_isJewellery',\n",
       " 'ad_isLine',\n",
       " 'ad_isLogo',\n",
       " 'ad_isMagenta',\n",
       " 'ad_isMaterial property',\n",
       " 'ad_isMultimedia',\n",
       " 'ad_isProduct',\n",
       " 'ad_isRectangle',\n",
       " 'ad_isSkin',\n",
       " 'ad_isTechnology',\n",
       " 'ad_isText',\n",
       " 'ad_isVehicle',\n",
       " 'ad_isYellow',\n",
       " 'Rating']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_ID = \"UserId\"\n",
    "AD_ID = \"AdId\"\n",
    "AGE = \"Age\"\n",
    "ZIP_CODE = \"CapZipCode\"\n",
    "COUNTRIES_VISITED = \"Countriesvisited\"\n",
    "FAVE_SPORTS = \"FaveSports\"\n",
    "GENDER = \"Gender\"\n",
    "HOME_COUNTRY = \"Homecountry\"\n",
    "HOME_TOWN = \"Hometown\"\n",
    "INCOME = \"Income\"\n",
    "LAST_NAME = \"LastName\"\n",
    "MOST_LISTENED_MUSICS = \"Mostlistenedmusics\"\n",
    "MOST_READ_BOOKS = \"Mostreadbooks\"\n",
    "MOST_VISITED_WEBSITES = \"Mostvisitedwebsites\"\n",
    "MOST_WATCHED_MOVIES = \"Mostwatchedmovies\"\n",
    "MOST_WATCHED_TV_PROGRAMMES = \"Mostwatchedtvprogrammes\"\n",
    "NAME = \"Name\"\n",
    "PAYPAL = \"Paypal\"\n",
    "TIMEPASS = \"Timepass\"\n",
    "TYPE_OF_JOB = \"TypeofJob\"\n",
    "WEEKLY_WORKING_HOURS = \"Weeklyworkinghours\"\n",
    "FAVE1 = \"fave1\"\n",
    "FAVE10 = \"fave10\"\n",
    "FAVE2 = \"fave2\"\n",
    "FAVE3 = \"fave3\"\n",
    "FAVE4 = \"fave4\"\n",
    "FAVE5 = \"fave5\"\n",
    "FAVE6 = \"fave6\"\n",
    "FAVE7 = \"fave7\"\n",
    "FAVE8 = \"fave8\"\n",
    "FAVE9 = \"fave9\"\n",
    "UNFAVE1 = \"unfave1\"\n",
    "UNFAVE2 = \"unfave2\"\n",
    "UNFAVE3 = \"unfave3\"\n",
    "UNFAVE4 = \"unfave4\"\n",
    "UNFAVE5 = \"unfave5\"\n",
    "UNFAVE6 = \"unfave6\"\n",
    "ADFILEPATH = \"AdFilePath\"\n",
    "GENDER_F = \"Gender_F\"\n",
    "GENDER_M = \"Gender_M\"\n",
    "RATING = \"Rating\"\n",
    "AD_NUM_FACES = \"ad_num_faces\"\n",
    "AD_LABEL_FEATURE_1 = 'ad_isAdvertising'\n",
    "AD_LABEL_FEATURE_2 = 'ad_isBrand'\n",
    "AD_LABEL_FEATURE_3 = 'ad_isElectronic device'\n",
    "AD_LABEL_FEATURE_4 = 'ad_isElectronics'\n",
    "AD_LABEL_FEATURE_5 = 'ad_isFashion accessory'\n",
    "AD_LABEL_FEATURE_6 = 'ad_isFictional character'\n",
    "AD_LABEL_FEATURE_7 = 'ad_isFont'\n",
    "AD_LABEL_FEATURE_8 = 'ad_isFurniture'\n",
    "AD_LABEL_FEATURE_9 = 'ad_isGadget'\n",
    "AD_LABEL_FEATURE_10 = 'ad_isGames'\n",
    "AD_LABEL_FEATURE_11 = 'ad_isGraphic design'\n",
    "AD_LABEL_FEATURE_12 = 'ad_isGraphics'\n",
    "AD_LABEL_FEATURE_13 = 'ad_isJewellery'\n",
    "AD_LABEL_FEATURE_14 = 'ad_isLine'\n",
    "AD_LABEL_FEATURE_15 = 'ad_isLogo'\n",
    "AD_LABEL_FEATURE_16 = 'ad_isMagenta'\n",
    "AD_LABEL_FEATURE_17 = 'ad_isMaterial property'\n",
    "AD_LABEL_FEATURE_18 = 'ad_isMultimedia'\n",
    "AD_LABEL_FEATURE_19 = 'ad_isProduct'\n",
    "AD_LABEL_FEATURE_20 = 'ad_isRectangle'\n",
    "AD_LABEL_FEATURE_21 = 'ad_isSkin'\n",
    "AD_LABEL_FEATURE_22 = 'ad_isTechnology'\n",
    "AD_LABEL_FEATURE_23 = 'ad_isText'\n",
    "AD_LABEL_FEATURE_24 = 'ad_isVehicle'\n",
    "AD_LABEL_FEATURE_25 = 'ad_isYellow'\n",
    "\n",
    "\n",
    "# Read all columns as strings to avoid any errors\n",
    "COL_DEFAULTS = {\n",
    "    USER_ID: \"**\",\n",
    "    AD_ID: \"**\",\n",
    "    AGE: \"**\",\n",
    "    ZIP_CODE: \"**\",\n",
    "    COUNTRIES_VISITED: \"**\",\n",
    "    FAVE_SPORTS: \"**\",\n",
    "    GENDER: \"**\",\n",
    "    HOME_COUNTRY: \"**\",\n",
    "    HOME_TOWN: \"**\",\n",
    "    INCOME: \"**\",\n",
    "    LAST_NAME: \"**\",\n",
    "    MOST_LISTENED_MUSICS: \"**\",\n",
    "    MOST_READ_BOOKS: \"**\",\n",
    "    MOST_VISITED_WEBSITES: \"**\",\n",
    "    MOST_WATCHED_MOVIES: \"**\",\n",
    "    MOST_WATCHED_TV_PROGRAMMES: \"**\",\n",
    "    NAME: \"**\",\n",
    "    PAYPAL: \"**\",\n",
    "    TIMEPASS: \"**\",\n",
    "    TYPE_OF_JOB: \"**\",\n",
    "    WEEKLY_WORKING_HOURS: \"**\",\n",
    "    FAVE1: \"**\",\n",
    "    FAVE10: \"**\",\n",
    "    FAVE2: \"**\",\n",
    "    FAVE3: \"**\",\n",
    "    FAVE4: \"**\",\n",
    "    FAVE5: \"**\",\n",
    "    FAVE6: \"**\",\n",
    "    FAVE7: \"**\",\n",
    "    FAVE8: \"**\",\n",
    "    FAVE9: \"**\",\n",
    "    UNFAVE1: \"**\",\n",
    "    UNFAVE2: \"**\",\n",
    "    UNFAVE3: \"**\",\n",
    "    UNFAVE4: \"**\",\n",
    "    UNFAVE5: \"**\",\n",
    "    UNFAVE6: \"**\",\n",
    "    ADFILEPATH: \"**\",\n",
    "    GENDER_F: \"**\",\n",
    "    GENDER_M: \"**\",\n",
    "    RATING: \"**\",\n",
    "    AD_NUM_FACES: \"**\"\n",
    "}\n",
    "\n",
    "# SELECTED_COLS = [AGE, ZIP_CODE, FAVE_SPORTS, GENDER, HOME_COUNTRY, HOME_TOWN, INCOME, MOST_LISTENED_MUSICS, MOST_READ_BOOKS, \n",
    "#                  MOST_VISITED_WEBSITES, MOST_WATCHED_MOVIES, MOST_WATCHED_TV_PROGRAMMES, TIMEPASS, TYPE_OF_JOB, WEEKLY_WORKING_HOURS, \n",
    "#                  FAVE1, FAVE2, FAVE3, FAVE4, FAVE5, FAVE6, FAVE7, FAVE8, FAVE9, FAVE10, UNFAVE1, UNFAVE2, UNFAVE3, UNFAVE4, UNFAVE5, \n",
    "#                  UNFAVE6, RATING]\n",
    "\n",
    "AD_FACE_COLS = [AD_NUM_FACES]\n",
    "AD_LABEL_COLS = [AD_LABEL_FEATURE_1,AD_LABEL_FEATURE_2,AD_LABEL_FEATURE_3,AD_LABEL_FEATURE_4,AD_LABEL_FEATURE_5,\n",
    "                AD_LABEL_FEATURE_6,AD_LABEL_FEATURE_7,AD_LABEL_FEATURE_8,AD_LABEL_FEATURE_9,AD_LABEL_FEATURE_10,\n",
    "                AD_LABEL_FEATURE_11,AD_LABEL_FEATURE_12,AD_LABEL_FEATURE_13,AD_LABEL_FEATURE_14,AD_LABEL_FEATURE_15,\n",
    "                AD_LABEL_FEATURE_16,AD_LABEL_FEATURE_17,AD_LABEL_FEATURE_18,AD_LABEL_FEATURE_19,AD_LABEL_FEATURE_20,\n",
    "                AD_LABEL_FEATURE_21,AD_LABEL_FEATURE_22,AD_LABEL_FEATURE_23,AD_LABEL_FEATURE_24,AD_LABEL_FEATURE_25]\n",
    "AD_OBJECT_COLS = []\n",
    "AD_SAFE_SEARCH_COLS = []\n",
    "\n",
    "\n",
    "SELECTED_AD_COLS = AD_FACE_COLS  + AD_LABEL_COLS + AD_OBJECT_COLS + AD_SAFE_SEARCH_COLS\n",
    "\n",
    "\n",
    "SELECTED_INP_COLS = [AGE, ZIP_CODE, FAVE_SPORTS, GENDER_F, GENDER_M] + SELECTED_AD_COLS\n",
    "SELECTED_COLS = SELECTED_INP_COLS + [TARGET_COL]\n",
    "\n",
    "SELECTED_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ad_dataset_pd():\n",
    "    return pd.read_csv(users_ads_rating_csv, usecols=SELECTED_COLS, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>CapZipCode</th>\n",
       "      <th>FaveSports</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>ad_isAdvertising</th>\n",
       "      <th>ad_isBrand</th>\n",
       "      <th>ad_isElectronic device</th>\n",
       "      <th>ad_isElectronics</th>\n",
       "      <th>...</th>\n",
       "      <th>ad_isMaterial property</th>\n",
       "      <th>ad_isMultimedia</th>\n",
       "      <th>ad_isProduct</th>\n",
       "      <th>ad_isRectangle</th>\n",
       "      <th>ad_isSkin</th>\n",
       "      <th>ad_isTechnology</th>\n",
       "      <th>ad_isText</th>\n",
       "      <th>ad_isVehicle</th>\n",
       "      <th>ad_isYellow</th>\n",
       "      <th>ad_num_faces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>18</td>\n",
       "      <td>25070</td>\n",
       "      <td>Team sports (Footbal, Baseball, Rugby, ...) , ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>34</td>\n",
       "      <td>10000</td>\n",
       "      <td>Individual sports‎ (Tennis, Archery, ...)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33494</th>\n",
       "      <td>27</td>\n",
       "      <td>60064</td>\n",
       "      <td>Water sports, Winter sports</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33003</th>\n",
       "      <td>56</td>\n",
       "      <td>51031</td>\n",
       "      <td>Olympic sports‎</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26596</th>\n",
       "      <td>32</td>\n",
       "      <td>22655</td>\n",
       "      <td>Team sports (Footbal, Baseball, Rugby, ...) , ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25020</th>\n",
       "      <td>27</td>\n",
       "      <td>CM20 1AY</td>\n",
       "      <td>Indoor sports, Olympic sports‎</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19323</th>\n",
       "      <td>49</td>\n",
       "      <td>H4N 2Z1</td>\n",
       "      <td>Team sports (Footbal, Baseball, Rugby, ...)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25048</th>\n",
       "      <td>27</td>\n",
       "      <td>CM20 1AY</td>\n",
       "      <td>Indoor sports, Olympic sports‎</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5523</th>\n",
       "      <td>55</td>\n",
       "      <td>98684-9440</td>\n",
       "      <td>Individual sports‎ (Tennis, Archery, ...)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6670</th>\n",
       "      <td>24</td>\n",
       "      <td>CH44 4BW</td>\n",
       "      <td>I do not like Sports</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  CapZipCode                                         FaveSports  \\\n",
       "2716   18       25070  Team sports (Footbal, Baseball, Rugby, ...) , ...   \n",
       "1285   34       10000          Individual sports‎ (Tennis, Archery, ...)   \n",
       "33494  27       60064                        Water sports, Winter sports   \n",
       "33003  56       51031                                    Olympic sports‎   \n",
       "26596  32       22655  Team sports (Footbal, Baseball, Rugby, ...) , ...   \n",
       "25020  27    CM20 1AY                     Indoor sports, Olympic sports‎   \n",
       "19323  49     H4N 2Z1       Team sports (Footbal, Baseball, Rugby, ...)    \n",
       "25048  27    CM20 1AY                     Indoor sports, Olympic sports‎   \n",
       "5523   55  98684-9440          Individual sports‎ (Tennis, Archery, ...)   \n",
       "6670   24    CH44 4BW                               I do not like Sports   \n",
       "\n",
       "      Rating Gender_F Gender_M ad_isAdvertising ad_isBrand  \\\n",
       "2716     1.0        1        0                0          1   \n",
       "1285     3.0        1        0                0          0   \n",
       "33494    2.0        1        0                0          1   \n",
       "33003    1.0        1        0                0          0   \n",
       "26596    1.0        0        1                0          0   \n",
       "25020    4.0        1        0                0          0   \n",
       "19323    1.0        0        1                0          1   \n",
       "25048    4.0        1        0                0          1   \n",
       "5523     3.0        0        1                0          1   \n",
       "6670     2.0        0        1                0          0   \n",
       "\n",
       "      ad_isElectronic device ad_isElectronics  ... ad_isMaterial property  \\\n",
       "2716                       0                0  ...                      0   \n",
       "1285                       1                0  ...                      0   \n",
       "33494                      0                0  ...                      0   \n",
       "33003                      0                0  ...                      0   \n",
       "26596                      0                0  ...                      0   \n",
       "25020                      0                0  ...                      0   \n",
       "19323                      0                0  ...                      0   \n",
       "25048                      0                0  ...                      0   \n",
       "5523                       0                0  ...                      0   \n",
       "6670                       0                0  ...                      0   \n",
       "\n",
       "      ad_isMultimedia ad_isProduct ad_isRectangle ad_isSkin ad_isTechnology  \\\n",
       "2716                0            0              0         0               0   \n",
       "1285                1            1              0         0               1   \n",
       "33494               0            0              0         0               0   \n",
       "33003               0            0              0         0               0   \n",
       "26596               0            1              0         0               0   \n",
       "25020               0            1              0         0               0   \n",
       "19323               0            0              0         0               0   \n",
       "25048               0            0              1         0               0   \n",
       "5523                0            0              0         0               0   \n",
       "6670                0            0              0         0               0   \n",
       "\n",
       "      ad_isText ad_isVehicle ad_isYellow ad_num_faces  \n",
       "2716          1            0           0            0  \n",
       "1285          1            0           0            0  \n",
       "33494         0            0           0            0  \n",
       "33003         1            0           0            0  \n",
       "26596         1            0           0            0  \n",
       "25020         1            0           0            0  \n",
       "19323         1            0           0            0  \n",
       "25048         0            0           0            0  \n",
       "5523          1            0           0            0  \n",
       "6670          1            0           0            0  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_dataset_pd().sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_project(d:Dict, cols:List[str]) -> Dict:\n",
    "    return {k:v for k, v in d.items() if k in cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexerForVocab:\n",
    "    def __init__(self, vocab_list:List[str], oov_index:int=0):\n",
    "        \"\"\"\n",
    "        Creates a string indexer for the vocabulary with out of vocabulary (oov) indexing\n",
    "        \"\"\"\n",
    "        self._vocab_map = {v:i+1 for i, v in enumerate(vocab_list)}\n",
    "        self._oov = oov_index\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"Map for {len(self)} keys with 1 OOV key\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._vocab_map) + 1\n",
    "        \n",
    "    def index_of(self, item:str):\n",
    "        \"\"\"\n",
    "        Index of item in the vocabulary\n",
    "        \"\"\"\n",
    "        return self._vocab_map.get(item, self._oov)\n",
    "    \n",
    "    def index_of_mux(self, items:List[str]):\n",
    "        return [self.index_of(i) for i in items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age\n",
    "\n",
    "Convert to a number and remove any outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained from Tensorflow Data Validation APIs data-exploration/tensorflow-data-validation.ipynb\n",
    "\n",
    "MEAN_AGE, STD_AGE, MEDIAN_AGE, MAX_AGE = 31.74, 12.07, 29, 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_age(age_str:tf.string, default_age=MEDIAN_AGE) -> int:\n",
    "    \"\"\"Typecast age to an integer and update outliers with the default\"\"\"\n",
    "    try:\n",
    "        age = int(age_str)\n",
    "        if age < 0 or age > MAX_AGE:\n",
    "            raise ValueError(f\"{age} is not a valid age\")\n",
    "    except:\n",
    "        age = default_age\n",
    "    normalized_age = (age - MEAN_AGE) / STD_AGE\n",
    "    return normalized_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5128417564208783,\n",
       " -0.22700911350455663,\n",
       " -0.22700911350455663,\n",
       " -0.22700911350455663,\n",
       " -0.22700911350455663)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_age(\"50\"), fix_age(\"50.5\"), fix_age(\"-10\"), fix_age(\"bad_age_10\"), fix_age(\"300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip Code\n",
    "\n",
    "Prepare zip-code column for one-hot encoding each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_ZIP_CODE, FIRST_K_ZIP_DIGITS = \"00000\", 2\n",
    "\n",
    "zip_code_indexer = IndexerForVocab(string.digits + string.ascii_lowercase + string.ascii_uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_zip_code_tensor(zip_code:tf.string, n_digits, indexer) -> List[str]:\n",
    "    \"\"\"Extracts the the first n_digits as a list\"\"\"\n",
    "    zip_digits = []\n",
    "    try:\n",
    "        if isinstance(zip_code, tf.Tensor):\n",
    "            zip_code = zip_code.numpy()[0].decode('ascii', errors=\"ignore\") # very ineffecient way\n",
    "        zip_digits = list(zip_code.strip()[:n_digits])\n",
    "    except:\n",
    "        zip_digits = list(DEFAULT_ZIP_CODE[:n_digits])\n",
    "    return tf.concat( [\n",
    "        tf.one_hot(\n",
    "            indexer.index_of(d), len(indexer)\n",
    "        ) for d in zip_digits\n",
    "    ], 0 )\n",
    "\n",
    "def fix_zip_code(zip_code:str, n_digits, indexer) -> List[str]:\n",
    "    \"\"\"Extracts the the first n_digits as a list\"\"\"\n",
    "    zip_digits = []\n",
    "    try:\n",
    "        zip_digits = list(zip_code.strip()[:n_digits])\n",
    "    except:\n",
    "        zip_digits = list(DEFAULT_ZIP_CODE[:n_digits])\n",
    "    return np.ravel(np.eye(len(indexer))[indexer.index_of_mux(zip_digits)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_zip_code_indexer = IndexerForVocab(string.digits)\n",
    "\n",
    "(fix_zip_code(\"43556\", 10, test_zip_code_indexer),\n",
    "fix_zip_code(\"43556\", 2, test_zip_code_indexer),\n",
    "fix_zip_code(\"43556\", 4, test_zip_code_indexer),\n",
    "fix_zip_code(None, 3, test_zip_code_indexer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Favorite Sports\n",
    "\n",
    "Two approaches,\n",
    "1. Consider the first `K` sports mentioned by each user and one-hot encode each separately\n",
    "2. Multi label binarize all the sports as there are only 15 unique sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=None, sparse_output=False)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FAV_SPORTS_UNKNOWN = \"UNK_SPORT\"\n",
    "ALL_FAV_SPORTS = ['Olympic sports', 'Winter sports', 'Nothing', 'I do not like Sports', 'Equestrian sports', 'Skating sports', 'Precision sports', 'Hunting sports', 'Motor sports', 'Team sports', 'Individual sports', 'Other', 'Water sports', 'Indoor sports', 'Endurance sports']\n",
    "\n",
    "fav_sports_binarizer = MultiLabelBinarizer()\n",
    "fav_sports_binarizer.fit([ALL_FAV_SPORTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fav_sports_multi_select_str_to_list(sports_str:Union[str, tf.Tensor]) -> List[str]:\n",
    "    # remove commas that dont separate different user selections\n",
    "    # example, commas inside paranthesis of \"Individual sports (Tennis, Archery, ...)\" dont make new sports\n",
    "    if isinstance(sports_str, tf.Tensor):\n",
    "        sports_str = sports_str.numpy()[0].decode('ascii', errors=\"ignore\")\n",
    "    else:\n",
    "        sports_str = sports_str.encode(\"ascii\", errors=\"ignore\").decode(\"ascii\") # remove non-ascii chars\n",
    "    sports = re.sub(r\"\\s*\\(.*,.*\\)\\s*\", \"\", sports_str)\n",
    "    return re.split(r\"\\s*,\\s*\", sports)\n",
    "\n",
    "def fix_fav_sports_mlb(sports_str:str) -> List[int]:\n",
    "    sports = fav_sports_multi_select_str_to_list(sports_str)\n",
    "    return fav_sports_binarizer.transform([sports])[0]\n",
    "\n",
    "def fix_fav_sports_firstk(sports_str:str, first_k:int, pad_constant:int) -> List[str]:\n",
    "    sports = fav_sports_multi_select_str_to_list(sports_str)\n",
    "    right_pad_width = first_k - len(sports_enc)\n",
    "    result = [sports + [pad_constant] * right_pad_width][:first_k]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    fix_fav_sports_mlb(\"Individual sports (Tennis, Archery, ...), Indoor sports, Endurance sports, Skating sports\"),\n",
    "    fix_fav_sports_mlb(\"Skating sports\"),\n",
    "    fix_fav_sports_mlb(\"Individual sports (Tennis, Archery, ...)\"),\n",
    "    fix_fav_sports_mlb(\"Indoor sports, Endurance sports, Skating sports\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATINGS_CARDINALITY = 5 # not zero based indexing i.e. ratings range from 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_pd(rating_str:str):\n",
    "    return np.eye(RATINGS_CARDINALITY, dtype=int)[int(float(rating_str)) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pd_X(df:pd.DataFrame, inp_cols:List[str]):\n",
    "    \"\"\"Original dataframe will be modified\"\"\"\n",
    "    df[AGE] = df[AGE].apply(lambda age: [fix_age(age)])\n",
    "    df[ZIP_CODE] = df[ZIP_CODE].apply(lambda zc: fix_zip_code(zc, n_digits=2, indexer=zip_code_indexer))\n",
    "    df[FAVE_SPORTS] = df[FAVE_SPORTS].apply(fix_fav_sports_mlb)\n",
    "    df[GENDER_F] = df[GENDER_F].apply(lambda gender_f: [int(gender_f)])\n",
    "    df[GENDER_M] = df[GENDER_M].apply(lambda gender_m: [int(gender_m)])\n",
    "    df[AD_NUM_FACES] = df[AD_NUM_FACES].apply(lambda ad_num_faces: [int(ad_num_faces)])\n",
    "    \n",
    "    df[AD_LABEL_FEATURE_1] = df[AD_LABEL_FEATURE_1].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_2] = df[AD_LABEL_FEATURE_2].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_3] = df[AD_LABEL_FEATURE_3].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_4] = df[AD_LABEL_FEATURE_4].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_5] = df[AD_LABEL_FEATURE_5].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_6] = df[AD_LABEL_FEATURE_6].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_7] = df[AD_LABEL_FEATURE_7].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_8] = df[AD_LABEL_FEATURE_8].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_9] = df[AD_LABEL_FEATURE_9].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_10] = df[AD_LABEL_FEATURE_10].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_11] = df[AD_LABEL_FEATURE_11].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_12] = df[AD_LABEL_FEATURE_12].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_13] = df[AD_LABEL_FEATURE_13].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_14] = df[AD_LABEL_FEATURE_14].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_15] = df[AD_LABEL_FEATURE_15].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_16] = df[AD_LABEL_FEATURE_16].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_17] = df[AD_LABEL_FEATURE_17].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_18] = df[AD_LABEL_FEATURE_18].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_19] = df[AD_LABEL_FEATURE_19].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_20] = df[AD_LABEL_FEATURE_20].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_21] = df[AD_LABEL_FEATURE_21].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_22] = df[AD_LABEL_FEATURE_22].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_23] = df[AD_LABEL_FEATURE_23].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_24] = df[AD_LABEL_FEATURE_24].apply(lambda f: [int(f)])\n",
    "    df[AD_LABEL_FEATURE_25] = df[AD_LABEL_FEATURE_25].apply(lambda f: [int(f)])\n",
    "    \n",
    "            \n",
    "    \n",
    "    df[\"X\"] = df[inp_cols].apply(np.concatenate, axis=1)\n",
    "    # TODO: vectorize, else inefficient to sequentially loop over all example\n",
    "    X = np.array([x for x in df[\"X\"]])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pd_y(df:pd.DataFrame, target_col:str):\n",
    "    \"\"\"Original dataframe will be modified\"\"\"\n",
    "    df[\"y\"] = df[target_col].apply(create_target_pd)\n",
    "    # TODO: vectorize, else inefficient to sequentially loop over all example\n",
    "    y = np.array([y for y in df[\"y\"]])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_pd(inp_cols:List[str]=SELECTED_INP_COLS, target_col:str=TARGET_COL, fraction:float=1) -> pd.DataFrame:\n",
    "    \"\"\"Prepare the dataset for training on a fraction of all input data\"\"\"\n",
    "    df = ad_dataset_pd().sample(frac=fraction)\n",
    "    return transform_pd_X(df, inp_cols), transform_pd_y(df, target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tensorboard\n",
    "\n",
    "Monitor training and other stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Start tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 77956), started 6:05:02 ago. (Use '!kill 77956' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2cd2e75f49261ada\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2cd2e75f49261ada\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir logs (started 6:05:03 ago; pid 77956)\n"
     ]
    }
   ],
   "source": [
    "notebook.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Create a model and train using high level APIs like `tf.keras` and `tf.estimator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28 s, sys: 234 ms, total: 28.3 s\n",
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train_dataset = input_fn_train(BATCH_SIZE)\n",
    "X, y = create_dataset_pd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.metrics.SensitivityAtSpecificity(name=\"ss\")  # For false positive rate\n",
    "\n",
    "keras_model_metrics = [\n",
    "    \"accuracy\",\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc')\n",
    "]\n",
    "train_histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T CHANGE THE EPOCHS VALUE\n",
    "BATCH_SIZE = 4096\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging tensorboard data at logs/20200430-232306\n"
     ]
    }
   ],
   "source": [
    "logdir = Path(\"logs\")/datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    logdir, \n",
    "    histogram_freq=max(1, ceil(EPOCHS / 20)), # to control the amount of logging\n",
    "#     embeddings_freq=epochs,\n",
    ")\n",
    "print(f\"Logging tensorboard data at {logdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 20)                3420      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 3,525\n",
      "Trainable params: 3,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(20, input_shape=(X.shape[1],), activation=tf.keras.layers.LeakyReLU()),\n",
    "    tf.keras.layers.Dense(RATINGS_CARDINALITY , activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(\n",
    "        learning_rate=0.003,\n",
    "        clipvalue=0.5\n",
    "    ), \n",
    "#     optimizer=tf.keras.optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True), \n",
    "#     optimizer=tf.keras.optimizers.RMSprop(lr),\n",
    "#     loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=keras_model_metrics\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 18s, sys: 8min 26s, total: 17min 45s\n",
      "Wall time: 3min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_histories.append(model.fit(\n",
    "    X, y,\n",
    "    BATCH_SIZE,\n",
    "    epochs=EPOCHS, \n",
    "    #callbacks=[tensorboard_callback, tfdocs.modeling.EpochDots()],\n",
    "    callbacks=[tensorboard_callback],\n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_tp</th>\n",
       "      <th>val_fp</th>\n",
       "      <th>val_tn</th>\n",
       "      <th>val_fn</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.953246</td>\n",
       "      <td>0.635069</td>\n",
       "      <td>14960.0</td>\n",
       "      <td>5119.0</td>\n",
       "      <td>110081.0</td>\n",
       "      <td>13840.0</td>\n",
       "      <td>0.745057</td>\n",
       "      <td>0.519444</td>\n",
       "      <td>0.883266</td>\n",
       "      <td>1.014866</td>\n",
       "      <td>0.618472</td>\n",
       "      <td>3547.0</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>27498.0</td>\n",
       "      <td>3653.0</td>\n",
       "      <td>0.731491</td>\n",
       "      <td>0.492639</td>\n",
       "      <td>0.867585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy       tp      fp        tn       fn  precision  \\\n",
       "999  0.953246  0.635069  14960.0  5119.0  110081.0  13840.0   0.745057   \n",
       "\n",
       "       recall       auc  val_loss  val_accuracy  val_tp  val_fp   val_tn  \\\n",
       "999  0.519444  0.883266  1.014866      0.618472  3547.0  1302.0  27498.0   \n",
       "\n",
       "     val_fn  val_precision  val_recall   val_auc  \n",
       "999  3653.0       0.731491    0.492639  0.867585  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(train_histories[-1].history) # pick the latest training history\n",
    "\n",
    "metrics_df.tail(1) # pick the last epoch's metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tip:` You can copy the final metrics row from above and paste it using `Shift + Cmd + V` in our [sheet](https://docs.google.com/spreadsheets/d/1v-nYiDA3elM1UP9stkB42MK0bTbuLxYJE7qAYDP8FHw/edit#gid=925421130) to accurately place all values in the respective columns\n",
    "\n",
    "**IMPORTANT**: Please don't forget to update git version ID column after you check-in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Metrics with p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n",
    "\n",
    "Save the model for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save((logdir/\"keras_saved_model\").as_posix(), save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictionReport = namedtuple(\"PredictionReport\", \"probabilities predicted_rating confidence\")\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    AGE: [\"45\"],\n",
    "    ZIP_CODE: [\"94086\"],\n",
    "    FAVE_SPORTS: [\"I do not like Sports\"]\n",
    "})\n",
    "\n",
    "probabilities = model.predict(transform_pd_X(test_df, SELECTED_INP_COLS))\n",
    "predicted_rating, confidence = np.argmax(probabilities), np.max(probabilities)\n",
    "\n",
    "PredictionReport(probabilities, predicted_rating, confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Rough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Featurize using Feature Columns\n",
    "\n",
    "Create feature columns like one-hot, embeddings, bucketing from raw features created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EXAMPLE_BATCH = next(iter(input_fn_train(3)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EXAMPLE_BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_feature_column(feature_column):\n",
    "    feature_layer = tf.keras.layers.DenseFeatures(feature_column)\n",
    "    return feature_layer(EXAMPLE_BATCH).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "age_fc = tf.feature_column.numeric_column(AGE, normalizer_fn=lambda x: (x - MEAN_AGE) / STD_AGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "zip_fcs = [\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            f\"{ZIP_CODE}{i}\", vocabulary_list=list(string.digits), \n",
    "            num_oov_buckets=1)\n",
    "    )\n",
    "    for i in range(FIRST_K_ZIP_DIGITS)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EXAMPLE_BATCH[AGE], test_feature_column(age_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "{k: v for k, v in EXAMPLE_BATCH.items() if k.startswith(ZIP_CODE)}, test_feature_column(zip_fcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.keras.layers.concatenate(age_fc, zip_fcs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "221.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
